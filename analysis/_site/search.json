[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "Description here"
  },
  {
    "objectID": "preprocess.html",
    "href": "preprocess.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\n\n\n\n\nmr_preproc <- function(d) {\n\n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_easy.keys,\n    resp_MR_easy.corr,\n    resp_MR_easy.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      \"id\" = \"Индивидуальный_код\",\n      # rename columns for handy usage\n      \"key\" = resp_MR_easy.keys,\n      \"is_correct\" = resp_MR_easy.corr,\n      \"rt\" = resp_MR_easy.rt\n    ) -> MR_easy # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_medium.keys,\n    resp_MR_medium.corr,\n    resp_MR_medium.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |>  # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_MR_medium.keys,\n      \"is_correct\" = resp_MR_medium.corr,\n      \"rt\" = resp_MR_medium.rt\n    ) -> MR_medium # ready to use\n  \n  \n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_hard.keys,\n    resp_MR_hard.corr,\n    resp_MR_hard.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_MR_hard.keys,\n      \"is_correct\" = resp_MR_hard.corr,\n      \"rt\" = resp_MR_hard.rt\n    ) -> MR_hard # ready to use\n  \n  # bind all conditions of mental rotation task to one tibble\n  \n  bind_rows(MR_easy, MR_medium, MR_hard) -> MR\n  \n  return(MR)\n  \n}\n\n\nms_preproc <- function(d) {\n  \n  # Since we our participants could fill the fields in any order, \n  # here is a function which allows us to count correct inputs \n  # our subjects made.\n  \n  n_count <- function(df) {\n    df |> select(matches(\"^noun\")) |> as.matrix() -> s\n    df |> select(matches(\"^resp\")) |> as.matrix() -> r\n    a <- vector(mode = \"numeric\", length = 16L)\n    for (i in 1:16) {\n      a[i] <- sum(r[i, ] %in% s[i, ])\n    }\n    return(a)\n  }\n  \n  if (\"mouse_MSe.time\" %in% colnames(d)) {\n    \n    d |> select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"resp\\\\d\\\\.text$\"),\n      \"mouse_MSe.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\") |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"id\" = \"Индивидуальный_код\",\n        \"rt\" = \"mouse_MSe.time\"\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"MSm.text$\"),\n      \"mouse_MSm.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\") |> \n      rename(\"id\" = \"Индивидуальный_код\",\n             \"rt\" = \"mouse_MSm.time\") |>\n      rename_with(.fn = str_replace_all, \n                  pattern = \"_MSm\\\\.text\", \n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"MSh.text$\"),\n      \"mouse_MSh.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\") |>\n      rename(\"id\" = \"Индивидуальный_код\",\n             \"rt\" = \"mouse_MSh.time\") |> \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\",\n                  replacement = \"\") -> MS_hard\n    \n  } else {\n    \n    d |> select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"resp\\\\d\\\\.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\",\n             rt = NA) |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"id\" = \"Индивидуальный_код\"\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"MSm.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\",\n             rt = NA) |>\n      rename(\"id\" = \"Индивидуальный_код\") |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSm\\\\.text\",\n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"MSh.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\",\n             rt = NA) |>\n      rename(\"id\" = \"Индивидуальный_код\") |> \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\", \n                  replacement = \"\") -> MS_hard\n  }\n  \n  tibble(\n    id = MS_easy$id[1],\n    trials = 1:16,\n    MS_easy_n = n_count(MS_easy),\n    MS_easy_rt = MS_easy$rt,\n    MS_medium_n = n_count(MS_medium),\n    MS_medium_rt = MS_medium$rt,\n    MS_hard_n = n_count(MS_hard),\n    MS_hard_rt = MS_hard$rt\n  ) |>\n    pivot_longer(cols = -c(\"id\", \"trials\"), values_to = \"value\") |>\n    separate(name, c(\"task\", \"level\", \"name\")) |>\n    pivot_wider(values_from = value, names_from = name) |>\n    mutate(acc = ifelse(level == \"easy\", n / 3,\n                        ifelse(\n                          level == \"medium\", n / 5,\n                          ifelse(level == \"hard\", n / 7, NA)\n                        ))) -> MS\n  \n  return(MS)\n  \n}\n\n\nst_preproc <- function(d) {\n\n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    key_resp_SE.keys,\n    key_resp_SE.corr,\n    key_resp_SE.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = key_resp_SE.keys,\n      \"is_correct\" = key_resp_SE.corr,\n      \"rt\" = key_resp_SE.rt\n    ) -> ST_easy # ready to use\n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    key_resp_SM.keys,\n    key_resp_SM.corr,\n    key_resp_SM.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = key_resp_SM.keys,\n      \"is_correct\" = key_resp_SM.corr,\n      \"rt\" = key_resp_SM.rt\n    ) -> ST_medium # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    resp_S_H_trials.keys,\n    resp_S_H_trials.corr,\n    resp_S_H_trials.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_S_H_trials.keys,\n      \"is_correct\" = resp_S_H_trials.corr,\n      \"rt\" = resp_S_H_trials.rt\n    ) -> ST_hard # ready to use\n  \n  # bind all conditions of sternberg task to one tibble\n  bind_rows(ST_easy, ST_hard, ST_medium) -> ST\n  \n  return(ST)\n\n}\n\n\nnasatlx_preproc <- function(d) {\n  d |> select(\"Индивидуальный_код\",\n              slider.response,\n              head,\n              task_type,\n              task_level) |>\n    filter_at(vars(head, task_type, task_level), all_vars(!is.na(.))) |>\n    rename(\"id\" = \"Индивидуальный_код\",\n           \"score\" = slider.response) |>\n    mutate(\n      scale = recode(\n        head,\n        \"Умственная нагрузка\" = \"ME\",\n        \"Физическая нагрузка\" = \"PH\",\n        \"Давление времени\" = \"TI\",\n        \"Успешность выполнения\" = \"PE\",\n        \"Усилия\" = \"EF\",\n        \"Уровень фрустрации\" = \"FR\"\n      ),\n      task = recode(\n        task_type,\n        \"mental_rotation\" = \"MR\",\n        \"sternberg\" = \"ST\",\n        \"mental_span\" = \"MS\"\n      ),\n      level = recode(\n        task_level,\n        \"1\" = \"easy\",\n        \"2\" = \"medium\",\n        \"3\" = \"hard\"\n      )\n    ) |>\n    select(id, scale, score, task, level) -> NASATLX\n  \n  return(NASATLX)\n}\n\n\nsequence_preproc <- function(d) {\n  \n  d |> select(\n    E_rotation,\n    M_rotation,\n    H_rotation,\n    E_Sternberg,\n    M_Sternberg,\n    H_Sternberg,\n    E_span,\n    M_span,\n    H_span\n  ) |>\n    drop_na() |>\n    sapply(function(x) which(x == 1)) -> v \n    \n  tibble(name = names(v),\n           order = v,\n           id = d[[\"Индивидуальный_код\"]][1]) |>\n    arrange(order) |>\n    separate(name, c(\"level\", \"task\"), \"_\") |>\n    mutate(\n      task = recode(\n        task,\n        \"rotation\" = \"MR\",\n        \"Sternberg\" = \"ST\",\n        \"span\" = \"MS\"\n      ),\n      level = recode(\n        level,\n        \"E\" = \"easy\",\n        \"M\" = \"medium\",\n        \"H\" = \"hard\"\n      )\n    ) -> SEQUENCE\n  \n  return(SEQUENCE)\n  \n}\n\n\n\n\n\nfiles <- paste0(\"../data-firstbanch/\", dir(\"../data-firstbanch\"))\nlength(files)\n\n[1] 78\n\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\nSEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  SEQUENCE_data |> bind_rows(sequence_preproc(d) |> mutate(file = files[i])) -> SEQUENCE_data\n\n}\n\n[1] \"../data-firstbanch/001SSMS_entire_exp_2022-05-31_18h24.17.csv\"\n[1] \"../data-firstbanch/003SSKS_entire_exp_2022-06-16_20h02.35.389.csv\"\n[1] \"../data-firstbanch/004SSDR_entire_exp_2022-06-02_21h35.09.567.csv\"\n[1] \"../data-firstbanch/005SSDR_entire_exp_2022-05-31_20h43.50.910.csv\"\n[1] \"../data-firstbanch/006SSEE_entire_exp_2022-06-02_22h14.18.092.csv\"\n[1] \"../data-firstbanch/007SSJM_entire_exp_2022-06-01_15h12.27.341.csv\"\n[1] \"../data-firstbanch/008SSEP_entire_exp_2022-09-15_21h36.55.631.csv\"\n[1] \"../data-firstbanch/009SSAP_entire_exp_2022-06-04_15h48.30.436.csv\"\n[1] \"../data-firstbanch/010SSEA_entire_exp_2022-06-07_24h08.05.064.csv\"\n[1] \"../data-firstbanch/011SSAB_entire_exp_2022-06-01_14h54.48.csv\"\n[1] \"../data-firstbanch/012EROP_entire_exp_2022-07-14_20h26.20.219.csv\"\n[1] \"../data-firstbanch/013ERVB_entire_exp_2022-06-23_15h53.22.750.csv\"\n[1] \"../data-firstbanch/014ERAI_entire_exp_2022-06-16_13h57.46.683.csv\"\n[1] \"../data-firstbanch/015ERIG_entire_exp_2022-08-17_23h56.01.csv\"\n[1] \"../data-firstbanch/016ERSA_entire_exp_2022-06-16_14h19.07.981.csv\"\n[1] \"../data-firstbanch/017ERVZ_entire_exp_2022-08-20_16h11.35.184.csv\"\n[1] \"../data-firstbanch/019ERSM_entire_exp_2022-06-18_21h43.19.372.csv\"\n[1] \"../data-firstbanch/021SSAZ_entire_exp_2022-07-15_03h19.45.491.csv\"\n[1] \"../data-firstbanch/022ERVS_entire_exp_2022-07-15_21h42.11.588.csv\"\n[1] \"../data-firstbanch/023ERRS_entire_exp_2022-07-11_18h59.41.csv\"\n[1] \"../data-firstbanch/024SSSV_entire_exp_2022-07-24_18h50.18.841.csv\"\n[1] \"../data-firstbanch/025ARAS_entire_exp_2023-05-02_19h18.58.479.csv\"\n[1] \"../data-firstbanch/026SSDM_entire_exp_2022-07-16_12h26.44.968.csv\"\n[1] \"../data-firstbanch/027ARDB_entire_exp_2022-07-18_10h37.13.819.csv\"\n[1] \"../data-firstbanch/029SSDL_entire_exp_2022-07-16_09h09.20.517.csv\"\n[1] \"../data-firstbanch/030SSPM_entire_exp_2022-08-17_21h31.18.058.csv\"\n[1] \"../data-firstbanch/031SSAS_entire_exp_2022-07-16_08h00.03.221.csv\"\n[1] \"../data-firstbanch/032SSAP_entire_exp_2022-07-17_13h28.21.518.csv\"\n[1] \"../data-firstbanch/033SSML_entire_exp_2022-07-26_18h52.18.365.csv\"\n[1] \"../data-firstbanch/035SSDD_entire_exp_2022-08-14_12h43.23.036.csv\"\n[1] \"../data-firstbanch/037ARDL_entire_exp_2022-07-16_22h20.51.764.csv\"\n[1] \"../data-firstbanch/038AREN_entire_exp_2022-07-19_11h25.52.006.csv\"\n[1] \"../data-firstbanch/039ARVP_entire_exp_2022-08-08_15h15.43.173.csv\"\n[1] \"../data-firstbanch/040ARKK_entire_exp_2023-04-23_17h12.22.533.csv\"\n[1] \"../data-firstbanch/042SSAA_entire_exp_2022-08-17_14h03.26.713.csv\"\n[1] \"../data-firstbanch/045SSEM_entire_exp_2022-08-17_14h07.54.819.csv\"\n[1] \"../data-firstbanch/046SSVS_entire_exp_2022-08-20_13h21.07.492.csv\"\n[1] \"../data-firstbanch/047SSAK_entire_exp_2022-08-20_23h14.23.266.csv\"\n[1] \"../data-firstbanch/048SSAG_entire_exp_2022-08-18_20h28.36.828.csv\"\n[1] \"../data-firstbanch/050SSAA_entire_exp_2023-04-21_13h38.45.765.csv\"\n[1] \"../data-firstbanch/052SSME_entire_exp_2022-08-26_10h32.55.991.csv\"\n[1] \"../data-firstbanch/053SSAF_entire_exp_2022-08-25_21h56.58.660.csv\"\n[1] \"../data-firstbanch/054SSEB_entire_exp_2022-08-25_18h20.01.028.csv\"\n[1] \"../data-firstbanch/055SSNS_entire_exp_2022-08-27_10h54.17.951.csv\"\n[1] \"../data-firstbanch/056SSKA_entire_exp_2022-08-26_10h55.02.575.csv\"\n[1] \"../data-firstbanch/058SSAB_entire_exp_2022-09-01_19h07.29.229.csv\"\n[1] \"../data-firstbanch/059SSAS_entire_exp_2022-08-28_11h50.43.886.csv\"\n[1] \"../data-firstbanch/062SSON_entire_exp_2022-09-03_18h24.04.978.csv\"\n[1] \"../data-firstbanch/063SSMP_entire_exp_2022-08-31_09h41.09.233.csv\"\n[1] \"../data-firstbanch/064SSAB_entire_exp_2022-09-09_24h56.58.121.csv\"\n[1] \"../data-firstbanch/065SSTM_entire_exp_2022-09-08_13h04.21.029.csv\"\n[1] \"../data-firstbanch/066SSKA_entire_exp_2023-04-20_19h55.36.813.csv\"\n[1] \"../data-firstbanch/067SSDA_entire_exp_2022-09-08_15h14.26.648.csv\"\n[1] \"../data-firstbanch/068SSMT_entire_exp_2022-09-08_14h02.24.512.csv\"\n[1] \"../data-firstbanch/069SSMV_entire_exp_2022-09-09_15h05.56.561.csv\"\n[1] \"../data-firstbanch/070SSAK_entire_exp_2022-09-08_15h22.31.854.csv\"\n[1] \"../data-firstbanch/071SSEB_entire_exp_2022-09-13_13h34.34.403.csv\"\n[1] \"../data-firstbanch/073SSMS_entire_exp_2022-09-17_12h41.16.219.csv\"\n[1] \"../data-firstbanch/074SSKS_entire_exp_2022-09-09_08h40.26.331.csv\"\n[1] \"../data-firstbanch/076SSRK_entire_exp_2022-09-10_24h29.10.709.csv\"\n[1] \"../data-firstbanch/077SSKK_entire_exp_2022-09-09_18h47.59.035.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2022-09-18_20h01.24.482.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2023-04-23_12h12.09.879.csv\"\n[1] \"../data-firstbanch/080SSAF_entire_exp_2022-09-09_18h48.13.239.csv\"\n[1] \"../data-firstbanch/083SSAN_entire_exp_2022-09-10_09h01.25.268.csv\"\n[1] \"../data-firstbanch/086SSAI_entire_exp_2022-09-09_19h50.26.340.csv\"\n[1] \"../data-firstbanch/087SSVC_entire_exp_2022-09-17_17h38.47.991.csv\"\n[1] \"../data-firstbanch/088SSDR_entire_exp_2022-09-16_17h28.38.834.csv\"\n[1] \"../data-firstbanch/089SSDM_entire_exp_2023-04-25_14h12.30.529.csv\"\n[1] \"../data-firstbanch/091SSJP_entire_exp_2022-09-14_23h28.30.070.csv\"\n[1] \"../data-firstbanch/092SSAG_entire_exp_2022-09-10_16h20.00.504.csv\"\n[1] \"../data-firstbanch/093SSEG_entire_exp_2022-09-14_17h20.12.899.csv\"\n[1] \"../data-firstbanch/095SSVH_entire_exp_2022-09-15_24h16.25.521.csv\"\n[1] \"../data-firstbanch/096SSMR_entire_exp_2023-05-06_17h41.53.790.csv\"\n[1] \"../data-firstbanch/098SSDM_entire_exp_2023-04-23_16h09.02.953.csv\"\n[1] \"../data-firstbanch/099SSDA_entire_exp_04-20-2023_18h41.33.261.csv\"\n[1] \"../data-firstbanch/100SSNT_entire_exp_2023-04-25_13h53.44.583.csv\"\n[1] \"../data-firstbanch/101SSOK_entire_exp_2023-04-25_15h56.39.280.csv\"\n\n\n\nunique(MR_data$file) |> length()\n\n[1] 78\n\nunique(ST_data$file) |> length()\n\n[1] 78\n\nunique(MS_data$file) |> length()\n\n[1] 78\n\nunique(NASATLX_data$file) |> length()\n\n[1] 78\n\nunique(SEQUENCE_data$file) |> length()\n\n[1] 78\n\n\n\n\n\n\nexptime <- tibble()\n\nfor (j in 1:length(files)) {\n  \n  print(files[j])\n  \n  tibble(file = files[j],\n         start = files[j] |> \n           str_extract(\"\\\\d{4}-\\\\d{2}-\\\\d{2}_\\\\d+h\\\\d+\\\\.\\\\d+\") |> \n           str_replace(\"h\", \":\") |> \n           str_replace(\"\\\\.\", \":\") |> \n           str_replace(\"_\", \" \") |> \n           as_datetime(tz = \"Etc/GMT-3\"),\n         end = file.info(files[j])$mtime |> \n           as_datetime(tz = \"UTC\")\n  ) |> \n    bind_rows(exptime) -> exptime\n  \n}\n\n[1] \"../data-firstbanch/001SSMS_entire_exp_2022-05-31_18h24.17.csv\"\n[1] \"../data-firstbanch/003SSKS_entire_exp_2022-06-16_20h02.35.389.csv\"\n[1] \"../data-firstbanch/004SSDR_entire_exp_2022-06-02_21h35.09.567.csv\"\n[1] \"../data-firstbanch/005SSDR_entire_exp_2022-05-31_20h43.50.910.csv\"\n[1] \"../data-firstbanch/006SSEE_entire_exp_2022-06-02_22h14.18.092.csv\"\n[1] \"../data-firstbanch/007SSJM_entire_exp_2022-06-01_15h12.27.341.csv\"\n[1] \"../data-firstbanch/008SSEP_entire_exp_2022-09-15_21h36.55.631.csv\"\n[1] \"../data-firstbanch/009SSAP_entire_exp_2022-06-04_15h48.30.436.csv\"\n[1] \"../data-firstbanch/010SSEA_entire_exp_2022-06-07_24h08.05.064.csv\"\n[1] \"../data-firstbanch/011SSAB_entire_exp_2022-06-01_14h54.48.csv\"\n[1] \"../data-firstbanch/012EROP_entire_exp_2022-07-14_20h26.20.219.csv\"\n[1] \"../data-firstbanch/013ERVB_entire_exp_2022-06-23_15h53.22.750.csv\"\n[1] \"../data-firstbanch/014ERAI_entire_exp_2022-06-16_13h57.46.683.csv\"\n[1] \"../data-firstbanch/015ERIG_entire_exp_2022-08-17_23h56.01.csv\"\n[1] \"../data-firstbanch/016ERSA_entire_exp_2022-06-16_14h19.07.981.csv\"\n[1] \"../data-firstbanch/017ERVZ_entire_exp_2022-08-20_16h11.35.184.csv\"\n[1] \"../data-firstbanch/019ERSM_entire_exp_2022-06-18_21h43.19.372.csv\"\n[1] \"../data-firstbanch/021SSAZ_entire_exp_2022-07-15_03h19.45.491.csv\"\n[1] \"../data-firstbanch/022ERVS_entire_exp_2022-07-15_21h42.11.588.csv\"\n[1] \"../data-firstbanch/023ERRS_entire_exp_2022-07-11_18h59.41.csv\"\n[1] \"../data-firstbanch/024SSSV_entire_exp_2022-07-24_18h50.18.841.csv\"\n[1] \"../data-firstbanch/025ARAS_entire_exp_2023-05-02_19h18.58.479.csv\"\n[1] \"../data-firstbanch/026SSDM_entire_exp_2022-07-16_12h26.44.968.csv\"\n[1] \"../data-firstbanch/027ARDB_entire_exp_2022-07-18_10h37.13.819.csv\"\n[1] \"../data-firstbanch/029SSDL_entire_exp_2022-07-16_09h09.20.517.csv\"\n[1] \"../data-firstbanch/030SSPM_entire_exp_2022-08-17_21h31.18.058.csv\"\n[1] \"../data-firstbanch/031SSAS_entire_exp_2022-07-16_08h00.03.221.csv\"\n[1] \"../data-firstbanch/032SSAP_entire_exp_2022-07-17_13h28.21.518.csv\"\n[1] \"../data-firstbanch/033SSML_entire_exp_2022-07-26_18h52.18.365.csv\"\n[1] \"../data-firstbanch/035SSDD_entire_exp_2022-08-14_12h43.23.036.csv\"\n[1] \"../data-firstbanch/037ARDL_entire_exp_2022-07-16_22h20.51.764.csv\"\n[1] \"../data-firstbanch/038AREN_entire_exp_2022-07-19_11h25.52.006.csv\"\n[1] \"../data-firstbanch/039ARVP_entire_exp_2022-08-08_15h15.43.173.csv\"\n[1] \"../data-firstbanch/040ARKK_entire_exp_2023-04-23_17h12.22.533.csv\"\n[1] \"../data-firstbanch/042SSAA_entire_exp_2022-08-17_14h03.26.713.csv\"\n[1] \"../data-firstbanch/045SSEM_entire_exp_2022-08-17_14h07.54.819.csv\"\n[1] \"../data-firstbanch/046SSVS_entire_exp_2022-08-20_13h21.07.492.csv\"\n[1] \"../data-firstbanch/047SSAK_entire_exp_2022-08-20_23h14.23.266.csv\"\n[1] \"../data-firstbanch/048SSAG_entire_exp_2022-08-18_20h28.36.828.csv\"\n[1] \"../data-firstbanch/050SSAA_entire_exp_2023-04-21_13h38.45.765.csv\"\n[1] \"../data-firstbanch/052SSME_entire_exp_2022-08-26_10h32.55.991.csv\"\n[1] \"../data-firstbanch/053SSAF_entire_exp_2022-08-25_21h56.58.660.csv\"\n[1] \"../data-firstbanch/054SSEB_entire_exp_2022-08-25_18h20.01.028.csv\"\n[1] \"../data-firstbanch/055SSNS_entire_exp_2022-08-27_10h54.17.951.csv\"\n[1] \"../data-firstbanch/056SSKA_entire_exp_2022-08-26_10h55.02.575.csv\"\n[1] \"../data-firstbanch/058SSAB_entire_exp_2022-09-01_19h07.29.229.csv\"\n[1] \"../data-firstbanch/059SSAS_entire_exp_2022-08-28_11h50.43.886.csv\"\n[1] \"../data-firstbanch/062SSON_entire_exp_2022-09-03_18h24.04.978.csv\"\n[1] \"../data-firstbanch/063SSMP_entire_exp_2022-08-31_09h41.09.233.csv\"\n[1] \"../data-firstbanch/064SSAB_entire_exp_2022-09-09_24h56.58.121.csv\"\n[1] \"../data-firstbanch/065SSTM_entire_exp_2022-09-08_13h04.21.029.csv\"\n[1] \"../data-firstbanch/066SSKA_entire_exp_2023-04-20_19h55.36.813.csv\"\n[1] \"../data-firstbanch/067SSDA_entire_exp_2022-09-08_15h14.26.648.csv\"\n[1] \"../data-firstbanch/068SSMT_entire_exp_2022-09-08_14h02.24.512.csv\"\n[1] \"../data-firstbanch/069SSMV_entire_exp_2022-09-09_15h05.56.561.csv\"\n[1] \"../data-firstbanch/070SSAK_entire_exp_2022-09-08_15h22.31.854.csv\"\n[1] \"../data-firstbanch/071SSEB_entire_exp_2022-09-13_13h34.34.403.csv\"\n[1] \"../data-firstbanch/073SSMS_entire_exp_2022-09-17_12h41.16.219.csv\"\n[1] \"../data-firstbanch/074SSKS_entire_exp_2022-09-09_08h40.26.331.csv\"\n[1] \"../data-firstbanch/076SSRK_entire_exp_2022-09-10_24h29.10.709.csv\"\n[1] \"../data-firstbanch/077SSKK_entire_exp_2022-09-09_18h47.59.035.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2022-09-18_20h01.24.482.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2023-04-23_12h12.09.879.csv\"\n[1] \"../data-firstbanch/080SSAF_entire_exp_2022-09-09_18h48.13.239.csv\"\n[1] \"../data-firstbanch/083SSAN_entire_exp_2022-09-10_09h01.25.268.csv\"\n[1] \"../data-firstbanch/086SSAI_entire_exp_2022-09-09_19h50.26.340.csv\"\n[1] \"../data-firstbanch/087SSVC_entire_exp_2022-09-17_17h38.47.991.csv\"\n[1] \"../data-firstbanch/088SSDR_entire_exp_2022-09-16_17h28.38.834.csv\"\n[1] \"../data-firstbanch/089SSDM_entire_exp_2023-04-25_14h12.30.529.csv\"\n[1] \"../data-firstbanch/091SSJP_entire_exp_2022-09-14_23h28.30.070.csv\"\n[1] \"../data-firstbanch/092SSAG_entire_exp_2022-09-10_16h20.00.504.csv\"\n[1] \"../data-firstbanch/093SSEG_entire_exp_2022-09-14_17h20.12.899.csv\"\n[1] \"../data-firstbanch/095SSVH_entire_exp_2022-09-15_24h16.25.521.csv\"\n[1] \"../data-firstbanch/096SSMR_entire_exp_2023-05-06_17h41.53.790.csv\"\n[1] \"../data-firstbanch/098SSDM_entire_exp_2023-04-23_16h09.02.953.csv\"\n[1] \"../data-firstbanch/099SSDA_entire_exp_04-20-2023_18h41.33.261.csv\"\n[1] \"../data-firstbanch/100SSNT_entire_exp_2023-04-25_13h53.44.583.csv\"\n[1] \"../data-firstbanch/101SSOK_entire_exp_2023-04-25_15h56.39.280.csv\"\n\n\n\nexptime |> \n  mutate(dur = abs(start - end)) -> exptime\n\n\n\n\n\nset.seed(123)\ntibble(\n  file = exptime$file,\n  id = stringi::stri_rand_strings(length(exptime$file), 10)) -> IDS\n\n\nMR_data |> select(-id) |> full_join(IDS, by = \"file\") -> MR_data\nST_data |> select(-id) |> full_join(IDS, by = \"file\") -> ST_data\nMS_data |> select(-id) |> full_join(IDS, by = \"file\") -> MS_data\nNASATLX_data |> select(-id) |> full_join(IDS, by = \"file\") -> NASATLX_data\nSEQUENCE_data |> select(-id) |> full_join(IDS, by = \"file\") -> SEQUENCE_data\nexptime |> full_join(IDS, by = \"file\") -> exptime\n\n\n\n\n\nMR_data |> select(-file) |> write_csv(\"MR_firstbanch_data.csv\")\nST_data |> select(-file) |> write_csv(\"ST_firstbanch_data.csv\")\nMS_data |> select(-file) |> write_csv(\"MS_firstbanch_data.csv\")\nNASATLX_data |> select(-file) |> write_csv(\"NASATLX_firstbanch_data.csv\")\nSEQUENCE_data |> select(-file) |> write_csv(\"SEQ_firstbanch_data.csv\")\nexptime |> select(-file) |> write_csv(\"EXPTIME_firstbanch_data.csv\")\nIDS |> write_csv(\"IDS_firstbanch_data.csv\")"
  },
  {
    "objectID": "preprocess.html#packages",
    "href": "preprocess.html#packages",
    "title": "First Banch Preprocess Workflow",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "preprocess.html#custom-preprocess-functions",
    "href": "preprocess.html#custom-preprocess-functions",
    "title": "First Banch Preprocess Workflow",
    "section": "",
    "text": "mr_preproc &lt;- function(d) {\n\n  require(tidyverse)\n  \n  d |&gt; select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_easy.keys,\n    resp_MR_easy.corr,\n    resp_MR_easy.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      \"id\" = \"Индивидуальный_код\",\n      # rename columns for handy usage\n      \"key\" = resp_MR_easy.keys,\n      \"is_correct\" = resp_MR_easy.corr,\n      \"rt\" = resp_MR_easy.rt\n    ) -&gt; MR_easy # ready to use\n  \n  \n  d |&gt; select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_medium.keys,\n    resp_MR_medium.corr,\n    resp_MR_medium.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |&gt;  # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_MR_medium.keys,\n      \"is_correct\" = resp_MR_medium.corr,\n      \"rt\" = resp_MR_medium.rt\n    ) -&gt; MR_medium # ready to use\n  \n  \n  \n  d |&gt; select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_hard.keys,\n    resp_MR_hard.corr,\n    resp_MR_hard.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_MR_hard.keys,\n      \"is_correct\" = resp_MR_hard.corr,\n      \"rt\" = resp_MR_hard.rt\n    ) -&gt; MR_hard # ready to use\n  \n  # bind all conditions of mental rotation task to one tibble\n  \n  bind_rows(MR_easy, MR_medium, MR_hard) -&gt; MR\n  \n  return(MR)\n  \n}\n\n\nms_preproc &lt;- function(d) {\n  \n  # Since we our participants could fill the fields in any order, \n  # here is a function which allows us to count correct inputs \n  # our subjects made.\n  \n  n_count &lt;- function(df) {\n    df |&gt; select(matches(\"^noun\")) |&gt; as.matrix() -&gt; s\n    df |&gt; select(matches(\"^resp\")) |&gt; as.matrix() -&gt; r\n    a &lt;- vector(mode = \"numeric\", length = 16L)\n    for (i in 1:16) {\n      a[i] &lt;- sum(r[i, ] %in% s[i, ])\n    }\n    return(a)\n  }\n  \n  if (\"mouse_MSe.time\" %in% colnames(d)) {\n    \n    d |&gt; select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"resp\\\\d\\\\.text$\"),\n      \"mouse_MSe.time\"\n    ) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"easy\") |&gt;\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"id\" = \"Индивидуальный_код\",\n        \"rt\" = \"mouse_MSe.time\"\n      ) |&gt;\n      select(-c(paste0(\"noun\", 4:7))) -&gt; MS_easy\n    \n    d |&gt; select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"MSm.text$\"),\n      \"mouse_MSm.time\"\n    ) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"medium\") |&gt; \n      rename(\"id\" = \"Индивидуальный_код\",\n             \"rt\" = \"mouse_MSm.time\") |&gt;\n      rename_with(.fn = str_replace_all, \n                  pattern = \"_MSm\\\\.text\", \n                  replacement = \"\") |&gt; \n      select(-noun6, -noun7) -&gt; MS_medium\n    \n    \n    d |&gt; select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"MSh.text$\"),\n      \"mouse_MSh.time\"\n    ) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"hard\") |&gt;\n      rename(\"id\" = \"Индивидуальный_код\",\n             \"rt\" = \"mouse_MSh.time\") |&gt; \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\",\n                  replacement = \"\") -&gt; MS_hard\n    \n  } else {\n    \n    d |&gt; select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"resp\\\\d\\\\.text$\")) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"easy\",\n             rt = NA) |&gt;\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"id\" = \"Индивидуальный_код\"\n      ) |&gt;\n      select(-c(paste0(\"noun\", 4:7))) -&gt; MS_easy\n    \n    d |&gt; select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"MSm.text$\")) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"medium\",\n             rt = NA) |&gt;\n      rename(\"id\" = \"Индивидуальный_код\") |&gt;\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSm\\\\.text\",\n                  replacement = \"\") |&gt; \n      select(-noun6, -noun7) -&gt; MS_medium\n    \n    \n    d |&gt; select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"MSh.text$\")) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"hard\",\n             rt = NA) |&gt;\n      rename(\"id\" = \"Индивидуальный_код\") |&gt; \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\", \n                  replacement = \"\") -&gt; MS_hard\n  }\n  \n  tibble(\n    id = MS_easy$id[1],\n    trials = 1:16,\n    MS_easy_n = n_count(MS_easy),\n    MS_easy_rt = MS_easy$rt,\n    MS_medium_n = n_count(MS_medium),\n    MS_medium_rt = MS_medium$rt,\n    MS_hard_n = n_count(MS_hard),\n    MS_hard_rt = MS_hard$rt\n  ) |&gt;\n    pivot_longer(cols = -c(\"id\", \"trials\"), values_to = \"value\") |&gt;\n    separate(name, c(\"task\", \"level\", \"name\")) |&gt;\n    pivot_wider(values_from = value, names_from = name) |&gt;\n    mutate(acc = ifelse(level == \"easy\", n / 3,\n                        ifelse(\n                          level == \"medium\", n / 5,\n                          ifelse(level == \"hard\", n / 7, NA)\n                        ))) -&gt; MS\n  \n  return(MS)\n  \n}\n\n\nst_preproc &lt;- function(d) {\n\n  require(tidyverse)\n  \n  d |&gt; select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    key_resp_SE.keys,\n    key_resp_SE.corr,\n    key_resp_SE.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = key_resp_SE.keys,\n      \"is_correct\" = key_resp_SE.corr,\n      \"rt\" = key_resp_SE.rt\n    ) -&gt; ST_easy # ready to use\n  \n  d |&gt; select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    key_resp_SM.keys,\n    key_resp_SM.corr,\n    key_resp_SM.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = key_resp_SM.keys,\n      \"is_correct\" = key_resp_SM.corr,\n      \"rt\" = key_resp_SM.rt\n    ) -&gt; ST_medium # ready to use\n  \n  \n  d |&gt; select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    resp_S_H_trials.keys,\n    resp_S_H_trials.corr,\n    resp_S_H_trials.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_S_H_trials.keys,\n      \"is_correct\" = resp_S_H_trials.corr,\n      \"rt\" = resp_S_H_trials.rt\n    ) -&gt; ST_hard # ready to use\n  \n  # bind all conditions of sternberg task to one tibble\n  bind_rows(ST_easy, ST_hard, ST_medium) -&gt; ST\n  \n  return(ST)\n\n}\n\n\nnasatlx_preproc &lt;- function(d) {\n  d |&gt; select(\"Индивидуальный_код\",\n              slider.response,\n              head,\n              task_type,\n              task_level) |&gt;\n    filter_at(vars(head, task_type, task_level), all_vars(!is.na(.))) |&gt;\n    rename(\"id\" = \"Индивидуальный_код\",\n           \"score\" = slider.response) |&gt;\n    mutate(\n      scale = recode(\n        head,\n        \"Умственная нагрузка\" = \"ME\",\n        \"Физическая нагрузка\" = \"PH\",\n        \"Давление времени\" = \"TI\",\n        \"Успешность выполнения\" = \"PE\",\n        \"Усилия\" = \"EF\",\n        \"Уровень фрустрации\" = \"FR\"\n      ),\n      task = recode(\n        task_type,\n        \"mental_rotation\" = \"MR\",\n        \"sternberg\" = \"ST\",\n        \"mental_span\" = \"MS\"\n      ),\n      level = recode(\n        task_level,\n        \"1\" = \"easy\",\n        \"2\" = \"medium\",\n        \"3\" = \"hard\"\n      )\n    ) |&gt;\n    select(id, scale, score, task, level) -&gt; NASATLX\n  \n  return(NASATLX)\n}\n\n\nsequence_preproc &lt;- function(d) {\n  \n  d |&gt; select(\n    E_rotation,\n    M_rotation,\n    H_rotation,\n    E_Sternberg,\n    M_Sternberg,\n    H_Sternberg,\n    E_span,\n    M_span,\n    H_span\n  ) |&gt;\n    drop_na() |&gt;\n    sapply(function(x) which(x == 1)) -&gt; v \n    \n  tibble(name = names(v),\n           order = v,\n           id = d[[\"Индивидуальный_код\"]][1]) |&gt;\n    arrange(order) |&gt;\n    separate(name, c(\"level\", \"task\"), \"_\") |&gt;\n    mutate(\n      task = recode(\n        task,\n        \"rotation\" = \"MR\",\n        \"Sternberg\" = \"ST\",\n        \"span\" = \"MS\"\n      ),\n      level = recode(\n        level,\n        \"E\" = \"easy\",\n        \"M\" = \"medium\",\n        \"H\" = \"hard\"\n      )\n    ) -&gt; SEQUENCE\n  \n  return(SEQUENCE)\n  \n}"
  },
  {
    "objectID": "preprocess.html#load-preprocess-data",
    "href": "preprocess.html#load-preprocess-data",
    "title": "First Banch Preprocess Workflow",
    "section": "",
    "text": "files &lt;- paste0(\"../data-firstbanch/\", dir(\"../data-firstbanch\"))\nlength(files)\n\n[1] 78\n\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\nSEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  SEQUENCE_data |&gt; bind_rows(sequence_preproc(d) |&gt; mutate(file = files[i])) -&gt; SEQUENCE_data\n\n}\n\n[1] \"../data-firstbanch/001SSMS_entire_exp_2022-05-31_18h24.17.csv\"\n[1] \"../data-firstbanch/003SSKS_entire_exp_2022-06-16_20h02.35.389.csv\"\n[1] \"../data-firstbanch/004SSDR_entire_exp_2022-06-02_21h35.09.567.csv\"\n[1] \"../data-firstbanch/005SSDR_entire_exp_2022-05-31_20h43.50.910.csv\"\n[1] \"../data-firstbanch/006SSEE_entire_exp_2022-06-02_22h14.18.092.csv\"\n[1] \"../data-firstbanch/007SSJM_entire_exp_2022-06-01_15h12.27.341.csv\"\n[1] \"../data-firstbanch/008SSEP_entire_exp_2022-09-15_21h36.55.631.csv\"\n[1] \"../data-firstbanch/009SSAP_entire_exp_2022-06-04_15h48.30.436.csv\"\n[1] \"../data-firstbanch/010SSEA_entire_exp_2022-06-07_24h08.05.064.csv\"\n[1] \"../data-firstbanch/011SSAB_entire_exp_2022-06-01_14h54.48.csv\"\n[1] \"../data-firstbanch/012EROP_entire_exp_2022-07-14_20h26.20.219.csv\"\n[1] \"../data-firstbanch/013ERVB_entire_exp_2022-06-23_15h53.22.750.csv\"\n[1] \"../data-firstbanch/014ERAI_entire_exp_2022-06-16_13h57.46.683.csv\"\n[1] \"../data-firstbanch/015ERIG_entire_exp_2022-08-17_23h56.01.csv\"\n[1] \"../data-firstbanch/016ERSA_entire_exp_2022-06-16_14h19.07.981.csv\"\n[1] \"../data-firstbanch/017ERVZ_entire_exp_2022-08-20_16h11.35.184.csv\"\n[1] \"../data-firstbanch/019ERSM_entire_exp_2022-06-18_21h43.19.372.csv\"\n[1] \"../data-firstbanch/021SSAZ_entire_exp_2022-07-15_03h19.45.491.csv\"\n[1] \"../data-firstbanch/022ERVS_entire_exp_2022-07-15_21h42.11.588.csv\"\n[1] \"../data-firstbanch/023ERRS_entire_exp_2022-07-11_18h59.41.csv\"\n[1] \"../data-firstbanch/024SSSV_entire_exp_2022-07-24_18h50.18.841.csv\"\n[1] \"../data-firstbanch/025ARAS_entire_exp_2023-05-02_19h18.58.479.csv\"\n[1] \"../data-firstbanch/026SSDM_entire_exp_2022-07-16_12h26.44.968.csv\"\n[1] \"../data-firstbanch/027ARDB_entire_exp_2022-07-18_10h37.13.819.csv\"\n[1] \"../data-firstbanch/029SSDL_entire_exp_2022-07-16_09h09.20.517.csv\"\n[1] \"../data-firstbanch/030SSPM_entire_exp_2022-08-17_21h31.18.058.csv\"\n[1] \"../data-firstbanch/031SSAS_entire_exp_2022-07-16_08h00.03.221.csv\"\n[1] \"../data-firstbanch/032SSAP_entire_exp_2022-07-17_13h28.21.518.csv\"\n[1] \"../data-firstbanch/033SSML_entire_exp_2022-07-26_18h52.18.365.csv\"\n[1] \"../data-firstbanch/035SSDD_entire_exp_2022-08-14_12h43.23.036.csv\"\n[1] \"../data-firstbanch/037ARDL_entire_exp_2022-07-16_22h20.51.764.csv\"\n[1] \"../data-firstbanch/038AREN_entire_exp_2022-07-19_11h25.52.006.csv\"\n[1] \"../data-firstbanch/039ARVP_entire_exp_2022-08-08_15h15.43.173.csv\"\n[1] \"../data-firstbanch/040ARKK_entire_exp_2023-04-23_17h12.22.533.csv\"\n[1] \"../data-firstbanch/042SSAA_entire_exp_2022-08-17_14h03.26.713.csv\"\n[1] \"../data-firstbanch/045SSEM_entire_exp_2022-08-17_14h07.54.819.csv\"\n[1] \"../data-firstbanch/046SSVS_entire_exp_2022-08-20_13h21.07.492.csv\"\n[1] \"../data-firstbanch/047SSAK_entire_exp_2022-08-20_23h14.23.266.csv\"\n[1] \"../data-firstbanch/048SSAG_entire_exp_2022-08-18_20h28.36.828.csv\"\n[1] \"../data-firstbanch/050SSAA_entire_exp_2023-04-21_13h38.45.765.csv\"\n[1] \"../data-firstbanch/052SSME_entire_exp_2022-08-26_10h32.55.991.csv\"\n[1] \"../data-firstbanch/053SSAF_entire_exp_2022-08-25_21h56.58.660.csv\"\n[1] \"../data-firstbanch/054SSEB_entire_exp_2022-08-25_18h20.01.028.csv\"\n[1] \"../data-firstbanch/055SSNS_entire_exp_2022-08-27_10h54.17.951.csv\"\n[1] \"../data-firstbanch/056SSKA_entire_exp_2022-08-26_10h55.02.575.csv\"\n[1] \"../data-firstbanch/058SSAB_entire_exp_2022-09-01_19h07.29.229.csv\"\n[1] \"../data-firstbanch/059SSAS_entire_exp_2022-08-28_11h50.43.886.csv\"\n[1] \"../data-firstbanch/062SSON_entire_exp_2022-09-03_18h24.04.978.csv\"\n[1] \"../data-firstbanch/063SSMP_entire_exp_2022-08-31_09h41.09.233.csv\"\n[1] \"../data-firstbanch/064SSAB_entire_exp_2022-09-09_24h56.58.121.csv\"\n[1] \"../data-firstbanch/065SSTM_entire_exp_2022-09-08_13h04.21.029.csv\"\n[1] \"../data-firstbanch/066SSKA_entire_exp_2023-04-20_19h55.36.813.csv\"\n[1] \"../data-firstbanch/067SSDA_entire_exp_2022-09-08_15h14.26.648.csv\"\n[1] \"../data-firstbanch/068SSMT_entire_exp_2022-09-08_14h02.24.512.csv\"\n[1] \"../data-firstbanch/069SSMV_entire_exp_2022-09-09_15h05.56.561.csv\"\n[1] \"../data-firstbanch/070SSAK_entire_exp_2022-09-08_15h22.31.854.csv\"\n[1] \"../data-firstbanch/071SSEB_entire_exp_2022-09-13_13h34.34.403.csv\"\n[1] \"../data-firstbanch/073SSMS_entire_exp_2022-09-17_12h41.16.219.csv\"\n[1] \"../data-firstbanch/074SSKS_entire_exp_2022-09-09_08h40.26.331.csv\"\n[1] \"../data-firstbanch/076SSRK_entire_exp_2022-09-10_24h29.10.709.csv\"\n[1] \"../data-firstbanch/077SSKK_entire_exp_2022-09-09_18h47.59.035.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2022-09-18_20h01.24.482.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2023-04-23_12h12.09.879.csv\"\n[1] \"../data-firstbanch/080SSAF_entire_exp_2022-09-09_18h48.13.239.csv\"\n[1] \"../data-firstbanch/083SSAN_entire_exp_2022-09-10_09h01.25.268.csv\"\n[1] \"../data-firstbanch/086SSAI_entire_exp_2022-09-09_19h50.26.340.csv\"\n[1] \"../data-firstbanch/087SSVC_entire_exp_2022-09-17_17h38.47.991.csv\"\n[1] \"../data-firstbanch/088SSDR_entire_exp_2022-09-16_17h28.38.834.csv\"\n[1] \"../data-firstbanch/089SSDM_entire_exp_2023-04-25_14h12.30.529.csv\"\n[1] \"../data-firstbanch/091SSJP_entire_exp_2022-09-14_23h28.30.070.csv\"\n[1] \"../data-firstbanch/092SSAG_entire_exp_2022-09-10_16h20.00.504.csv\"\n[1] \"../data-firstbanch/093SSEG_entire_exp_2022-09-14_17h20.12.899.csv\"\n[1] \"../data-firstbanch/095SSVH_entire_exp_2022-09-15_24h16.25.521.csv\"\n[1] \"../data-firstbanch/096SSMR_entire_exp_2023-05-06_17h41.53.790.csv\"\n[1] \"../data-firstbanch/098SSDM_entire_exp_2023-04-23_16h09.02.953.csv\"\n[1] \"../data-firstbanch/099SSDA_entire_exp_04-20-2023_18h41.33.261.csv\"\n[1] \"../data-firstbanch/100SSNT_entire_exp_2023-04-25_13h53.44.583.csv\"\n[1] \"../data-firstbanch/101SSOK_entire_exp_2023-04-25_15h56.39.280.csv\"\n\n\n\nunique(MR_data$file) |&gt; length()\n\n[1] 78\n\nunique(ST_data$file) |&gt; length()\n\n[1] 78\n\nunique(MS_data$file) |&gt; length()\n\n[1] 78\n\nunique(NASATLX_data$file) |&gt; length()\n\n[1] 78\n\nunique(SEQUENCE_data$file) |&gt; length()\n\n[1] 78"
  },
  {
    "objectID": "preprocess.html#overall-experiment-time",
    "href": "preprocess.html#overall-experiment-time",
    "title": "First Banch Preprocess Workflow",
    "section": "",
    "text": "exptime &lt;- tibble()\n\nfor (j in 1:length(files)) {\n  \n  print(files[j])\n  \n  tibble(file = files[j],\n         start = files[j] |&gt; \n           str_extract(\"\\\\d{4}-\\\\d{2}-\\\\d{2}_\\\\d+h\\\\d+\\\\.\\\\d+\") |&gt; \n           str_replace(\"h\", \":\") |&gt; \n           str_replace(\"\\\\.\", \":\") |&gt; \n           str_replace(\"_\", \" \") |&gt; \n           as_datetime(tz = \"Etc/GMT-3\"),\n         end = file.info(files[j])$mtime |&gt; \n           as_datetime(tz = \"UTC\")\n  ) |&gt; \n    bind_rows(exptime) -&gt; exptime\n  \n}\n\n[1] \"../data-firstbanch/001SSMS_entire_exp_2022-05-31_18h24.17.csv\"\n[1] \"../data-firstbanch/003SSKS_entire_exp_2022-06-16_20h02.35.389.csv\"\n[1] \"../data-firstbanch/004SSDR_entire_exp_2022-06-02_21h35.09.567.csv\"\n[1] \"../data-firstbanch/005SSDR_entire_exp_2022-05-31_20h43.50.910.csv\"\n[1] \"../data-firstbanch/006SSEE_entire_exp_2022-06-02_22h14.18.092.csv\"\n[1] \"../data-firstbanch/007SSJM_entire_exp_2022-06-01_15h12.27.341.csv\"\n[1] \"../data-firstbanch/008SSEP_entire_exp_2022-09-15_21h36.55.631.csv\"\n[1] \"../data-firstbanch/009SSAP_entire_exp_2022-06-04_15h48.30.436.csv\"\n[1] \"../data-firstbanch/010SSEA_entire_exp_2022-06-07_24h08.05.064.csv\"\n[1] \"../data-firstbanch/011SSAB_entire_exp_2022-06-01_14h54.48.csv\"\n[1] \"../data-firstbanch/012EROP_entire_exp_2022-07-14_20h26.20.219.csv\"\n[1] \"../data-firstbanch/013ERVB_entire_exp_2022-06-23_15h53.22.750.csv\"\n[1] \"../data-firstbanch/014ERAI_entire_exp_2022-06-16_13h57.46.683.csv\"\n[1] \"../data-firstbanch/015ERIG_entire_exp_2022-08-17_23h56.01.csv\"\n[1] \"../data-firstbanch/016ERSA_entire_exp_2022-06-16_14h19.07.981.csv\"\n[1] \"../data-firstbanch/017ERVZ_entire_exp_2022-08-20_16h11.35.184.csv\"\n[1] \"../data-firstbanch/019ERSM_entire_exp_2022-06-18_21h43.19.372.csv\"\n[1] \"../data-firstbanch/021SSAZ_entire_exp_2022-07-15_03h19.45.491.csv\"\n[1] \"../data-firstbanch/022ERVS_entire_exp_2022-07-15_21h42.11.588.csv\"\n[1] \"../data-firstbanch/023ERRS_entire_exp_2022-07-11_18h59.41.csv\"\n[1] \"../data-firstbanch/024SSSV_entire_exp_2022-07-24_18h50.18.841.csv\"\n[1] \"../data-firstbanch/025ARAS_entire_exp_2023-05-02_19h18.58.479.csv\"\n[1] \"../data-firstbanch/026SSDM_entire_exp_2022-07-16_12h26.44.968.csv\"\n[1] \"../data-firstbanch/027ARDB_entire_exp_2022-07-18_10h37.13.819.csv\"\n[1] \"../data-firstbanch/029SSDL_entire_exp_2022-07-16_09h09.20.517.csv\"\n[1] \"../data-firstbanch/030SSPM_entire_exp_2022-08-17_21h31.18.058.csv\"\n[1] \"../data-firstbanch/031SSAS_entire_exp_2022-07-16_08h00.03.221.csv\"\n[1] \"../data-firstbanch/032SSAP_entire_exp_2022-07-17_13h28.21.518.csv\"\n[1] \"../data-firstbanch/033SSML_entire_exp_2022-07-26_18h52.18.365.csv\"\n[1] \"../data-firstbanch/035SSDD_entire_exp_2022-08-14_12h43.23.036.csv\"\n[1] \"../data-firstbanch/037ARDL_entire_exp_2022-07-16_22h20.51.764.csv\"\n[1] \"../data-firstbanch/038AREN_entire_exp_2022-07-19_11h25.52.006.csv\"\n[1] \"../data-firstbanch/039ARVP_entire_exp_2022-08-08_15h15.43.173.csv\"\n[1] \"../data-firstbanch/040ARKK_entire_exp_2023-04-23_17h12.22.533.csv\"\n[1] \"../data-firstbanch/042SSAA_entire_exp_2022-08-17_14h03.26.713.csv\"\n[1] \"../data-firstbanch/045SSEM_entire_exp_2022-08-17_14h07.54.819.csv\"\n[1] \"../data-firstbanch/046SSVS_entire_exp_2022-08-20_13h21.07.492.csv\"\n[1] \"../data-firstbanch/047SSAK_entire_exp_2022-08-20_23h14.23.266.csv\"\n[1] \"../data-firstbanch/048SSAG_entire_exp_2022-08-18_20h28.36.828.csv\"\n[1] \"../data-firstbanch/050SSAA_entire_exp_2023-04-21_13h38.45.765.csv\"\n[1] \"../data-firstbanch/052SSME_entire_exp_2022-08-26_10h32.55.991.csv\"\n[1] \"../data-firstbanch/053SSAF_entire_exp_2022-08-25_21h56.58.660.csv\"\n[1] \"../data-firstbanch/054SSEB_entire_exp_2022-08-25_18h20.01.028.csv\"\n[1] \"../data-firstbanch/055SSNS_entire_exp_2022-08-27_10h54.17.951.csv\"\n[1] \"../data-firstbanch/056SSKA_entire_exp_2022-08-26_10h55.02.575.csv\"\n[1] \"../data-firstbanch/058SSAB_entire_exp_2022-09-01_19h07.29.229.csv\"\n[1] \"../data-firstbanch/059SSAS_entire_exp_2022-08-28_11h50.43.886.csv\"\n[1] \"../data-firstbanch/062SSON_entire_exp_2022-09-03_18h24.04.978.csv\"\n[1] \"../data-firstbanch/063SSMP_entire_exp_2022-08-31_09h41.09.233.csv\"\n[1] \"../data-firstbanch/064SSAB_entire_exp_2022-09-09_24h56.58.121.csv\"\n[1] \"../data-firstbanch/065SSTM_entire_exp_2022-09-08_13h04.21.029.csv\"\n[1] \"../data-firstbanch/066SSKA_entire_exp_2023-04-20_19h55.36.813.csv\"\n[1] \"../data-firstbanch/067SSDA_entire_exp_2022-09-08_15h14.26.648.csv\"\n[1] \"../data-firstbanch/068SSMT_entire_exp_2022-09-08_14h02.24.512.csv\"\n[1] \"../data-firstbanch/069SSMV_entire_exp_2022-09-09_15h05.56.561.csv\"\n[1] \"../data-firstbanch/070SSAK_entire_exp_2022-09-08_15h22.31.854.csv\"\n[1] \"../data-firstbanch/071SSEB_entire_exp_2022-09-13_13h34.34.403.csv\"\n[1] \"../data-firstbanch/073SSMS_entire_exp_2022-09-17_12h41.16.219.csv\"\n[1] \"../data-firstbanch/074SSKS_entire_exp_2022-09-09_08h40.26.331.csv\"\n[1] \"../data-firstbanch/076SSRK_entire_exp_2022-09-10_24h29.10.709.csv\"\n[1] \"../data-firstbanch/077SSKK_entire_exp_2022-09-09_18h47.59.035.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2022-09-18_20h01.24.482.csv\"\n[1] \"../data-firstbanch/079SSRR_entire_exp_2023-04-23_12h12.09.879.csv\"\n[1] \"../data-firstbanch/080SSAF_entire_exp_2022-09-09_18h48.13.239.csv\"\n[1] \"../data-firstbanch/083SSAN_entire_exp_2022-09-10_09h01.25.268.csv\"\n[1] \"../data-firstbanch/086SSAI_entire_exp_2022-09-09_19h50.26.340.csv\"\n[1] \"../data-firstbanch/087SSVC_entire_exp_2022-09-17_17h38.47.991.csv\"\n[1] \"../data-firstbanch/088SSDR_entire_exp_2022-09-16_17h28.38.834.csv\"\n[1] \"../data-firstbanch/089SSDM_entire_exp_2023-04-25_14h12.30.529.csv\"\n[1] \"../data-firstbanch/091SSJP_entire_exp_2022-09-14_23h28.30.070.csv\"\n[1] \"../data-firstbanch/092SSAG_entire_exp_2022-09-10_16h20.00.504.csv\"\n[1] \"../data-firstbanch/093SSEG_entire_exp_2022-09-14_17h20.12.899.csv\"\n[1] \"../data-firstbanch/095SSVH_entire_exp_2022-09-15_24h16.25.521.csv\"\n[1] \"../data-firstbanch/096SSMR_entire_exp_2023-05-06_17h41.53.790.csv\"\n[1] \"../data-firstbanch/098SSDM_entire_exp_2023-04-23_16h09.02.953.csv\"\n[1] \"../data-firstbanch/099SSDA_entire_exp_04-20-2023_18h41.33.261.csv\"\n[1] \"../data-firstbanch/100SSNT_entire_exp_2023-04-25_13h53.44.583.csv\"\n[1] \"../data-firstbanch/101SSOK_entire_exp_2023-04-25_15h56.39.280.csv\"\n\n\n\nexptime |&gt; \n  mutate(dur = abs(start - end)) -&gt; exptime"
  },
  {
    "objectID": "preprocess.html#create-and-add-ids",
    "href": "preprocess.html#create-and-add-ids",
    "title": "First Banch Preprocess Workflow",
    "section": "",
    "text": "set.seed(123)\ntibble(\n  file = exptime$file,\n  id = stringi::stri_rand_strings(length(exptime$file), 10)) -&gt; IDS\n\n\nMR_data |&gt; select(-id) |&gt; full_join(IDS, by = \"file\") -&gt; MR_data\nST_data |&gt; select(-id) |&gt; full_join(IDS, by = \"file\") -&gt; ST_data\nMS_data |&gt; select(-id) |&gt; full_join(IDS, by = \"file\") -&gt; MS_data\nNASATLX_data |&gt; select(-id) |&gt; full_join(IDS, by = \"file\") -&gt; NASATLX_data\nSEQUENCE_data |&gt; select(-id) |&gt; full_join(IDS, by = \"file\") -&gt; SEQUENCE_data\nexptime |&gt; full_join(IDS, by = \"file\") -&gt; exptime"
  },
  {
    "objectID": "preprocess.html#save-preprocessed-data",
    "href": "preprocess.html#save-preprocessed-data",
    "title": "First Banch Preprocess Workflow",
    "section": "",
    "text": "MR_data |&gt; select(-file) |&gt; write_csv(\"MR_firstbanch_data.csv\")\nST_data |&gt; select(-file) |&gt; write_csv(\"ST_firstbanch_data.csv\")\nMS_data |&gt; select(-file) |&gt; write_csv(\"MS_firstbanch_data.csv\")\nNASATLX_data |&gt; select(-file) |&gt; write_csv(\"NASATLX_firstbanch_data.csv\")\nSEQUENCE_data |&gt; select(-file) |&gt; write_csv(\"SEQ_firstbanch_data.csv\")\nexptime |&gt; select(-file) |&gt; write_csv(\"EXPTIME_firstbanch_data.csv\")\nIDS |&gt; write_csv(\"IDS_firstbanch_data.csv\")"
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "knitr::opts_chunk$set(error = TRUE)\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ntheme_set(theme_bw()) # set black and white theme\nlibrary(lavaan)\n\nThis is lavaan 0.6-15\nlavaan is FREE software! Please report any bugs.\n\nlibrary(tidySEM)\n\nLoading required package: OpenMx\nOpenMx may run faster if it is compiled to take advantage of multiple cores.\nRegistered S3 method overwritten by 'tidySEM':\n  method          from  \n  predict.MxModel OpenMx\n\nlibrary(semPower)\n\n\n### Welcome to semPower 1.2.0 ###\n\nSee https://github.com/moshagen/semPower for quick examples and a detailed manual.\n\nPlease cite as:\nMoshagen, M., & Erdfelder, E. (2016). A new strategy for testing structural equation models.\nStructural Equation Modeling, 23, 54-60. doi: 10.1080/10705511.2014.950896\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:OpenMx':\n\n    %&%, expm\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(lmerTest)\n\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(MuMIn)\n\nError in library(MuMIn): there is no package called 'MuMIn'\n\nlibrary(pwr)\n\nError in library(pwr): there is no package called 'pwr'\n\n\n\nrm(list = ls())\n\n\n\n\n\nMR_data <- read_csv(\"MR_firstbanch_data.csv\")\n\nRows: 3744 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): correctAns, base_pic, rotated_pic, key, task, level, id\ndbl (3): is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nST_data <- read_csv(\"ST_firstbanch_data.csv\")\n\nRows: 3744 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): key, task, level, id\ndbl (4): target_present, is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nMS_data <- read_csv(\"MS_firstbanch_data.csv\")\n\nRows: 3744 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (4): trials, n, rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nNASATLX_data <- read_csv(\"NASATLX_firstbanch_data.csv\")\n\nRows: 4212 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): scale, task, level, id\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nSEQUENCE_data <- read_csv(\"SEQ_firstbanch_data.csv\")\n\nRows: 702 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, task, id\ndbl (1): order\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nEXPTIME <- read_csv(\"EXPTIME_firstbanch_data.csv\")\n\nRows: 78 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): id\ndbl  (1): dur\ndttm (2): start, end\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nEXPTIME |> ggplot(aes(dur)) +\n  geom_density()\n\nWarning: Removed 1 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\nEXPTIME |> \n  filter(dur < 250) |> \n  ggplot(aes(dur)) +\n  # geom_density() +\n  geom_histogram() +\n  geom_vline(xintercept = 70) +\n  geom_vline(xintercept = 75) +\n  geom_vline(xintercept = 100)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nEXPTIME |> \n  filter(dur < 250) |> \n  ggplot(aes(dur)) +\n  geom_boxplot() \n\n\n\n  #geom_vline(xintercept = 93, linetype = \"dashed\")\n\n\nEXPTIME$dur |> min(na.rm = TRUE)\n\n[1] 77.99356\n\nquantile(EXPTIME$dur[EXPTIME$dur<250], .75, na.rm = TRUE) + 1.5 * IQR(EXPTIME$dur[EXPTIME$dur<250], na.rm = TRUE)\n\n     75% \n94.32646 \n\n\n\n\n\n\n\n\nMR_data |> \n  group_by(id, level, task) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> MR_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMR_data_agg |> write_csv(\"MR_firstbanch_data_agg.csv\")\n\n\nMR_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  <chr>  <chr> <int> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 easy   MR       78  7.11  4.56  1.43  25.5     6.10     8.12\n2 hard   MR       78 12.0  10.3   1.60  69.1     9.67    14.2 \n3 medium MR       78  8.79  5.88  1.10  37.1     7.49    10.1 \n\n\n\nMR_data_agg |> \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, rt)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  <chr>  <chr> <int> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 easy   MR       78 0.850 0.174 0.312     1    0.812    0.889\n2 hard   MR       78 0.721 0.178 0.312     1    0.682    0.761\n3 medium MR       78 0.755 0.178 0.25      1    0.715    0.794\n\n\n\nMR_data_agg |> \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, acc)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\n\n\n\n\n\n\nMS_data |> \n  group_by(id, level, task) |> \n  summarise(rt = mean(rt),\n            acc = mean(acc)) -> MS_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMS_data_agg |> write_csv(\"MS_firstbanch_data_agg.csv\")\n\n\nMS_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt, na.rm = TRUE),\n            sd = sd(rt, na.rm = TRUE),\n            min = min(rt, na.rm = TRUE),\n            max = max(rt, na.rm = TRUE),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  <chr>  <chr> <int> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 easy   MS       78  11.7  5.72  5.47  46.8     10.4     13.0\n2 hard   MS       78  22.7 11.8  11.2   91.0     20.1     25.4\n3 medium MS       78  19.1  5.79 10.1   39.9     17.8     20.4\n\n\n\nMS_data_agg |> \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, rt)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  <chr>  <chr> <int> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 easy   MS       78 0.949 0.165     0 1        0.913    0.986\n2 hard   MS       78 0.635 0.168     0 0.973    0.597    0.672\n3 medium MS       78 0.878 0.172     0 1        0.839    0.916\n\n\n\nMS_data_agg |> \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, acc)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\n\n\n\n\n\n\n\nST_data |> \n  group_by(id, level, task) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> ST_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nST_data_agg |> write_csv(\"ST_firstbanch_data_agg.csv\")\n\n\nST_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  <chr>  <chr> <int> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 easy   ST       78  1.12 0.325 0.627  2.47     1.05     1.19\n2 hard   ST       78  1.44 0.441 0.737  3.52     1.34     1.54\n3 medium ST       78  1.39 0.470 0.692  3.45     1.28     1.49\n\n\n\nST_data_agg |> \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, rt)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean     sd   min   max CI_lower CI_upper\n  <chr>  <chr> <int> <dbl>  <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 easy   ST       78 0.979 0.0358 0.875 1        0.971    0.987\n2 hard   ST       78 0.686 0.127  0.312 0.875    0.658    0.714\n3 medium ST       78 0.836 0.114  0.562 1        0.811    0.861\n\n\n\nST_data_agg |> \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, acc)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\n\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) |>\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, rt)) +\n  facet_wrap(~ task, scales = \"free_y\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"Reaction Time\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) |>\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, acc)) +\n  facet_wrap(~ task, scales = \"free_y\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"Accuracy\")\n\n\n\n\n\n\n\n\n\nNASATLX_data |> \n  # fix factor\n  mutate(\n    level = factor(\n      level,\n      levels = c(\"easy\", \"medium\", \"hard\"),\n      ordered = TRUE\n    ),\n    # modify vars to match with previously created encoding\n    scl = str_to_lower(scale),\n    tsk = str_to_lower(task),\n    lvl = str_sub(level, start = 1, end = 1) |> str_to_upper(),\n    score = score * 5\n  ) |>\n  # create a new var for CFA\n  unite(item, scl, tsk, lvl) -> NASATLX_data\n\n\nlevel_colors <- c(\"#4bd752\", \"#d7984b\", \"#d7524b\")\ntask_colors <- c(\"red4\", \"green4\", \"blue4\")\nback_histogram_color <- \"gray60\"\n\n\nNASATLX_data |>\n  ggplot(aes(scale, score, fill = level)) +\n  geom_boxplot() +\n  facet_grid(task ~ .) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_fill_manual(values = level_colors)\n\nWarning: Removed 17 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\npd <- position_dodge(0.3)\nNASATLX_data |>\n  ggplot(aes(scale, score, color = level)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n  facet_grid(task ~ .) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_color_manual(values = level_colors)\n\nWarning: Removed 17 rows containing non-finite values (`stat_summary()`).\nRemoved 17 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\n\n\nNASATLX_data |> \n  select(-item) |> \n  # mutate(row_nubmer = row_number()) |> \n  pivot_wider(values_from = score, names_from = scale) -> nasa_tlx_wide\n# NASA_TLX |> group_by(task, level) |> summarise(n=n())\n# nasa_tlx_wide |> group_by(task, level) |> summarise(n=n())\n\n\nr2tof2 <- function(r2) r2 / (1 - r2)\n\n\n\n\nmix_ME <- lmer(ME ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ME)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ME ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6090.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1846 -0.5810  0.0514  0.6403  3.1496 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 172.8    13.14   \n Residual             300.2    17.33   \nNumber of obs: 701, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          46.445      2.463 335.008  18.861  < 2e-16 ***\ntaskMS              -16.813      2.774 615.020  -6.060 2.37e-09 ***\ntaskST              -18.655      2.774 615.020  -6.724 4.05e-11 ***\nlevelmedium          10.951      2.774 615.020   3.947 8.82e-05 ***\nlevelhard            19.777      2.774 615.020   7.128 2.86e-12 ***\ntaskMS:levelmedium   20.000      3.924 615.020   5.097 4.59e-07 ***\ntaskST:levelmedium   14.677      3.924 615.020   3.741 0.000201 ***\ntaskMS:levelhard     27.488      3.924 615.020   7.006 6.47e-12 ***\ntaskST:levelhard     20.282      3.931 615.107   5.160 3.34e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.563                                                             \ntaskST      -0.563  0.500                                                      \nlevelmedium -0.563  0.500  0.500                                               \nlevelhard   -0.563  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.398 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.398 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.398 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.398 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_ME)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask         6703    3352     2 615.06  11.165 1.727e-05 ***\nlevel      152214   76107     2 615.06 253.516 < 2.2e-16 ***\ntask:level  16928    4232     4 615.06  14.097 5.168e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ME)[1]\n\nError in r.squaredGLMM(mix_ME): could not find function \"r.squaredGLMM\"\n\nr2tof2(r.squaredGLMM(mix_ME)[1])\n\nError in r.squaredGLMM(mix_ME): could not find function \"r.squaredGLMM\"\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_ME)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\nError in pwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_ME)[1]), u = 7, sig.level = 0.05, : could not find function \"pwr.f2.test\"\n\n\n\n\n\n\nmix_PH <- lmer(PH ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PH)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PH ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 5661\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.5884 -0.5011 -0.0854  0.4111  5.0325 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 434.9    20.85   \n Residual             148.2    12.17   \nNumber of obs: 694, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)         17.0474     2.7392 127.9525   6.224 6.41e-09 ***\ntaskMS              -3.0090     1.9782 608.2281  -1.521  0.12875    \ntaskST              -5.6698     1.9562 608.0818  -2.898  0.00389 ** \nlevelmedium          0.8142     1.9562 608.0818   0.416  0.67740    \nlevelhard            5.5848     1.9562 608.0818   2.855  0.00445 ** \ntaskMS:levelmedium   8.9361     2.7821 608.1575   3.212  0.00139 ** \ntaskST:levelmedium   8.8358     2.7666 608.0868   3.194  0.00148 ** \ntaskMS:levelhard     7.8940     2.7860 608.1309   2.833  0.00476 ** \ntaskST:levelhard     7.7832     2.7615 608.0620   2.818  0.00498 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.356                                                             \ntaskST      -0.360  0.498                                                      \nlevelmedium -0.360  0.498  0.504                                               \nlevelhard   -0.360  0.498  0.504  0.504                                        \ntskMS:lvlmd  0.253 -0.711 -0.354 -0.703 -0.354                                 \ntskST:lvlmd  0.254 -0.352 -0.707 -0.707 -0.356  0.497                          \ntskMS:lvlhr  0.253 -0.709 -0.354 -0.354 -0.702  0.504      0.250               \ntskST:lvlhr  0.255 -0.353 -0.708 -0.357 -0.708  0.251      0.501      0.497    \n\nanova(mix_PH)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask        1087.1   543.6     2 608.13  3.6685  0.026080 *  \nlevel      13744.9  6872.5     2 608.10 46.3819 < 2.2e-16 ***\ntask:level  2422.0   605.5     4 608.12  4.0865  0.002816 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PH)[1]\n\nError in r.squaredGLMM(mix_PH): could not find function \"r.squaredGLMM\"\n\nr2tof2(r.squaredGLMM(mix_PH)[1])\n\nError in r.squaredGLMM(mix_PH): could not find function \"r.squaredGLMM\"\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PH)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\nError in pwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PH)[1]), u = 7, sig.level = 0.05, : could not find function \"pwr.f2.test\"\n\n\n\n\n\n\nmix_TI <- lmer(TI ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_TI)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: TI ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6223.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0957 -0.5892 -0.0314  0.6288  2.8906 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 160.6    12.67   \n Residual             373.7    19.33   \nNumber of obs: 701, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)         15.5984     2.6173 401.8373   5.960 5.53e-09 ***\ntaskMS               3.5592     3.0955 614.9845   1.150 0.250661    \ntaskST              11.3673     3.0955 614.9845   3.672 0.000261 ***\nlevelmedium          0.7836     3.0955 614.9845   0.253 0.800248    \nlevelhard            4.1863     3.0955 614.9845   1.352 0.176739    \ntaskMS:levelmedium  32.1104     4.3776 614.9845   7.335 7.02e-13 ***\ntaskST:levelmedium  33.6197     4.3854 615.0938   7.666 6.94e-14 ***\ntaskMS:levelhard    51.4924     4.3776 614.9845  11.763  < 2e-16 ***\ntaskST:levelhard    50.8953     4.3776 614.9845  11.626  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.591                                                             \ntaskST      -0.591  0.500                                                      \nlevelmedium -0.591  0.500  0.500                                               \nlevelhard   -0.591  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.418 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.417 -0.353 -0.706 -0.706 -0.353  0.499                          \ntskMS:lvlhr  0.418 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.418 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_TI)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask       203830  101915     2 615.03 272.724 < 2.2e-16 ***\nlevel      173710   86855     2 615.03 232.424 < 2.2e-16 ***\ntask:level  70059   17515     4 615.03  46.869 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_TI)[1]\n\nError in r.squaredGLMM(mix_TI): could not find function \"r.squaredGLMM\"\n\nr2tof2(r.squaredGLMM(mix_TI)[1])\n\nError in r.squaredGLMM(mix_TI): could not find function \"r.squaredGLMM\"\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_TI)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\nError in pwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_TI)[1]), u = 7, sig.level = 0.05, : could not find function \"pwr.f2.test\"\n\n\n\n\n\n\nmix_PE <- lmer(PE ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PE)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PE ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6076.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3961 -0.6412  0.0325  0.6477  2.5583 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 113.9    10.67   \n Residual             306.0    17.49   \nNumber of obs: 701, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          66.615      2.320 435.796  28.711  < 2e-16 ***\ntaskMS               25.479      2.801 615.017   9.096  < 2e-16 ***\ntaskST               23.503      2.801 615.017   8.391 3.31e-16 ***\nlevelmedium          -8.781      2.801 615.017  -3.135   0.0018 ** \nlevelhard           -16.480      2.801 615.017  -5.884 6.60e-09 ***\ntaskMS:levelmedium  -17.419      3.961 615.017  -4.397 1.29e-05 ***\ntaskST:levelmedium  -28.291      3.961 615.017  -7.142 2.61e-12 ***\ntaskMS:levelhard    -39.938      3.961 615.017 -10.082  < 2e-16 ***\ntaskST:levelhard    -44.857      3.968 615.138 -11.304  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.604                                                             \ntaskST      -0.604  0.500                                                      \nlevelmedium -0.604  0.500  0.500                                               \nlevelhard   -0.604  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.427 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.427 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.427 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.426 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_PE)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask         7295    3647     2 615.07  11.921  8.33e-06 ***\nlevel      234141  117070     2 615.07 382.616 < 2.2e-16 ***\ntask:level  49094   12273     4 615.07  40.113 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PE)[1]\n\nError in r.squaredGLMM(mix_PE): could not find function \"r.squaredGLMM\"\n\nr2tof2(r.squaredGLMM(mix_PE)[1])\n\nError in r.squaredGLMM(mix_PE): could not find function \"r.squaredGLMM\"\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PE)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\nError in pwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PE)[1]), u = 7, sig.level = 0.05, : could not find function \"pwr.f2.test\"\n\n\n\n\n\n\nmix_EF <- lmer(EF ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_EF)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6055.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1279 -0.6094  0.0357  0.6249  3.5591 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 249.8    15.81   \n Residual             276.8    16.64   \nNumber of obs: 700, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          44.381      2.598 247.283  17.080  < 2e-16 ***\ntaskMS              -12.862      2.664 614.020  -4.828 1.74e-06 ***\ntaskST              -11.609      2.664 614.020  -4.358 1.54e-05 ***\nlevelmedium           9.006      2.664 614.020   3.381 0.000769 ***\nlevelhard            17.584      2.664 614.020   6.601 8.86e-11 ***\ntaskMS:levelmedium   17.979      3.774 614.080   4.764 2.38e-06 ***\ntaskST:levelmedium   13.621      3.774 614.080   3.609 0.000333 ***\ntaskMS:levelhard     25.250      3.767 614.020   6.702 4.65e-11 ***\ntaskST:levelhard     14.255      3.767 614.020   3.784 0.000170 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.513                                                             \ntaskST      -0.513  0.500                                                      \nlevelmedium -0.513  0.500  0.500                                               \nlevelhard   -0.513  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.362 -0.706 -0.353 -0.706 -0.353                                 \ntskST:lvlmd  0.362 -0.353 -0.706 -0.706 -0.353  0.498                          \ntskMS:lvlhr  0.362 -0.707 -0.354 -0.354 -0.707  0.499      0.250               \ntskST:lvlhr  0.362 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_EF)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF  F value    Pr(>F)    \ntask         1763     881     2 614.07   3.1842    0.0421 *  \nlevel      113335   56667     2 614.07 204.7413 < 2.2e-16 ***\ntask:level  13748    3437     4 614.07  12.4179 1.018e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_EF)[1]\n\nError in r.squaredGLMM(mix_EF): could not find function \"r.squaredGLMM\"\n\nr2tof2(r.squaredGLMM(mix_EF)[1])\n\nError in r.squaredGLMM(mix_EF): could not find function \"r.squaredGLMM\"\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_EF)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\nError in pwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_EF)[1]), u = 7, sig.level = 0.05, : could not find function \"pwr.f2.test\"\n\n\n\n\n\n\nmix_FR <- lmer(FR ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_FR)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: FR ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6292.3\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.92494 -0.67440 -0.04275  0.63993  2.97611 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 343.0    18.52   \n Residual             402.2    20.05   \nNumber of obs: 698, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          35.058      3.091 256.301  11.342  < 2e-16 ***\ntaskMS              -11.619      3.235 612.136  -3.592 0.000355 ***\ntaskST              -13.828      3.211 611.853  -4.306 1.94e-05 ***\nlevelmedium           6.322      3.211 611.853   1.969 0.049432 *  \nlevelhard            12.950      3.223 611.978   4.018 6.59e-05 ***\ntaskMS:levelmedium   13.354      4.558 611.995   2.930 0.003518 ** \ntaskST:levelmedium   20.118      4.541 611.853   4.430 1.12e-05 ***\ntaskMS:levelhard     23.420      4.566 612.053   5.129 3.92e-07 ***\ntaskST:levelhard     30.659      4.558 611.996   6.727 4.00e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.516                                                             \ntaskST      -0.519  0.496                                                      \nlevelmedium -0.519  0.496  0.500                                               \nlevelhard   -0.518  0.495  0.498  0.498                                        \ntskMS:lvlmd  0.366 -0.710 -0.352 -0.705 -0.351                                 \ntskST:lvlmd  0.367 -0.351 -0.707 -0.707 -0.352  0.498                          \ntskMS:lvlhr  0.365 -0.708 -0.352 -0.352 -0.706  0.503      0.249               \ntskST:lvlhr  0.366 -0.349 -0.705 -0.352 -0.707  0.248      0.498      0.499    \n\nanova(mix_FR)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF  F value    Pr(>F)    \ntask         1246     623     2 611.95   1.5486    0.2134    \nlevel      111859   55929     2 611.94 139.0640 < 2.2e-16 ***\ntask:level  20526    5131     4 612.00  12.7589 5.569e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_FR)[1]\n\nError in r.squaredGLMM(mix_FR): could not find function \"r.squaredGLMM\"\n\nr2tof2(r.squaredGLMM(mix_FR)[1])\n\nError in r.squaredGLMM(mix_FR): could not find function \"r.squaredGLMM\"\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_FR)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\nError in pwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_FR)[1]), u = 7, sig.level = 0.05, : could not find function \"pwr.f2.test\"\n\n\n\n\n\n\n\nlavmodel <- \"\nPE =~ PE_mr + PE_ms + PE_st\nME =~ ME_mr + ME_ms + ME_st\nPH =~ PH_mr + PH_ms + PH_st\nEF =~ EF_mr + EF_ms + EF_st\nTI =~ TI_mr + TI_ms + TI_st\nFR =~ FR_mr + FR_ms + FR_st\nOW =~ PE + ME + PH + EF + TI + FR\"\n\n\nsemPower.getDf(lavmodel)\n\n[1] 129\n\n\n\nap <- semPower.aPriori(effect = .05, effect.measure = 'RMSEA',\n                       alpha = .05, power = .80, df = semPower.getDf(lavmodel))\nsummary(ap)\n\n\n semPower: A-priori power analysis\n                                   \n F0                        0.322500\n RMSEA                     0.050000\n Mc                        0.851079\n                                   \n df                        129     \n Required Num Observations 142     \n                                   \n Critical Chi-Square       156.5075\n NCP                       45.47250\n Alpha                     0.050000\n Beta                      0.198348\n Power (1-beta)            0.801652\n Implied Alpha/Beta Ratio  0.252082\n\n\n\n\n\n\n\n\n\nNASATLX_data |> \n  pivot_wider(id_cols = id, \n              names_from = item, \n              values_from = score,\n              values_fn = unlist) -> NASATLX_cfa\n\n\n\n\n\nmodel1 <- \"PE =~ pe_st_E + pe_st_M + pe_st_H + pe_mr_E + pe_mr_M + pe_mr_H + pe_ms_E + pe_ms_M + pe_ms_H\nME =~ me_st_E + me_st_M + me_st_H + me_mr_E + me_mr_M + me_mr_H + me_ms_E + me_ms_M + me_ms_H\nPH =~ ph_st_E + ph_st_M + ph_st_H + ph_mr_E + ph_mr_M + ph_mr_H + ph_ms_E + ph_ms_M + ph_ms_H\nEF =~ ef_st_E + ef_st_M + ef_st_H + ef_mr_E + ef_mr_M + ef_mr_H + ef_ms_E + ef_ms_M + ef_ms_H\nTI =~ ti_st_E + ti_st_M + ti_st_H + ti_mr_E + ti_mr_M + ti_mr_H + ti_ms_E + ti_ms_M + ti_ms_H\nFR =~ fr_st_E + fr_st_M + fr_st_H + fr_mr_E + fr_mr_M + fr_mr_H + fr_ms_E + fr_ms_M + fr_ms_H\nOW =~ PE + ME + PH + EF + TI + FR\"\n\n\ncfa1 <- cfa(model1, NASATLX_cfa)\n\nWarning in lav_object_post_check(object): lavaan WARNING: some estimated lv\nvariances are negative\n\nsummary(cfa1, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 455 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                       114\n\n                                                  Used       Total\n  Number of observations                            67          78\n\nModel Test User Model:\n                                                      \n  Test statistic                              3660.590\n  Degrees of freedom                              1371\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              5450.455\n  Degrees of freedom                              1431\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.430\n  Tucker-Lewis Index (TLI)                       0.405\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -15485.621\n  Loglikelihood unrestricted model (H1)     -13655.326\n                                                      \n  Akaike (AIC)                               31199.242\n  Bayesian (BIC)                             31450.577\n  Sample-size adjusted Bayesian (SABIC)      31091.632\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.158\n  90 Percent confidence interval - lower         0.152\n  90 Percent confidence interval - upper         0.164\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.152\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  PE =~                                               \n    pe_st_E           1.000                           \n    pe_st_M           2.255    0.980    2.301    0.021\n    pe_st_H           0.883    0.658    1.342    0.180\n    pe_mr_E           3.979    1.469    2.709    0.007\n    pe_mr_M           4.586    1.672    2.743    0.006\n    pe_mr_H           4.053    1.464    2.769    0.006\n    pe_ms_E           1.025    0.537    1.910    0.056\n    pe_ms_M           1.643    0.922    1.781    0.075\n    pe_ms_H           1.434    0.776    1.848    0.065\n  ME =~                                               \n    me_st_E           1.000                           \n    me_st_M           1.013    0.263    3.850    0.000\n    me_st_H           0.958    0.292    3.280    0.001\n    me_mr_E           1.566    0.351    4.466    0.000\n    me_mr_M           1.330    0.303    4.391    0.000\n    me_mr_H           1.032    0.263    3.920    0.000\n    me_ms_E           0.991    0.257    3.856    0.000\n    me_ms_M           1.180    0.291    4.053    0.000\n    me_ms_H           0.877    0.218    4.023    0.000\n  PH =~                                               \n    ph_st_E           1.000                           \n    ph_st_M           1.992    0.249    8.007    0.000\n    ph_st_H           2.349    0.260    9.027    0.000\n    ph_mr_E           1.971    0.211    9.328    0.000\n    ph_mr_M           1.988    0.222    8.971    0.000\n    ph_mr_H           2.338    0.263    8.880    0.000\n    ph_ms_E           1.450    0.182    7.961    0.000\n    ph_ms_M           2.179    0.241    9.046    0.000\n    ph_ms_H           2.642    0.286    9.254    0.000\n  EF =~                                               \n    ef_st_E           1.000                           \n    ef_st_M           1.029    0.188    5.477    0.000\n    ef_st_H           0.877    0.199    4.410    0.000\n    ef_mr_E           1.178    0.216    5.445    0.000\n    ef_mr_M           1.173    0.217    5.411    0.000\n    ef_mr_H           0.841    0.180    4.660    0.000\n    ef_ms_E           1.157    0.197    5.859    0.000\n    ef_ms_M           1.158    0.194    5.975    0.000\n    ef_ms_H           0.712    0.151    4.719    0.000\n  TI =~                                               \n    ti_st_E           1.000                           \n    ti_st_M           0.882    0.419    2.105    0.035\n    ti_st_H           0.594    0.371    1.601    0.109\n    ti_mr_E           1.667    0.432    3.861    0.000\n    ti_mr_M           1.465    0.378    3.876    0.000\n    ti_mr_H           1.547    0.415    3.730    0.000\n    ti_ms_E           1.382    0.399    3.466    0.001\n    ti_ms_M           0.987    0.418    2.362    0.018\n    ti_ms_H           0.650    0.360    1.805    0.071\n  FR =~                                               \n    fr_st_E           1.000                           \n    fr_st_M           1.716    0.355    4.837    0.000\n    fr_st_H           1.463    0.343    4.265    0.000\n    fr_mr_E           1.547    0.349    4.436    0.000\n    fr_mr_M           1.840    0.393    4.685    0.000\n    fr_mr_H           1.672    0.356    4.695    0.000\n    fr_ms_E           1.234    0.307    4.026    0.000\n    fr_ms_M           1.651    0.341    4.838    0.000\n    fr_ms_H           1.556    0.338    4.606    0.000\n  OW =~                                               \n    PE                1.000                           \n    ME              128.381  914.645    0.140    0.888\n    PH               77.803  554.331    0.140    0.888\n    EF              186.293 1327.040    0.140    0.888\n    TI               59.585  424.836    0.140    0.888\n    FR               91.614  652.834    0.140    0.888\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .pe_st_E         124.591   22.092    5.640    0.000\n   .pe_st_M         361.285   65.373    5.527    0.000\n   .pe_st_H         354.264   61.638    5.747    0.000\n   .pe_mr_E         244.581   54.022    4.527    0.000\n   .pe_mr_M         244.480   59.972    4.077    0.000\n   .pe_mr_H         133.027   39.392    3.377    0.001\n   .pe_ms_E         168.410   29.687    5.673    0.000\n   .pe_ms_M         548.307   96.241    5.697    0.000\n   .pe_ms_H         369.741   65.033    5.685    0.000\n   .me_st_E         245.268   45.144    5.433    0.000\n   .me_st_M         287.394   52.463    5.478    0.000\n   .me_st_H         442.050   78.816    5.609    0.000\n   .me_mr_E         350.656   67.808    5.171    0.000\n   .me_mr_M         277.611   53.108    5.227    0.000\n   .me_mr_H         278.281   51.010    5.455    0.000\n   .me_ms_E         273.701   49.982    5.476    0.000\n   .me_ms_M         317.793   58.786    5.406    0.000\n   .me_ms_H         180.945   33.398    5.418    0.000\n   .ph_st_E          72.731   13.064    5.567    0.000\n   .ph_st_M         187.008   34.332    5.447    0.000\n   .ph_st_H         118.723   23.571    5.037    0.000\n   .ph_mr_E          60.178   12.690    4.742    0.000\n   .ph_mr_M          89.689   17.669    5.076    0.000\n   .ph_mr_H         134.864   26.271    5.133    0.000\n   .ph_ms_E         102.020   18.696    5.457    0.000\n   .ph_ms_M         100.315   19.972    5.023    0.000\n   .ph_ms_H         118.111   24.450    4.831    0.000\n   .ef_st_E         239.012   44.587    5.361    0.000\n   .ef_st_M         235.841   44.255    5.329    0.000\n   .ef_st_H         366.863   65.803    5.575    0.000\n   .ef_mr_E         316.820   59.323    5.341    0.000\n   .ef_mr_M         322.696   60.292    5.352    0.000\n   .ef_mr_H         283.996   51.311    5.535    0.000\n   .ef_ms_E         219.092   42.458    5.160    0.000\n   .ef_ms_M         198.370   38.959    5.092    0.000\n   .ef_ms_H         195.545   35.398    5.524    0.000\n   .ti_st_E         341.022   60.770    5.612    0.000\n   .ti_st_M         729.668  127.474    5.724    0.000\n   .ti_st_H         661.912  114.995    5.756    0.000\n   .ti_mr_E          93.538   24.026    3.893    0.000\n   .ti_mr_M          64.491   17.520    3.681    0.000\n   .ti_mr_H         149.496   31.182    4.794    0.000\n   .ti_ms_E         243.719   45.882    5.312    0.000\n   .ti_ms_M         656.806  115.249    5.699    0.000\n   .ti_ms_H         590.417  102.767    5.745    0.000\n   .fr_st_E         237.844   44.183    5.383    0.000\n   .fr_st_M         339.631   68.622    4.949    0.000\n   .fr_st_H         470.206   87.896    5.350    0.000\n   .fr_mr_E         441.207   83.804    5.265    0.000\n   .fr_mr_M         472.552   92.733    5.096    0.000\n   .fr_mr_H         385.333   75.746    5.087    0.000\n   .fr_ms_E         421.392   77.461    5.440    0.000\n   .fr_ms_M         313.899   63.433    4.948    0.000\n   .fr_ms_H         369.805   71.717    5.156    0.000\n   .PE               18.314   13.071    1.401    0.161\n   .ME               20.134   13.400    1.502    0.133\n   .PH               76.958   20.526    3.749    0.000\n   .EF               -7.894   17.614   -0.448    0.654\n   .TI               70.275   36.871    1.906    0.057\n   .FR               84.756   33.213    2.552    0.011\n    OW                0.007    0.096    0.070    0.944\n\n\n\nmodel_easy <- \"PE =~ pe_mr_E + pe_ms_E + pe_st_E\nPH =~ ph_mr_E + ph_ms_E + ph_st_E\nME =~ me_mr_E + me_ms_E + me_st_E\nEF =~ ef_mr_E + ef_ms_E + ef_st_E\nTI =~ ti_mr_E + ti_ms_E + ti_st_E\nFR =~ fr_mr_E + fr_ms_E + fr_st_E\nOW =~ PE + ME + PH + EF + TI + FR\"\n\ncfa_easy <- cfa(model_easy, NASATLX_cfa,)\n\nWarning in lavaan::lavaan(model = model_easy, data = NASATLX_cfa, model.type = \"cfa\", : lavaan WARNING:\n    the optimizer warns that a solution has NOT been found!\n\nsummary(cfa_easy, fit.measures = TRUE)\n\nWarning in lav_object_summary(object = object, header = header, fit.measures = fit.measures, : lavaan WARNING: fit measures not available if model did not converge\n\n\nlavaan 0.6.15 did NOT end normally after 2260 iterations\n** WARNING ** Estimates below are most likely unreliable\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                            73          78\n\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate   Std.Err  z-value  P(>|z|)\n  PE =~                                                \n    pe_mr_E            1.000                           \n    pe_ms_E            1.310       NA                  \n    pe_st_E            1.213       NA                  \n  PH =~                                                \n    ph_mr_E            1.000                           \n    ph_ms_E            0.787       NA                  \n    ph_st_E            0.571       NA                  \n  ME =~                                                \n    me_mr_E            1.000                           \n    me_ms_E            1.094       NA                  \n    me_st_E            0.836       NA                  \n  EF =~                                                \n    ef_mr_E            1.000                           \n    ef_ms_E            1.217       NA                  \n    ef_st_E            0.984       NA                  \n  TI =~                                                \n    ti_mr_E            1.000                           \n    ti_ms_E            0.987       NA                  \n    ti_st_E            0.722       NA                  \n  FR =~                                                \n    fr_mr_E            1.000                           \n    fr_ms_E            1.461       NA                  \n    fr_st_E            0.989       NA                  \n  OW =~                                                \n    PE                 1.000                           \n    ME              2899.037       NA                  \n    PH                -0.158       NA                  \n    EF               -17.873       NA                  \n    TI                -6.829       NA                  \n    FR                 3.480       NA                  \n\nVariances:\n                   Estimate   Std.Err  z-value  P(>|z|)\n   .pe_mr_E          464.987       NA                  \n   .pe_ms_E           86.235       NA                  \n   .pe_st_E           63.481       NA                  \n   .ph_mr_E           95.968       NA                  \n   .ph_ms_E           87.338       NA                  \n   .ph_st_E           50.572       NA                  \n   .me_mr_E          449.647       NA                  \n   .me_ms_E          143.733       NA                  \n   .me_st_E          229.140       NA                  \n   .ef_mr_E          358.257       NA                  \n   .ef_ms_E          110.697       NA                  \n   .ef_st_E          195.518       NA                  \n   .ti_mr_E          148.921       NA                  \n   .ti_ms_E          216.321       NA                  \n   .ti_st_E          321.114       NA                  \n   .fr_mr_E          593.657       NA                  \n   .fr_ms_E          289.120       NA                  \n   .fr_st_E          214.943       NA                  \n   .PE                51.502       NA                  \n   .PH               400.229       NA                  \n   .ME             35192.656       NA                  \n   .EF               266.885       NA                  \n   .TI               201.642       NA                  \n   .FR               154.556       NA                  \n    OW                -0.004       NA                  \n\nfitmeasures(cfa_easy, fit.measures = c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\nError in lav_fit_measures(object = object, fit.measures = fit.measures, : lavaan ERROR: fit measures not available if model did not converge\n\n\n\nmodel_medium <- \"PE =~ pe_mr_M + pe_ms_M + pe_st_M\nPH =~ ph_mr_M + ph_ms_M + ph_st_M\nME =~ me_mr_M + me_ms_M + me_st_M\nEF =~ ef_mr_M + ef_ms_M + ef_st_M\nTI =~ ti_mr_M + ti_ms_M + ti_st_M\nFR =~ fr_mr_M + fr_ms_M + fr_st_M\nOW =~ PE + ME + PH + EF + TI + FR\"\n\ncfa_medium <- cfa(model_medium, NASATLX_cfa,)\n\nWarning in lav_object_post_check(object): lavaan WARNING: some estimated lv\nvariances are negative\n\nsummary(cfa_medium, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 493 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                            74          78\n\nModel Test User Model:\n                                                      \n  Test statistic                               414.017\n  Degrees of freedom                               129\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               937.686\n  Degrees of freedom                               153\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.637\n  Tucker-Lewis Index (TLI)                       0.569\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -5875.701\n  Loglikelihood unrestricted model (H1)      -5668.692\n                                                      \n  Akaike (AIC)                               11835.402\n  Bayesian (BIC)                             11932.173\n  Sample-size adjusted Bayesian (SABIC)      11799.815\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.173\n  90 Percent confidence interval - lower         0.154\n  90 Percent confidence interval - upper         0.192\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.141\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  PE =~                                               \n    pe_mr_M           1.000                           \n    pe_ms_M           0.685    0.401    1.711    0.087\n    pe_st_M           1.061    0.741    1.432    0.152\n  PH =~                                               \n    ph_mr_M           1.000                           \n    ph_ms_M           1.174    0.114   10.327    0.000\n    ph_st_M           1.135    0.115    9.872    0.000\n  ME =~                                               \n    me_mr_M           1.000                           \n    me_ms_M           1.701    0.463    3.672    0.000\n    me_st_M           1.058    0.345    3.071    0.002\n  EF =~                                               \n    ef_mr_M           1.000                           \n    ef_ms_M           1.508    0.289    5.214    0.000\n    ef_st_M           1.088    0.249    4.380    0.000\n  TI =~                                               \n    ti_mr_M           1.000                           \n    ti_ms_M           5.632    2.751    2.047    0.041\n    ti_st_M           3.908    2.027    1.928    0.054\n  FR =~                                               \n    fr_mr_M           1.000                           \n    fr_ms_M           1.332    0.271    4.921    0.000\n    fr_st_M           1.095    0.245    4.474    0.000\n  OW =~                                               \n    PE                1.000                           \n    ME               73.844 1151.565    0.064    0.949\n    PH               84.873 1323.482    0.064    0.949\n    EF              109.365 1705.387    0.064    0.949\n    TI               30.009  468.136    0.064    0.949\n    FR              113.058 1763.000    0.064    0.949\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .pe_mr_M         452.474  130.577    3.465    0.001\n   .pe_ms_M         511.248   98.015    5.216    0.000\n   .pe_st_M         263.411  128.374    2.052    0.040\n   .ph_mr_M         140.173   31.023    4.518    0.000\n   .ph_ms_M         104.826   32.777    3.198    0.001\n   .ph_st_M         142.456   35.272    4.039    0.000\n   .me_mr_M         402.103   68.867    5.839    0.000\n   .me_ms_M         236.209   58.827    4.015    0.000\n   .me_st_M         331.211   57.866    5.724    0.000\n   .ef_mr_M         437.092   74.252    5.887    0.000\n   .ef_ms_M         105.505   33.491    3.150    0.002\n   .ef_st_M         302.997   52.858    5.732    0.000\n   .ti_mr_M         242.309   39.894    6.074    0.000\n   .ti_ms_M         311.098   84.946    3.662    0.000\n   .ti_st_M         637.972  109.853    5.808    0.000\n   .fr_mr_M         633.851  114.284    5.546    0.000\n   .fr_ms_M         208.689   68.761    3.035    0.002\n   .fr_st_M         405.566   80.446    5.041    0.000\n   .PE              153.647  126.134    1.218    0.223\n   .PH              266.020   61.746    4.308    0.000\n   .ME                7.055   15.442    0.457    0.648\n   .EF              -12.589   15.004   -0.839    0.401\n   .TI               -1.186    2.460   -0.482    0.630\n   .FR              100.758   47.793    2.108    0.035\n    OW                0.017    0.536    0.032    0.974\n\nfitmeasures(cfa_medium, fit.measures = c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n  chisq      df  pvalue     cfi     tli   rmsea    srmr \n414.017 129.000   0.000   0.637   0.569   0.173   0.141 \n\n\n\nmodel_hard <- \"PE =~ pe_mr_H + pe_ms_H + pe_st_H\nPH =~ ph_mr_H + ph_ms_H + ph_st_H\nME =~ me_mr_H + me_ms_H + me_st_H\nEF =~ ef_mr_H + ef_ms_H + ef_st_H\nTI =~ ti_mr_H + ti_ms_H + ti_st_H\nFR =~ fr_mr_H + fr_ms_H + fr_st_H\nOW =~ PE + ME + PH + EF + TI + FR\"\n\ncfa_hard <- cfa(model_hard, NASATLX_cfa,)\n\nWarning in lav_object_post_check(object): lavaan WARNING: some estimated lv\nvariances are negative\n\nsummary(cfa_medium, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 493 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                            74          78\n\nModel Test User Model:\n                                                      \n  Test statistic                               414.017\n  Degrees of freedom                               129\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               937.686\n  Degrees of freedom                               153\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.637\n  Tucker-Lewis Index (TLI)                       0.569\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -5875.701\n  Loglikelihood unrestricted model (H1)      -5668.692\n                                                      \n  Akaike (AIC)                               11835.402\n  Bayesian (BIC)                             11932.173\n  Sample-size adjusted Bayesian (SABIC)      11799.815\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.173\n  90 Percent confidence interval - lower         0.154\n  90 Percent confidence interval - upper         0.192\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.141\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  PE =~                                               \n    pe_mr_M           1.000                           \n    pe_ms_M           0.685    0.401    1.711    0.087\n    pe_st_M           1.061    0.741    1.432    0.152\n  PH =~                                               \n    ph_mr_M           1.000                           \n    ph_ms_M           1.174    0.114   10.327    0.000\n    ph_st_M           1.135    0.115    9.872    0.000\n  ME =~                                               \n    me_mr_M           1.000                           \n    me_ms_M           1.701    0.463    3.672    0.000\n    me_st_M           1.058    0.345    3.071    0.002\n  EF =~                                               \n    ef_mr_M           1.000                           \n    ef_ms_M           1.508    0.289    5.214    0.000\n    ef_st_M           1.088    0.249    4.380    0.000\n  TI =~                                               \n    ti_mr_M           1.000                           \n    ti_ms_M           5.632    2.751    2.047    0.041\n    ti_st_M           3.908    2.027    1.928    0.054\n  FR =~                                               \n    fr_mr_M           1.000                           \n    fr_ms_M           1.332    0.271    4.921    0.000\n    fr_st_M           1.095    0.245    4.474    0.000\n  OW =~                                               \n    PE                1.000                           \n    ME               73.844 1151.565    0.064    0.949\n    PH               84.873 1323.482    0.064    0.949\n    EF              109.365 1705.387    0.064    0.949\n    TI               30.009  468.136    0.064    0.949\n    FR              113.058 1763.000    0.064    0.949\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .pe_mr_M         452.474  130.577    3.465    0.001\n   .pe_ms_M         511.248   98.015    5.216    0.000\n   .pe_st_M         263.411  128.374    2.052    0.040\n   .ph_mr_M         140.173   31.023    4.518    0.000\n   .ph_ms_M         104.826   32.777    3.198    0.001\n   .ph_st_M         142.456   35.272    4.039    0.000\n   .me_mr_M         402.103   68.867    5.839    0.000\n   .me_ms_M         236.209   58.827    4.015    0.000\n   .me_st_M         331.211   57.866    5.724    0.000\n   .ef_mr_M         437.092   74.252    5.887    0.000\n   .ef_ms_M         105.505   33.491    3.150    0.002\n   .ef_st_M         302.997   52.858    5.732    0.000\n   .ti_mr_M         242.309   39.894    6.074    0.000\n   .ti_ms_M         311.098   84.946    3.662    0.000\n   .ti_st_M         637.972  109.853    5.808    0.000\n   .fr_mr_M         633.851  114.284    5.546    0.000\n   .fr_ms_M         208.689   68.761    3.035    0.002\n   .fr_st_M         405.566   80.446    5.041    0.000\n   .PE              153.647  126.134    1.218    0.223\n   .PH              266.020   61.746    4.308    0.000\n   .ME                7.055   15.442    0.457    0.648\n   .EF              -12.589   15.004   -0.839    0.401\n   .TI               -1.186    2.460   -0.482    0.630\n   .FR              100.758   47.793    2.108    0.035\n    OW                0.017    0.536    0.032    0.974\n\nfitmeasures(cfa_hard, fit.measures = c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n  chisq      df  pvalue     cfi     tli   rmsea    srmr \n366.216 129.000   0.000   0.663   0.601   0.159   0.115"
  },
  {
    "objectID": "analysis.html#packages",
    "href": "analysis.html#packages",
    "title": "First banch. Analysis workflow",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw()) # set black and white theme\nlibrary(lavaan)\n\nThis is lavaan 0.6-15\nlavaan is FREE software! Please report any bugs.\n\nlibrary(tidySEM)\n\nLoading required package: OpenMx\nOpenMx may run faster if it is compiled to take advantage of multiple cores.\nRegistered S3 method overwritten by 'tidySEM':\n  method          from  \n  predict.MxModel OpenMx\n\nlibrary(semPower)\n\n\n### Welcome to semPower 2.0.1 ###\n\nSee https://github.com/moshagen/semPower for quick examples.\nSee https://moshagen.github.io/semPower/ for a detailed manual.\n\nPlease cite as:\nMoshagen, M., & Erdfelder, E. (2016). A new strategy for testing structural equation models.\nStructural Equation Modeling, 23, 54-60. doi: 10.1080/10705511.2014.950896\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:OpenMx':\n\n    %&%, expm\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(lmerTest)\n\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(MuMIn)\nlibrary(pwr)\n\n\nrm(list = ls())"
  },
  {
    "objectID": "analysis.html#reading-data",
    "href": "analysis.html#reading-data",
    "title": "First banch. Analysis workflow",
    "section": "",
    "text": "MR_data &lt;- read_csv(\"MR_firstbanch_data.csv\")\n\nRows: 3744 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): correctAns, base_pic, rotated_pic, key, task, level, id\ndbl (3): is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nST_data &lt;- read_csv(\"ST_firstbanch_data.csv\")\n\nRows: 3744 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): key, task, level, id\ndbl (4): target_present, is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nMS_data &lt;- read_csv(\"MS_firstbanch_data.csv\")\n\nRows: 3744 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (4): trials, n, rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nNASATLX_data &lt;- read_csv(\"NASATLX_firstbanch_data.csv\")\n\nRows: 4212 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): scale, task, level, id\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nSEQUENCE_data &lt;- read_csv(\"SEQ_firstbanch_data.csv\")\n\nRows: 702 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, task, id\ndbl (1): order\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nEXPTIME &lt;- read_csv(\"EXPTIME_firstbanch_data.csv\")\n\nRows: 78 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): id\ndbl  (1): dur\ndttm (2): start, end\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "analysis.html#behavioral-data",
    "href": "analysis.html#behavioral-data",
    "title": "First banch. Analysis workflow",
    "section": "",
    "text": "MR_data |&gt; \n  group_by(id, level, task) |&gt; \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -&gt; MR_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMR_data_agg |&gt; write_csv(\"MR_firstbanch_data_agg.csv\")\n\n\nMR_data_agg |&gt; \n  group_by(level, task) |&gt; \n  summarise(n = unique(id) |&gt; length(),\n            mean = mean(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 easy   MR       78  7.11  4.56  1.43  25.5     6.10     8.12\n2 hard   MR       78 12.0  10.3   1.60  69.1     9.67    14.2 \n3 medium MR       78  8.79  5.88  1.10  37.1     7.49    10.1 \n\n\n\nMR_data_agg |&gt; \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data_agg |&gt; \n  group_by(level, task) |&gt; \n  summarise(n = unique(id) |&gt; length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 easy   MR       78 0.850 0.174 0.312     1    0.812    0.889\n2 hard   MR       78 0.721 0.178 0.312     1    0.682    0.761\n3 medium MR       78 0.755 0.178 0.25      1    0.715    0.794\n\n\n\nMR_data_agg |&gt; \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\n\n\n\n\n\n\nMS_data |&gt; \n  group_by(id, level, task) |&gt; \n  summarise(rt = mean(rt),\n            acc = mean(acc)) -&gt; MS_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMS_data_agg |&gt; write_csv(\"MS_firstbanch_data_agg.csv\")\n\n\nMS_data_agg |&gt; \n  group_by(level, task) |&gt; \n  summarise(n = unique(id) |&gt; length(),\n            mean = mean(rt, na.rm = TRUE),\n            sd = sd(rt, na.rm = TRUE),\n            min = min(rt, na.rm = TRUE),\n            max = max(rt, na.rm = TRUE),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 easy   MS       78  11.7  5.72  5.47  46.8     10.4     13.0\n2 hard   MS       78  22.7 11.8  11.2   91.0     20.1     25.4\n3 medium MS       78  19.1  5.79 10.1   39.9     17.8     20.4\n\n\n\nMS_data_agg |&gt; \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data_agg |&gt; \n  group_by(level, task) |&gt; \n  summarise(n = unique(id) |&gt; length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 easy   MS       78 0.949 0.165     0 1        0.913    0.986\n2 hard   MS       78 0.635 0.168     0 0.973    0.597    0.672\n3 medium MS       78 0.878 0.172     0 1        0.839    0.916\n\n\n\nMS_data_agg |&gt; \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\n\n\n\n\n\n\n\nST_data |&gt; \n  group_by(id, level, task) |&gt; \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -&gt; ST_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nST_data_agg |&gt; write_csv(\"ST_firstbanch_data_agg.csv\")\n\n\nST_data_agg |&gt; \n  group_by(level, task) |&gt; \n  summarise(n = unique(id) |&gt; length(),\n            mean = mean(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean    sd   min   max CI_lower CI_upper\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 easy   ST       78  1.12 0.325 0.627  2.47     1.05     1.19\n2 hard   ST       78  1.44 0.441 0.737  3.52     1.34     1.54\n3 medium ST       78  1.39 0.470 0.692  3.45     1.28     1.49\n\n\n\nST_data_agg |&gt; \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data_agg |&gt; \n  group_by(level, task) |&gt; \n  summarise(n = unique(id) |&gt; length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n))\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 9\n# Groups:   level [3]\n  level  task      n  mean     sd   min   max CI_lower CI_upper\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 easy   ST       78 0.979 0.0358 0.875 1        0.971    0.987\n2 hard   ST       78 0.686 0.127  0.312 0.875    0.658    0.714\n3 medium ST       78 0.836 0.114  0.562 1        0.811    0.861\n\n\n\nST_data_agg |&gt; \n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\n\n\n\n\n\n\nMR_data_agg |&gt; \n  bind_rows(MS_data_agg, ST_data_agg) |&gt;\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, rt)) +\n  facet_wrap(~ task, scales = \"free_y\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"Reaction Time\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMR_data_agg |&gt; \n  bind_rows(MS_data_agg, ST_data_agg) |&gt;\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |&gt; \n  ggplot(aes(level, acc)) +\n  facet_wrap(~ task, scales = \"free_y\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"Accuracy\")"
  },
  {
    "objectID": "analysis.html#experimental-time",
    "href": "analysis.html#experimental-time",
    "title": "First banch. Analysis workflow",
    "section": "",
    "text": "EXPTIME |&gt; ggplot(aes(dur)) +\n  geom_density()\n\nWarning: Removed 1 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\nEXPTIME |&gt; \n  filter(dur &lt; 250) |&gt; \n  ggplot(aes(dur)) +\n  # geom_density() +\n  geom_histogram() +\n  geom_vline(xintercept = 70) +\n  geom_vline(xintercept = 75) +\n  geom_vline(xintercept = 100)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nEXPTIME |&gt; \n  filter(dur &lt; 250) |&gt; \n  ggplot(aes(dur)) +\n  geom_boxplot() \n\n\n\n  #geom_vline(xintercept = 93, linetype = \"dashed\")\n\n\nEXPTIME$dur |&gt; min(na.rm = TRUE)\n\n[1] 28.23333\n\nquantile(EXPTIME$dur[EXPTIME$dur&lt;250], .75, na.rm = TRUE) + 1.5 * IQR(EXPTIME$dur[EXPTIME$dur&lt;250], na.rm = TRUE)\n\n   75% \n82.375"
  },
  {
    "objectID": "analysis.html#nasa-tlx",
    "href": "analysis.html#nasa-tlx",
    "title": "First banch. Analysis workflow",
    "section": "",
    "text": "NASATLX_data |&gt; \n  # fix factor\n  mutate(\n    level = factor(\n      level,\n      levels = c(\"easy\", \"medium\", \"hard\"),\n      ordered = TRUE\n    ),\n    # modify vars to match with previously created encoding\n    scl = str_to_lower(scale),\n    tsk = str_to_lower(task),\n    lvl = str_sub(level, start = 1, end = 1) |&gt; str_to_upper(),\n    score = score * 5\n  ) |&gt;\n  # create a new var for CFA\n  unite(item, scl, tsk, lvl) -&gt; NASATLX_data\n\n\nlevel_colors &lt;- c(\"#4bd752\", \"#d7984b\", \"#d7524b\")\ntask_colors &lt;- c(\"red4\", \"green4\", \"blue4\")\nback_histogram_color &lt;- \"gray60\"\n\n\nNASATLX_data |&gt;\n  ggplot(aes(scale, score, fill = level)) +\n  geom_boxplot() +\n  facet_grid(task ~ .) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_fill_manual(values = level_colors)\n\nWarning: Removed 17 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\npd &lt;- position_dodge(0.3)\nNASATLX_data |&gt;\n  ggplot(aes(scale, score, color = level)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n  facet_grid(task ~ .) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_color_manual(values = level_colors)\n\nWarning: Removed 17 rows containing non-finite values (`stat_summary()`).\nRemoved 17 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\n\n\nNASATLX_data |&gt; \n  select(-item) |&gt; \n  # mutate(row_nubmer = row_number()) |&gt; \n  pivot_wider(values_from = score, names_from = scale) -&gt; nasa_tlx_wide\n# NASA_TLX |&gt; group_by(task, level) |&gt; summarise(n=n())\n# nasa_tlx_wide |&gt; group_by(task, level) |&gt; summarise(n=n())\n\n\nr2tof2 &lt;- function(r2) r2 / (1 - r2)\n\n\n\n\nmix_ME &lt;- lmer(ME ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ME)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ME ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6090.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1846 -0.5810  0.0514  0.6403  3.1496 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 172.8    13.14   \n Residual             300.2    17.33   \nNumber of obs: 701, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)          46.445      2.463 335.008  18.861  &lt; 2e-16 ***\ntaskMS              -16.813      2.774 615.020  -6.060 2.37e-09 ***\ntaskST              -18.655      2.774 615.020  -6.724 4.05e-11 ***\nlevelmedium          10.951      2.774 615.020   3.947 8.82e-05 ***\nlevelhard            19.777      2.774 615.020   7.128 2.86e-12 ***\ntaskMS:levelmedium   20.000      3.924 615.020   5.097 4.59e-07 ***\ntaskST:levelmedium   14.677      3.924 615.020   3.741 0.000201 ***\ntaskMS:levelhard     27.488      3.924 615.020   7.006 6.47e-12 ***\ntaskST:levelhard     20.282      3.931 615.107   5.160 3.34e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.563                                                             \ntaskST      -0.563  0.500                                                      \nlevelmedium -0.563  0.500  0.500                                               \nlevelhard   -0.563  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.398 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.398 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.398 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.398 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_ME)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask         6703    3352     2 615.06  11.165 1.727e-05 ***\nlevel      152214   76107     2 615.06 253.516 &lt; 2.2e-16 ***\ntask:level  16928    4232     4 615.06  14.097 5.168e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ME)[1]\n\nWarning: 'r.squaredGLMM' now calculates a revised statistic. See the help page.\n\n\n[1] 0.3470414\n\nr2tof2(r.squaredGLMM(mix_ME)[1])\n\n[1] 0.5314908\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_ME)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 7\n              v = 26.69644\n             f2 = 0.5314908\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_PH &lt;- lmer(PH ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PH)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PH ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 5661\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.5884 -0.5011 -0.0854  0.4111  5.0325 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 434.9    20.85   \n Residual             148.2    12.17   \nNumber of obs: 694, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)         17.0474     2.7392 127.9525   6.224 6.41e-09 ***\ntaskMS              -3.0090     1.9782 608.2281  -1.521  0.12875    \ntaskST              -5.6698     1.9562 608.0818  -2.898  0.00389 ** \nlevelmedium          0.8142     1.9562 608.0818   0.416  0.67740    \nlevelhard            5.5848     1.9562 608.0818   2.855  0.00445 ** \ntaskMS:levelmedium   8.9361     2.7821 608.1575   3.212  0.00139 ** \ntaskST:levelmedium   8.8358     2.7666 608.0868   3.194  0.00148 ** \ntaskMS:levelhard     7.8940     2.7860 608.1309   2.833  0.00476 ** \ntaskST:levelhard     7.7832     2.7615 608.0620   2.818  0.00498 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.356                                                             \ntaskST      -0.360  0.498                                                      \nlevelmedium -0.360  0.498  0.504                                               \nlevelhard   -0.360  0.498  0.504  0.504                                        \ntskMS:lvlmd  0.253 -0.711 -0.354 -0.703 -0.354                                 \ntskST:lvlmd  0.254 -0.352 -0.707 -0.707 -0.356  0.497                          \ntskMS:lvlhr  0.253 -0.709 -0.354 -0.354 -0.702  0.504      0.250               \ntskST:lvlhr  0.255 -0.353 -0.708 -0.357 -0.708  0.251      0.501      0.497    \n\nanova(mix_PH)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask        1087.1   543.6     2 608.13  3.6685  0.026080 *  \nlevel      13744.9  6872.5     2 608.10 46.3819 &lt; 2.2e-16 ***\ntask:level  2422.0   605.5     4 608.12  4.0865  0.002816 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PH)[1]\n\n[1] 0.04098889\n\nr2tof2(r.squaredGLMM(mix_PH)[1])\n\n[1] 0.04274079\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PH)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 7\n              v = 334.8529\n             f2 = 0.04274079\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_TI &lt;- lmer(TI ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_TI)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: TI ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6223.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0957 -0.5892 -0.0314  0.6288  2.8906 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 160.6    12.67   \n Residual             373.7    19.33   \nNumber of obs: 701, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)         15.5984     2.6173 401.8373   5.960 5.53e-09 ***\ntaskMS               3.5592     3.0955 614.9845   1.150 0.250661    \ntaskST              11.3673     3.0955 614.9845   3.672 0.000261 ***\nlevelmedium          0.7836     3.0955 614.9845   0.253 0.800248    \nlevelhard            4.1863     3.0955 614.9845   1.352 0.176739    \ntaskMS:levelmedium  32.1104     4.3776 614.9845   7.335 7.02e-13 ***\ntaskST:levelmedium  33.6197     4.3854 615.0938   7.666 6.94e-14 ***\ntaskMS:levelhard    51.4924     4.3776 614.9845  11.763  &lt; 2e-16 ***\ntaskST:levelhard    50.8953     4.3776 614.9845  11.626  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.591                                                             \ntaskST      -0.591  0.500                                                      \nlevelmedium -0.591  0.500  0.500                                               \nlevelhard   -0.591  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.418 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.417 -0.353 -0.706 -0.706 -0.353  0.499                          \ntskMS:lvlhr  0.418 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.418 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_TI)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask       203830  101915     2 615.03 272.724 &lt; 2.2e-16 ***\nlevel      173710   86855     2 615.03 232.424 &lt; 2.2e-16 ***\ntask:level  70059   17515     4 615.03  46.869 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_TI)[1]\n\n[1] 0.5446988\n\nr2tof2(r.squaredGLMM(mix_TI)[1])\n\n[1] 1.196348\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_TI)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 7\n              v = 12.23247\n             f2 = 1.196348\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_PE &lt;- lmer(PE ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PE)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PE ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6076.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3961 -0.6412  0.0325  0.6477  2.5583 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 113.9    10.67   \n Residual             306.0    17.49   \nNumber of obs: 701, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)          66.615      2.320 435.796  28.711  &lt; 2e-16 ***\ntaskMS               25.479      2.801 615.017   9.096  &lt; 2e-16 ***\ntaskST               23.503      2.801 615.017   8.391 3.31e-16 ***\nlevelmedium          -8.781      2.801 615.017  -3.135   0.0018 ** \nlevelhard           -16.480      2.801 615.017  -5.884 6.60e-09 ***\ntaskMS:levelmedium  -17.419      3.961 615.017  -4.397 1.29e-05 ***\ntaskST:levelmedium  -28.291      3.961 615.017  -7.142 2.61e-12 ***\ntaskMS:levelhard    -39.938      3.961 615.017 -10.082  &lt; 2e-16 ***\ntaskST:levelhard    -44.857      3.968 615.138 -11.304  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.604                                                             \ntaskST      -0.604  0.500                                                      \nlevelmedium -0.604  0.500  0.500                                               \nlevelhard   -0.604  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.427 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.427 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.427 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.426 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_PE)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask         7295    3647     2 615.07  11.921  8.33e-06 ***\nlevel      234141  117070     2 615.07 382.616 &lt; 2.2e-16 ***\ntask:level  49094   12273     4 615.07  40.113 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PE)[1]\n\n[1] 0.4967487\n\nr2tof2(r.squaredGLMM(mix_PE)[1])\n\n[1] 0.9870788\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PE)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 7\n              v = 14.63282\n             f2 = 0.9870788\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_EF &lt;- lmer(EF ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_EF)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6055.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1279 -0.6094  0.0357  0.6249  3.5591 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 249.8    15.81   \n Residual             276.8    16.64   \nNumber of obs: 700, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)          44.381      2.598 247.283  17.080  &lt; 2e-16 ***\ntaskMS              -12.862      2.664 614.020  -4.828 1.74e-06 ***\ntaskST              -11.609      2.664 614.020  -4.358 1.54e-05 ***\nlevelmedium           9.006      2.664 614.020   3.381 0.000769 ***\nlevelhard            17.584      2.664 614.020   6.601 8.86e-11 ***\ntaskMS:levelmedium   17.979      3.774 614.080   4.764 2.38e-06 ***\ntaskST:levelmedium   13.621      3.774 614.080   3.609 0.000333 ***\ntaskMS:levelhard     25.250      3.767 614.020   6.702 4.65e-11 ***\ntaskST:levelhard     14.255      3.767 614.020   3.784 0.000170 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.513                                                             \ntaskST      -0.513  0.500                                                      \nlevelmedium -0.513  0.500  0.500                                               \nlevelhard   -0.513  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.362 -0.706 -0.353 -0.706 -0.353                                 \ntskST:lvlmd  0.362 -0.353 -0.706 -0.706 -0.353  0.498                          \ntskMS:lvlhr  0.362 -0.707 -0.354 -0.354 -0.707  0.499      0.250               \ntskST:lvlhr  0.362 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_EF)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF  F value    Pr(&gt;F)    \ntask         1763     881     2 614.07   3.1842    0.0421 *  \nlevel      113335   56667     2 614.07 204.7413 &lt; 2.2e-16 ***\ntask:level  13748    3437     4 614.07  12.4179 1.018e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_EF)[1]\n\n[1] 0.2592648\n\nr2tof2(r.squaredGLMM(mix_EF)[1])\n\n[1] 0.3500102\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_EF)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 7\n              v = 40.49648\n             f2 = 0.3500102\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_FR &lt;- lmer(FR ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_FR)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: FR ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6292.3\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.92494 -0.67440 -0.04275  0.63993  2.97611 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 343.0    18.52   \n Residual             402.2    20.05   \nNumber of obs: 698, groups:  id, 78\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)          35.058      3.091 256.301  11.342  &lt; 2e-16 ***\ntaskMS              -11.619      3.235 612.136  -3.592 0.000355 ***\ntaskST              -13.828      3.211 611.853  -4.306 1.94e-05 ***\nlevelmedium           6.322      3.211 611.853   1.969 0.049432 *  \nlevelhard            12.950      3.223 611.978   4.018 6.59e-05 ***\ntaskMS:levelmedium   13.354      4.558 611.995   2.930 0.003518 ** \ntaskST:levelmedium   20.118      4.541 611.853   4.430 1.12e-05 ***\ntaskMS:levelhard     23.420      4.566 612.053   5.129 3.92e-07 ***\ntaskST:levelhard     30.659      4.558 611.996   6.727 4.00e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.516                                                             \ntaskST      -0.519  0.496                                                      \nlevelmedium -0.519  0.496  0.500                                               \nlevelhard   -0.518  0.495  0.498  0.498                                        \ntskMS:lvlmd  0.366 -0.710 -0.352 -0.705 -0.351                                 \ntskST:lvlmd  0.367 -0.351 -0.707 -0.707 -0.352  0.498                          \ntskMS:lvlhr  0.365 -0.708 -0.352 -0.352 -0.706  0.503      0.249               \ntskST:lvlhr  0.366 -0.349 -0.705 -0.352 -0.707  0.248      0.498      0.499    \n\nanova(mix_FR)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF  F value    Pr(&gt;F)    \ntask         1246     623     2 611.95   1.5486    0.2134    \nlevel      111859   55929     2 611.94 139.0640 &lt; 2.2e-16 ***\ntask:level  20526    5131     4 612.00  12.7589 5.569e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_FR)[1]\n\n[1] 0.204493\n\nr2tof2(r.squaredGLMM(mix_FR)[1])\n\n[1] 0.2570599\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_FR)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 7\n              v = 55.20916\n             f2 = 0.2570599\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\n\nlavmodel &lt;- \"\nPE =~ PE_mr + PE_ms + PE_st\nME =~ ME_mr + ME_ms + ME_st\nPH =~ PH_mr + PH_ms + PH_st\nEF =~ EF_mr + EF_ms + EF_st\nTI =~ TI_mr + TI_ms + TI_st\nFR =~ FR_mr + FR_ms + FR_st\nOW =~ PE + ME + PH + EF + TI + FR\"\n\n\nsemPower.getDf(lavmodel)\n\n[1] 129\n\n\n\nap &lt;- semPower.aPriori(effect = .05, effect.measure = 'RMSEA',\n                       alpha = .05, power = .80, df = semPower.getDf(lavmodel))\nsummary(ap)\n\n\n semPower: A priori power analysis\n                                   \n F0                        0.322500\n RMSEA                     0.050000\n Mc                        0.851079\n                                   \n df                        129     \n Required Num Observations 142     \n                                   \n Critical Chi-Square       156.5075\n NCP                       45.47250\n Alpha                     0.050000\n Beta                      0.198348\n Power (1 - Beta)          0.801652\n Implied Alpha/Beta Ratio  0.252082\n\n\n\n\n\n\n\n\n\nNASATLX_data |&gt; \n  pivot_wider(id_cols = id, \n              names_from = item, \n              values_from = score,\n              values_fn = unlist) -&gt; NASATLX_cfa\n\n\n\n\n\nmodel1 &lt;- \"PE =~ pe_st_E + pe_st_M + pe_st_H + pe_mr_E + pe_mr_M + pe_mr_H + pe_ms_E + pe_ms_M + pe_ms_H\nME =~ me_st_E + me_st_M + me_st_H + me_mr_E + me_mr_M + me_mr_H + me_ms_E + me_ms_M + me_ms_H\nPH =~ ph_st_E + ph_st_M + ph_st_H + ph_mr_E + ph_mr_M + ph_mr_H + ph_ms_E + ph_ms_M + ph_ms_H\nEF =~ ef_st_E + ef_st_M + ef_st_H + ef_mr_E + ef_mr_M + ef_mr_H + ef_ms_E + ef_ms_M + ef_ms_H\nTI =~ ti_st_E + ti_st_M + ti_st_H + ti_mr_E + ti_mr_M + ti_mr_H + ti_ms_E + ti_ms_M + ti_ms_H\nFR =~ fr_st_E + fr_st_M + fr_st_H + fr_mr_E + fr_mr_M + fr_mr_H + fr_ms_E + fr_ms_M + fr_ms_H\nOW =~ PE + ME + PH + EF + TI + FR\"\n\n\ncfa1 &lt;- cfa(model1, NASATLX_cfa)\n\nWarning in lav_object_post_check(object): lavaan WARNING: some estimated lv\nvariances are negative\n\nsummary(cfa1, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 457 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                       114\n\n                                                  Used       Total\n  Number of observations                            67          78\n\nModel Test User Model:\n                                                      \n  Test statistic                              3660.590\n  Degrees of freedom                              1371\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              5450.455\n  Degrees of freedom                              1431\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.430\n  Tucker-Lewis Index (TLI)                       0.405\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -15485.621\n  Loglikelihood unrestricted model (H1)     -13655.326\n                                                      \n  Akaike (AIC)                               31199.242\n  Bayesian (BIC)                             31450.577\n  Sample-size adjusted Bayesian (SABIC)      31091.632\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.158\n  90 Percent confidence interval - lower         0.152\n  90 Percent confidence interval - upper         0.164\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.152\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PE =~                                               \n    pe_st_E           1.000                           \n    pe_st_M           2.255    0.980    2.301    0.021\n    pe_st_H           0.883    0.658    1.342    0.180\n    pe_mr_E           3.979    1.469    2.709    0.007\n    pe_mr_M           4.586    1.672    2.743    0.006\n    pe_mr_H           4.053    1.464    2.769    0.006\n    pe_ms_E           1.025    0.537    1.910    0.056\n    pe_ms_M           1.643    0.922    1.781    0.075\n    pe_ms_H           1.434    0.776    1.848    0.065\n  ME =~                                               \n    me_st_E           1.000                           \n    me_st_M           1.013    0.263    3.850    0.000\n    me_st_H           0.958    0.292    3.280    0.001\n    me_mr_E           1.566    0.351    4.466    0.000\n    me_mr_M           1.330    0.303    4.391    0.000\n    me_mr_H           1.032    0.263    3.920    0.000\n    me_ms_E           0.991    0.257    3.856    0.000\n    me_ms_M           1.180    0.291    4.053    0.000\n    me_ms_H           0.877    0.218    4.023    0.000\n  PH =~                                               \n    ph_st_E           1.000                           \n    ph_st_M           1.992    0.249    8.007    0.000\n    ph_st_H           2.349    0.260    9.026    0.000\n    ph_mr_E           1.971    0.211    9.327    0.000\n    ph_mr_M           1.988    0.222    8.971    0.000\n    ph_mr_H           2.338    0.263    8.880    0.000\n    ph_ms_E           1.450    0.182    7.961    0.000\n    ph_ms_M           2.179    0.241    9.045    0.000\n    ph_ms_H           2.642    0.286    9.253    0.000\n  EF =~                                               \n    ef_st_E           1.000                           \n    ef_st_M           1.029    0.188    5.478    0.000\n    ef_st_H           0.877    0.199    4.410    0.000\n    ef_mr_E           1.177    0.216    5.445    0.000\n    ef_mr_M           1.173    0.217    5.411    0.000\n    ef_mr_H           0.841    0.180    4.660    0.000\n    ef_ms_E           1.157    0.197    5.859    0.000\n    ef_ms_M           1.158    0.194    5.975    0.000\n    ef_ms_H           0.712    0.151    4.719    0.000\n  TI =~                                               \n    ti_st_E           1.000                           \n    ti_st_M           0.882    0.419    2.105    0.035\n    ti_st_H           0.594    0.371    1.601    0.109\n    ti_mr_E           1.667    0.432    3.861    0.000\n    ti_mr_M           1.465    0.378    3.876    0.000\n    ti_mr_H           1.548    0.415    3.730    0.000\n    ti_ms_E           1.382    0.399    3.466    0.001\n    ti_ms_M           0.987    0.418    2.362    0.018\n    ti_ms_H           0.650    0.360    1.805    0.071\n  FR =~                                               \n    fr_st_E           1.000                           \n    fr_st_M           1.716    0.355    4.837    0.000\n    fr_st_H           1.463    0.343    4.265    0.000\n    fr_mr_E           1.547    0.349    4.436    0.000\n    fr_mr_M           1.840    0.393    4.685    0.000\n    fr_mr_H           1.672    0.356    4.695    0.000\n    fr_ms_E           1.234    0.307    4.027    0.000\n    fr_ms_M           1.651    0.341    4.838    0.000\n    fr_ms_H           1.555    0.338    4.607    0.000\n  OW =~                                               \n    PE                1.000                           \n    ME              129.227  926.720    0.139    0.889\n    PH               78.302  561.551    0.139    0.889\n    EF              187.539 1344.685    0.139    0.889\n    TI               59.971  430.389    0.139    0.889\n    FR               92.231  661.541    0.139    0.889\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .pe_st_E         124.592   22.092    5.640    0.000\n   .pe_st_M         361.286   65.373    5.527    0.000\n   .pe_st_H         354.263   61.638    5.747    0.000\n   .pe_mr_E         244.580   54.022    4.527    0.000\n   .pe_mr_M         244.481   59.972    4.077    0.000\n   .pe_mr_H         133.027   39.392    3.377    0.001\n   .pe_ms_E         168.410   29.687    5.673    0.000\n   .pe_ms_M         548.305   96.241    5.697    0.000\n   .pe_ms_H         369.742   65.034    5.685    0.000\n   .me_st_E         245.269   45.144    5.433    0.000\n   .me_st_M         287.396   52.463    5.478    0.000\n   .me_st_H         442.052   78.816    5.609    0.000\n   .me_mr_E         350.656   67.808    5.171    0.000\n   .me_mr_M         277.611   53.108    5.227    0.000\n   .me_mr_H         278.281   51.010    5.455    0.000\n   .me_ms_E         273.702   49.982    5.476    0.000\n   .me_ms_M         317.792   58.786    5.406    0.000\n   .me_ms_H         180.944   33.398    5.418    0.000\n   .ph_st_E          72.731   13.064    5.567    0.000\n   .ph_st_M         187.008   34.332    5.447    0.000\n   .ph_st_H         118.723   23.571    5.037    0.000\n   .ph_mr_E          60.179   12.690    4.742    0.000\n   .ph_mr_M          89.689   17.669    5.076    0.000\n   .ph_mr_H         134.863   26.271    5.133    0.000\n   .ph_ms_E         102.020   18.696    5.457    0.000\n   .ph_ms_M         100.315   19.972    5.023    0.000\n   .ph_ms_H         118.110   24.449    4.831    0.000\n   .ef_st_E         239.011   44.588    5.360    0.000\n   .ef_st_M         235.842   44.255    5.329    0.000\n   .ef_st_H         366.864   65.803    5.575    0.000\n   .ef_mr_E         316.818   59.323    5.341    0.000\n   .ef_mr_M         322.696   60.292    5.352    0.000\n   .ef_mr_H         283.996   51.311    5.535    0.000\n   .ef_ms_E         219.092   42.458    5.160    0.000\n   .ef_ms_M         198.369   38.958    5.092    0.000\n   .ef_ms_H         195.544   35.398    5.524    0.000\n   .ti_st_E         341.024   60.770    5.612    0.000\n   .ti_st_M         729.673  127.474    5.724    0.000\n   .ti_st_H         661.921  114.997    5.756    0.000\n   .ti_mr_E          93.536   24.026    3.893    0.000\n   .ti_mr_M          64.489   17.520    3.681    0.000\n   .ti_mr_H         149.496   31.182    4.794    0.000\n   .ti_ms_E         243.722   45.883    5.312    0.000\n   .ti_ms_M         656.813  115.250    5.699    0.000\n   .ti_ms_H         590.416  102.767    5.745    0.000\n   .fr_st_E         237.842   44.183    5.383    0.000\n   .fr_st_M         339.632   68.622    4.949    0.000\n   .fr_st_H         470.211   87.897    5.350    0.000\n   .fr_mr_E         441.208   83.804    5.265    0.000\n   .fr_mr_M         472.556   92.734    5.096    0.000\n   .fr_mr_H         385.335   75.746    5.087    0.000\n   .fr_ms_E         421.390   77.460    5.440    0.000\n   .fr_ms_M         313.895   63.432    4.948    0.000\n   .fr_ms_H         369.808   71.717    5.156    0.000\n   .PE               18.313   13.071    1.401    0.161\n   .ME               20.134   13.400    1.502    0.133\n   .PH               76.954   20.525    3.749    0.000\n   .EF               -7.898   17.618   -0.448    0.654\n   .TI               70.269   36.870    1.906    0.057\n   .FR               84.765   33.215    2.552    0.011\n    OW                0.007    0.095    0.070    0.944\n\n\n\nmodel_easy &lt;- \"PE =~ pe_mr_E + pe_ms_E + pe_st_E\nPH =~ ph_mr_E + ph_ms_E + ph_st_E\nME =~ me_mr_E + me_ms_E + me_st_E\nEF =~ ef_mr_E + ef_ms_E + ef_st_E\nTI =~ ti_mr_E + ti_ms_E + ti_st_E\nFR =~ fr_mr_E + fr_ms_E + fr_st_E\nOW =~ PE + ME + PH + EF + TI + FR\"\n\ncfa_easy &lt;- cfa(model_easy, NASATLX_cfa,)\n\nWarning in lavaan::lavaan(model = model_easy, data = NASATLX_cfa, model.type = \"cfa\", : lavaan WARNING:\n    the optimizer (NLMINB) claimed the model converged, but not all\n    elements of the gradient are (near) zero; the optimizer may not\n    have found a local solution use check.gradient = FALSE to skip\n    this check.\n\nsummary(cfa_easy, fit.measures = TRUE)\n\nWarning in lav_object_summary(object = object, header = header, fit.measures = fit.measures, : lavaan WARNING: fit measures not available if model did not converge\n\n\nlavaan 0.6.15 did NOT end normally after 2116 iterations\n** WARNING ** Estimates below are most likely unreliable\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                            73          78\n\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PE =~                                               \n    pe_mr_E           1.000                           \n    pe_ms_E           1.419       NA                  \n    pe_st_E           1.209       NA                  \n  PH =~                                               \n    ph_mr_E           1.000                           \n    ph_ms_E           0.771       NA                  \n    ph_st_E           0.553       NA                  \n  ME =~                                               \n    me_mr_E           1.000                           \n    me_ms_E           1.332       NA                  \n    me_st_E           0.970       NA                  \n  EF =~                                               \n    ef_mr_E           1.000                           \n    ef_ms_E         615.563       NA                  \n    ef_st_E         450.263       NA                  \n  TI =~                                               \n    ti_mr_E           1.000                           \n    ti_ms_E           0.897       NA                  \n    ti_st_E           0.658       NA                  \n  FR =~                                               \n    fr_mr_E           1.000                           \n    fr_ms_E           1.621       NA                  \n    fr_st_E           0.981       NA                  \n  OW =~                                               \n    PE                1.000                           \n    ME               77.820       NA                  \n    PH               35.580       NA                  \n    EF              -27.319       NA                  \n    TI              -16.505       NA                  \n    FR               32.616       NA                  \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .pe_mr_E         467.637       NA                  \n   .pe_ms_E          78.043       NA                  \n   .pe_st_E          69.064       NA                  \n   .ph_mr_E          81.950       NA                  \n   .ph_ms_E          90.557       NA                  \n   .ph_st_E          55.096       NA                  \n   .me_mr_E         501.362       NA                  \n   .me_ms_E         112.752       NA                  \n   .me_st_E         226.683       NA                  \n   .ef_mr_E         653.026       NA                  \n   .ef_ms_E          52.514       NA                  \n   .ef_st_E         212.342       NA                  \n   .ti_mr_E         127.553       NA                  \n   .ti_ms_E         233.108       NA                  \n   .ti_st_E         329.558       NA                  \n   .fr_mr_E         607.300       NA                  \n   .fr_ms_E         245.992       NA                  \n   .fr_st_E         229.707       NA                  \n   .PE               47.895       NA                  \n   .PH              405.813       NA                  \n   .ME              162.755       NA                  \n   .EF                0.119       NA                  \n   .TI              223.000       NA                  \n   .FR              142.155       NA                  \n    OW               -0.000       NA                  \n\nfitmeasures(cfa_easy, fit.measures = c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\nError in lav_fit_measures(object = object, fit.measures = fit.measures, : lavaan ERROR: fit measures not available if model did not converge\n\n\n\nmodel_medium &lt;- \"PE =~ pe_mr_M + pe_ms_M + pe_st_M\nPH =~ ph_mr_M + ph_ms_M + ph_st_M\nME =~ me_mr_M + me_ms_M + me_st_M\nEF =~ ef_mr_M + ef_ms_M + ef_st_M\nTI =~ ti_mr_M + ti_ms_M + ti_st_M\nFR =~ fr_mr_M + fr_ms_M + fr_st_M\nOW =~ PE + ME + PH + EF + TI + FR\"\n\ncfa_medium &lt;- cfa(model_medium, NASATLX_cfa,)\n\nWarning in lav_object_post_check(object): lavaan WARNING: some estimated lv\nvariances are negative\n\nsummary(cfa_medium, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 595 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                            74          78\n\nModel Test User Model:\n                                                      \n  Test statistic                               414.006\n  Degrees of freedom                               129\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               937.686\n  Degrees of freedom                               153\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.637\n  Tucker-Lewis Index (TLI)                       0.569\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -5875.695\n  Loglikelihood unrestricted model (H1)      -5668.692\n                                                      \n  Akaike (AIC)                               11835.391\n  Bayesian (BIC)                             11932.162\n  Sample-size adjusted Bayesian (SABIC)      11799.804\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.173\n  90 Percent confidence interval - lower         0.154\n  90 Percent confidence interval - upper         0.192\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.141\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PE =~                                               \n    pe_mr_M           1.000                           \n    pe_ms_M           0.692    0.404    1.713    0.087\n    pe_st_M           1.111    0.795    1.398    0.162\n  PH =~                                               \n    ph_mr_M           1.000                           \n    ph_ms_M           1.175    0.114   10.302    0.000\n    ph_st_M           1.136    0.115    9.853    0.000\n  ME =~                                               \n    me_mr_M           1.000                           \n    me_ms_M           1.700    0.462    3.682    0.000\n    me_st_M           1.056    0.344    3.070    0.002\n  EF =~                                               \n    ef_mr_M           1.000                           \n    ef_ms_M           1.507    0.289    5.217    0.000\n    ef_st_M           1.087    0.248    4.376    0.000\n  TI =~                                               \n    ti_mr_M           1.000                           \n    ti_ms_M           5.636    2.758    2.044    0.041\n    ti_st_M           3.908    2.030    1.925    0.054\n  FR =~                                               \n    fr_mr_M           1.000                           \n    fr_ms_M           1.321    0.267    4.951    0.000\n    fr_st_M           1.088    0.242    4.498    0.000\n  OW =~                                               \n    PE                1.000                           \n    ME               77.337 1225.523    0.063    0.950\n    PH               88.722 1405.879    0.063    0.950\n    EF              114.555 1815.199    0.063    0.950\n    TI               31.359  497.099    0.063    0.950\n    FR              119.009 1885.795    0.063    0.950\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .pe_mr_M         459.659  129.163    3.559    0.000\n   .pe_ms_M         515.945   98.551    5.235    0.000\n   .pe_st_M         254.842  135.912    1.875    0.061\n   .ph_mr_M         140.360   31.040    4.522    0.000\n   .ph_ms_M         105.049   32.821    3.201    0.001\n   .ph_st_M         142.392   35.293    4.035    0.000\n   .me_mr_M         400.687   68.640    5.837    0.000\n   .me_ms_M         235.436   58.752    4.007    0.000\n   .me_st_M         333.738   58.257    5.729    0.000\n   .ef_mr_M         437.248   74.274    5.887    0.000\n   .ef_ms_M         105.610   33.510    3.152    0.002\n   .ef_st_M         304.507   53.091    5.736    0.000\n   .ti_mr_M         242.729   39.965    6.073    0.000\n   .ti_ms_M         310.719   84.981    3.656    0.000\n   .ti_st_M         637.750  109.822    5.807    0.000\n   .fr_mr_M         631.586  114.143    5.533    0.000\n   .fr_ms_M         210.454   68.924    3.053    0.002\n   .fr_st_M         405.789   80.574    5.036    0.000\n   .PE              146.638  123.264    1.190    0.234\n   .PH              264.745   61.527    4.303    0.000\n   .ME                7.078   15.473    0.457    0.647\n   .EF              -12.849   15.063   -0.853    0.394\n   .TI               -1.161    2.451   -0.474    0.636\n   .FR              102.947   48.504    2.122    0.034\n    OW                0.016    0.498    0.032    0.975\n\nfitmeasures(cfa_medium, fit.measures = c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n  chisq      df  pvalue     cfi     tli   rmsea    srmr \n414.006 129.000   0.000   0.637   0.569   0.173   0.141 \n\n\n\nmodel_hard &lt;- \"PE =~ pe_mr_H + pe_ms_H + pe_st_H\nPH =~ ph_mr_H + ph_ms_H + ph_st_H\nME =~ me_mr_H + me_ms_H + me_st_H\nEF =~ ef_mr_H + ef_ms_H + ef_st_H\nTI =~ ti_mr_H + ti_ms_H + ti_st_H\nFR =~ fr_mr_H + fr_ms_H + fr_st_H\nOW =~ PE + ME + PH + EF + TI + FR\"\n\ncfa_hard &lt;- cfa(model_hard, NASATLX_cfa,)\n\nWarning in lav_object_post_check(object): lavaan WARNING: some estimated lv\nvariances are negative\n\nsummary(cfa_medium, fit.measures = TRUE)\n\nlavaan 0.6.15 ended normally after 595 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        42\n\n                                                  Used       Total\n  Number of observations                            74          78\n\nModel Test User Model:\n                                                      \n  Test statistic                               414.006\n  Degrees of freedom                               129\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                               937.686\n  Degrees of freedom                               153\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.637\n  Tucker-Lewis Index (TLI)                       0.569\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -5875.695\n  Loglikelihood unrestricted model (H1)      -5668.692\n                                                      \n  Akaike (AIC)                               11835.391\n  Bayesian (BIC)                             11932.162\n  Sample-size adjusted Bayesian (SABIC)      11799.804\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.173\n  90 Percent confidence interval - lower         0.154\n  90 Percent confidence interval - upper         0.192\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.141\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  PE =~                                               \n    pe_mr_M           1.000                           \n    pe_ms_M           0.692    0.404    1.713    0.087\n    pe_st_M           1.111    0.795    1.398    0.162\n  PH =~                                               \n    ph_mr_M           1.000                           \n    ph_ms_M           1.175    0.114   10.302    0.000\n    ph_st_M           1.136    0.115    9.853    0.000\n  ME =~                                               \n    me_mr_M           1.000                           \n    me_ms_M           1.700    0.462    3.682    0.000\n    me_st_M           1.056    0.344    3.070    0.002\n  EF =~                                               \n    ef_mr_M           1.000                           \n    ef_ms_M           1.507    0.289    5.217    0.000\n    ef_st_M           1.087    0.248    4.376    0.000\n  TI =~                                               \n    ti_mr_M           1.000                           \n    ti_ms_M           5.636    2.758    2.044    0.041\n    ti_st_M           3.908    2.030    1.925    0.054\n  FR =~                                               \n    fr_mr_M           1.000                           \n    fr_ms_M           1.321    0.267    4.951    0.000\n    fr_st_M           1.088    0.242    4.498    0.000\n  OW =~                                               \n    PE                1.000                           \n    ME               77.337 1225.523    0.063    0.950\n    PH               88.722 1405.879    0.063    0.950\n    EF              114.555 1815.199    0.063    0.950\n    TI               31.359  497.099    0.063    0.950\n    FR              119.009 1885.795    0.063    0.950\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .pe_mr_M         459.659  129.163    3.559    0.000\n   .pe_ms_M         515.945   98.551    5.235    0.000\n   .pe_st_M         254.842  135.912    1.875    0.061\n   .ph_mr_M         140.360   31.040    4.522    0.000\n   .ph_ms_M         105.049   32.821    3.201    0.001\n   .ph_st_M         142.392   35.293    4.035    0.000\n   .me_mr_M         400.687   68.640    5.837    0.000\n   .me_ms_M         235.436   58.752    4.007    0.000\n   .me_st_M         333.738   58.257    5.729    0.000\n   .ef_mr_M         437.248   74.274    5.887    0.000\n   .ef_ms_M         105.610   33.510    3.152    0.002\n   .ef_st_M         304.507   53.091    5.736    0.000\n   .ti_mr_M         242.729   39.965    6.073    0.000\n   .ti_ms_M         310.719   84.981    3.656    0.000\n   .ti_st_M         637.750  109.822    5.807    0.000\n   .fr_mr_M         631.586  114.143    5.533    0.000\n   .fr_ms_M         210.454   68.924    3.053    0.002\n   .fr_st_M         405.789   80.574    5.036    0.000\n   .PE              146.638  123.264    1.190    0.234\n   .PH              264.745   61.527    4.303    0.000\n   .ME                7.078   15.473    0.457    0.647\n   .EF              -12.849   15.063   -0.853    0.394\n   .TI               -1.161    2.451   -0.474    0.636\n   .FR              102.947   48.504    2.122    0.034\n    OW                0.016    0.498    0.032    0.975\n\nfitmeasures(cfa_hard, fit.measures = c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n  chisq      df  pvalue     cfi     tli   rmsea    srmr \n366.213 129.000   0.000   0.664   0.601   0.159   0.115"
  },
  {
    "objectID": "toloka-explore.html",
    "href": "toloka-explore.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\n\nrm(list=ls())\n\n\nmr_preproc <- function(d) {\n  \n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_easy.keys,\n    resp_MR_easy.corr,\n    resp_MR_easy.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_easy.keys,\n      \"is_correct\" = resp_MR_easy.corr,\n      \"rt\" = resp_MR_easy.rt\n    ) -> MR_easy # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_medium.keys,\n    resp_MR_medium.corr,\n    resp_MR_medium.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |>  # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_medium.keys,\n      \"is_correct\" = resp_MR_medium.corr,\n      \"rt\" = resp_MR_medium.rt\n    ) -> MR_medium # ready to use\n  \n  \n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_hard.keys,\n    resp_MR_hard.corr,\n    resp_MR_hard.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_hard.keys,\n      \"is_correct\" = resp_MR_hard.corr,\n      \"rt\" = resp_MR_hard.rt\n    ) -> MR_hard # ready to use\n  \n  # bind all conditions of mental rotation task to one tibble\n  \n  bind_rows(MR_easy, MR_medium, MR_hard) -> MR\n  \n  return(MR)\n  \n}\n\nst_preproc <- function(d) {\n  \n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    target_present,\n    key_resp_SE.keys,\n    key_resp_SE.corr,\n    key_resp_SE.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SE.keys,\n      \"is_correct\" = key_resp_SE.corr,\n      \"rt\" = key_resp_SE.rt\n    ) -> ST_easy # ready to use\n  \n  d |> select(\n    # select columns we need\n    target_present,\n    key_resp_SM.keys,\n    key_resp_SM.corr,\n    key_resp_SM.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SM.keys,\n      \"is_correct\" = key_resp_SM.corr,\n      \"rt\" = key_resp_SM.rt\n    ) -> ST_medium # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    target_present,\n    resp_S_H_trials.keys,\n    resp_S_H_trials.corr,\n    resp_S_H_trials.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_S_H_trials.keys,\n      \"is_correct\" = resp_S_H_trials.corr,\n      \"rt\" = resp_S_H_trials.rt\n    ) -> ST_hard # ready to use\n  \n  # bind all conditions of sternberg task to one tibble\n  bind_rows(ST_easy, ST_hard, ST_medium) -> ST\n  \n  return(ST)\n  \n}\n\nms_preproc <- function(d) {\n  \n  # Since we our participants could fill the fields in any order, \n  # here is a function which allows us to count correct inputs \n  # our subjects made.\n  \n  n_count <- function(df) {\n    df |> select(matches(\"^noun\")) |> as.matrix() -> s\n    df |> select(matches(\"^resp\")) |> as.matrix() -> r\n    a <- vector(mode = \"numeric\", length = 16L)\n    for (i in 1:16) {\n      a[i] <- sum(r[i, ] %in% s[i, ])\n    }\n    return(a)\n  }\n  \n  if (\"mouse_MSe.time\" %in% colnames(d)) {\n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"resp\\\\d\\\\.text$\"),\n      \"mouse_MSe.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\") |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"rt\" = \"mouse_MSe.time\"\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"MSm.text$\"),\n      \"mouse_MSm.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\") |> \n      rename(\"rt\" = \"mouse_MSm.time\") |>\n      rename_with(.fn = str_replace_all, \n                  pattern = \"_MSm\\\\.text\", \n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"MSh.text$\"),\n      \"mouse_MSh.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\") |>\n      rename(\"rt\" = \"mouse_MSh.time\") |> \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\",\n                  replacement = \"\") -> MS_hard\n    \n  } else {\n    \n    d |> select(matches(\"^noun\"),\n                matches(\"resp\\\\d\\\\.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\",\n             rt = NA) |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(matches(\"^noun\"),\n                matches(\"MSm.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\",\n             rt = NA) |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSm\\\\.text\",\n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(matches(\"^noun\"),\n                matches(\"MSh.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\",\n             rt = NA) |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\", \n                  replacement = \"\") -> MS_hard\n  }\n  \n  tibble(\n    #id = MS_easy$id[1],\n    trials = 1:16,\n    MS_easy_n = n_count(MS_easy),\n    MS_easy_rt = MS_easy$rt,\n    MS_medium_n = n_count(MS_medium),\n    MS_medium_rt = MS_medium$rt,\n    MS_hard_n = n_count(MS_hard),\n    MS_hard_rt = MS_hard$rt\n  ) |>\n    pivot_longer(cols = -c(\"trials\"), values_to = \"value\") |>\n    separate(name, c(\"task\", \"level\", \"name\")) |>\n    pivot_wider(values_from = value, names_from = name) |>\n    mutate(acc = ifelse(level == \"easy\", n / 3,\n                        ifelse(\n                          level == \"medium\", n / 5,\n                          ifelse(level == \"hard\", n / 7, NA)\n                        ))) -> MS\n  \n  return(MS)\n  \n}\n\nnasatlx_preproc <- function(d) {\n  d |> select(slider.response,\n              head,\n              task_type,\n              task_level) |>\n    filter_at(vars(head, task_type, task_level), all_vars(!is.na(.))) |>\n    rename(\"score\" = slider.response) |>\n    mutate(\n      scale = recode(\n        head,\n        \"Умственная нагрузка\" = \"ME\",\n        \"Физическая нагрузка\" = \"PH\",\n        \"Давление времени\" = \"TI\",\n        \"Успешность выполнения\" = \"PE\",\n        \"Усилия\" = \"EF\",\n        \"Уровень фрустрации\" = \"FR\"\n      ),\n      task = recode(\n        task_type,\n        \"mental_rotation\" = \"MR\",\n        \"sternberg\" = \"ST\",\n        \"mental_span\" = \"MS\"\n      ),\n      level = recode(\n        task_level,\n        \"1\" = \"easy\",\n        \"2\" = \"medium\",\n        \"3\" = \"hard\"\n      )\n    ) |>\n    select(scale, score, task, level) -> NASATLX\n  \n  return(NASATLX)\n}\n\n# sequence_preproc <- function(d) {\n#   \n#   d |> select(\n#     E_rotation,\n#     M_rotation,\n#     H_rotation,\n#     E_Sternberg,\n#     M_Sternberg,\n#     H_Sternberg,\n#     E_span,\n#     M_span,\n#     H_span\n#   ) |>\n#     drop_na() |>\n#     sapply(function(x) which(x == 1)) -> v \n#   \n#   tibble(name = names(v),\n#          order = v,\n#          id = d[[\"Индивидуальный_код\"]][1]) |>\n#     arrange(order) |>\n#     separate(name, c(\"level\", \"task\"), \"_\") |>\n#     mutate(\n#       task = recode(\n#         task,\n#         \"rotation\" = \"MR\",\n#         \"Sternberg\" = \"ST\",\n#         \"span\" = \"MS\"\n#       ),\n#       level = recode(\n#         level,\n#         \"E\" = \"easy\",\n#         \"M\" = \"medium\",\n#         \"H\" = \"hard\"\n#       )\n#     ) -> SEQUENCE\n#   \n#   return(SEQUENCE)\n#   \n# }\n\n\n\n\nTo compare\n\nread_csv(\"../preproc-data/MR_firstbanch_data_agg.csv\") -> MR_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/MS_firstbanch_data_agg.csv\") -> MS_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/ST_firstbanch_data_agg.csv\") -> ST_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nfiles <- paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\"))\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool1/365de3d587a6051d9066b869baebe6e2_toloka_2023-07-18_16h41.40.855.csv\"\n[1] \"../data-toloka/pool1/6af6b02e8c1c6bd3a161eb57c5e15aec_toloka_2023-07-18_16h45.12.214.csv\"\n[1] \"../data-toloka/pool1/BM1907_toloka_2023-07-19_12h24.59.648.csv\"\n[1] \"../data-toloka/pool1/EK_87c83102d38e143f82f3ee0ba479365c_toloka_2023-07-19_10h44.00.598.csv\"\n[1] \"../data-toloka/pool1/ОВ1907_toloka_2023-07-19_10h50.37.778.csv\"\n\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 360 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\n\n\n\nfiles <- paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\"))\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool2/22.12.1976_toloka_2023-07-20_13h46.18.948.csv\"\n[1] \"../data-toloka/pool2/AA1907_toloka_2023-07-19_18h28.35.931.csv\"\n[1] \"../data-toloka/pool2/AS1907_toloka_2023-07-19_16h28.42.052.csv\"\n[1] \"../data-toloka/pool2/AT1907_toloka_2023-07-19_21h02.24.635.csv\"\n[1] \"../data-toloka/pool2/EA19.07.2023_toloka_2023-07-19_15h45.55.420.csv\"\n[1] \"../data-toloka/pool2/ES1907_toloka_2023-07-19_23h27.32.195.csv\"\n[1] \"../data-toloka/pool2/GV1907_toloka_2023-07-19_16h56.45.263.csv\"\n[1] \"../data-toloka/pool2/tolkacheva_toloka_2023-07-19_17h00.04.319.csv\"\n[1] \"../data-toloka/pool2/VG1907_toloka_2023-07-19_16h28.02.926.csv\"\n[1] \"../data-toloka/pool2/VN1907_toloka_2023-07-19_16h30.33.286.csv\"\n\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 720 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\n\n\n\nfiles <- c(\n  paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\")),\n  paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\"))\n)\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool1/365de3d587a6051d9066b869baebe6e2_toloka_2023-07-18_16h41.40.855.csv\"\n[1] \"../data-toloka/pool1/6af6b02e8c1c6bd3a161eb57c5e15aec_toloka_2023-07-18_16h45.12.214.csv\"\n[1] \"../data-toloka/pool1/BM1907_toloka_2023-07-19_12h24.59.648.csv\"\n[1] \"../data-toloka/pool1/EK_87c83102d38e143f82f3ee0ba479365c_toloka_2023-07-19_10h44.00.598.csv\"\n[1] \"../data-toloka/pool1/ОВ1907_toloka_2023-07-19_10h50.37.778.csv\"\n[1] \"../data-toloka/pool2/22.12.1976_toloka_2023-07-20_13h46.18.948.csv\"\n[1] \"../data-toloka/pool2/AA1907_toloka_2023-07-19_18h28.35.931.csv\"\n[1] \"../data-toloka/pool2/AS1907_toloka_2023-07-19_16h28.42.052.csv\"\n[1] \"../data-toloka/pool2/AT1907_toloka_2023-07-19_21h02.24.635.csv\"\n[1] \"../data-toloka/pool2/EA19.07.2023_toloka_2023-07-19_15h45.55.420.csv\"\n[1] \"../data-toloka/pool2/ES1907_toloka_2023-07-19_23h27.32.195.csv\"\n[1] \"../data-toloka/pool2/GV1907_toloka_2023-07-19_16h56.45.263.csv\"\n[1] \"../data-toloka/pool2/tolkacheva_toloka_2023-07-19_17h00.04.319.csv\"\n[1] \"../data-toloka/pool2/VG1907_toloka_2023-07-19_16h28.02.926.csv\"\n[1] \"../data-toloka/pool2/VN1907_toloka_2023-07-19_16h30.33.286.csv\"\n\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  labs(title = \"ST\")\n\n\n\n\n\n\n\n\npool88 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40236288__21-07-2023.tsv\")\n\nRows: 7 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:meds, OUTPUT:gender, OUTPUT:diseases,...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (13): GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GOLDEN:gender...\ndttm  (5): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:accepted, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npool87 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40260687__21-07-2023.tsv\")\n\nRows: 4 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:id, OUTPUT:meds, OUTPUT:gender, OUTPU...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (14): GOLDEN:id, GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GO...\ndttm  (4): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:accepted, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npool68 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40272468__21-07-2023.tsv\")\n\nRows: 20 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:id, OUTPUT:meds, OUTPUT:gender, OUTPU...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (12): GOLDEN:id, GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GO...\ndttm  (6): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:accepted, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npool16 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40307616__21-07-2023.tsv\")\n\nRows: 43 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:id, OUTPUT:meds, OUTPUT:gender, OUTPU...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (13): GOLDEN:id, GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GO...\ndttm  (5): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:rejected, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npool88$`ASSIGNMENT:worker_id` %in% pool87$`ASSIGNMENT:worker_id` |> sum()\n\n[1] 0\n\npool88$`ASSIGNMENT:worker_id` %in% pool68$`ASSIGNMENT:worker_id` |> sum()\n\n[1] 0\n\npool88$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |> sum()\n\n[1] 0\n\npool87$`ASSIGNMENT:worker_id` %in% pool68$`ASSIGNMENT:worker_id` |> sum()\n\n[1] 0\n\npool87$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |> sum()\n\n[1] 0\n\npool68$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |> sum()\n\n[1] 2\n\n## duplicates\npool68$`ASSIGNMENT:worker_id`[pool68$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id`]\n\n[1] \"f19c1b96415fa4ebadffa0b9fdf0b666\" \"040267dc3213d9bb136605f74e9fd81f\"\n\n\n\n\n\n\n#rm(list=ls())\n\n\n## broken Column `mouse_MSh.time` doesn't exist.\nfile.remove(\"../data-toloka/pool34/21111984_toloka_2023-07-21_17h42.24.114.csv\")\n\nWarning in\nfile.remove(\"../data-toloka/pool34/21111984_toloka_2023-07-21_17h42.24.114.csv\"):\ncannot remove file\n'../data-toloka/pool34/21111984_toloka_2023-07-21_17h42.24.114.csv', reason 'No\nsuch file or directory'\n\n\n[1] FALSE\n\n\n\nfiles <- paste0(\"../data-toloka/pool34/\", dir(\"../data-toloka/pool34\"))\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool34/01.09.1988_toloka_2023-07-21_16h03.32.707.csv\"\n[1] \"../data-toloka/pool34/010390_toloka_2023-07-21_13h41.57.595.csv\"\n[1] \"../data-toloka/pool34/02.10.1992_toloka_2023-07-21_13h49.46.426.csv\"\n[1] \"../data-toloka/pool34/03.07.1987_toloka_2023-07-21_18h22.46.276.csv\"\n[1] \"../data-toloka/pool34/031186_toloka_2023-07-21_13h45.33.796.csv\"\n[1] \"../data-toloka/pool34/03121996_toloka_2023-07-21_19h46.15.237.csv\"\n[1] \"../data-toloka/pool34/04.11.1995_toloka_2023-07-21_18h39.24.717.csv\"\n[1] \"../data-toloka/pool34/040485_toloka_2023-07-21_17h36.41.405.csv\"\n[1] \"../data-toloka/pool34/040485_toloka_2023-07-21_17h56.38.378.csv\"\n[1] \"../data-toloka/pool34/040897_toloka_2023-07-21_15h56.53.591.csv\"\n[1] \"../data-toloka/pool34/05011994_toloka_2023-07-21_18h04.14.803.csv\"\n[1] \"../data-toloka/pool34/060302_toloka_2023-07-21_15h02.31.748.csv\"\n[1] \"../data-toloka/pool34/06051987_toloka_2023-07-21_18h25.49.317.csv\"\n[1] \"../data-toloka/pool34/09021990_toloka_2023-07-21_13h41.16.661.csv\"\n[1] \"../data-toloka/pool34/090291_toloka_2023-07-21_23h39.02.549.csv\"\n[1] \"../data-toloka/pool34/10111988_toloka_2023-07-21_13h28.34.745.csv\"\n[1] \"../data-toloka/pool34/120786_toloka_2023-07-21_15h34.34.535.csv\"\n[1] \"../data-toloka/pool34/13.01.1989_toloka_2023-07-21_18h04.48.759.csv\"\n[1] \"../data-toloka/pool34/14021986_toloka_2023-07-21_18h07.50.397.csv\"\n[1] \"../data-toloka/pool34/140800_toloka_2023-07-21_22h35.26.001.csv\"\n[1] \"../data-toloka/pool34/1511987_toloka_2023-07-21_22h11.58.878.csv\"\n[1] \"../data-toloka/pool34/151295_toloka_2023-07-21_14h20.24.718.csv\"\n[1] \"../data-toloka/pool34/16121987_toloka_2023-07-21_14h15.15.295.csv\"\n[1] \"../data-toloka/pool34/17.06.1988_toloka_2023-07-21_13h56.37.405.csv\"\n[1] \"../data-toloka/pool34/19091998_toloka_2023-07-21_13h59.25.510.csv\"\n[1] \"../data-toloka/pool34/19121989_toloka_2023-07-21_18h44.23.764.csv\"\n[1] \"../data-toloka/pool34/201085_toloka_2023-07-21_13h48.03.696.csv\"\n[1] \"../data-toloka/pool34/20121998_toloka_2023-07-21_18h21.19.291.csv\"\n[1] \"../data-toloka/pool34/210499_toloka_2023-07-21_13h37.56.499.csv\"\n[1] \"../data-toloka/pool34/210723_toloka_2023-07-21_18h40.05.195.csv\"\n[1] \"../data-toloka/pool34/211104_toloka_2023-07-21_17h06.29.907.csv\"\n[1] \"../data-toloka/pool34/230697_toloka_2023-07-21_23h40.02.926.csv\"\n[1] \"../data-toloka/pool34/230799_toloka_2023-07-21_21h03.46.166.csv\"\n[1] \"../data-toloka/pool34/24051985_toloka_2023-07-21_14h07.46.171.csv\"\n[1] \"../data-toloka/pool34/26042003_toloka_2023-07-21_20h24.07.570.csv\"\n[1] \"../data-toloka/pool34/27.11.1987_toloka_2023-07-21_18h20.10.164.csv\"\n[1] \"../data-toloka/pool34/28101993_toloka_2023-07-21_14h03.32.293.csv\"\n[1] \"../data-toloka/pool34/281184_toloka_2023-07-21_20h40.16.637.csv\"\n[1] \"../data-toloka/pool34/291295_toloka_2023-07-21_14h47.45.284.csv\"\n[1] \"../data-toloka/pool34/300305_toloka_2023-07-21_14h46.09.683.csv\"\n[1] \"../data-toloka/pool34/301099_toloka_2023-07-22_11h34.54.059.csv\"\n[1] \"../data-toloka/pool34/31081998_toloka_2023-07-21_13h39.43.342.csv\"\n\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data$file |> unique() |> length()\n\n[1] 42\n\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 3024 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#packages",
    "href": "toloka-explore.html#packages",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\n\n\nrm(list=ls())\n\n\nmr_preproc &lt;- function(d) {\n  \n  require(tidyverse)\n  \n  d |&gt; select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_easy.keys,\n    resp_MR_easy.corr,\n    resp_MR_easy.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_easy.keys,\n      \"is_correct\" = resp_MR_easy.corr,\n      \"rt\" = resp_MR_easy.rt\n    ) -&gt; MR_easy # ready to use\n  \n  \n  d |&gt; select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_medium.keys,\n    resp_MR_medium.corr,\n    resp_MR_medium.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |&gt;  # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_medium.keys,\n      \"is_correct\" = resp_MR_medium.corr,\n      \"rt\" = resp_MR_medium.rt\n    ) -&gt; MR_medium # ready to use\n  \n  \n  \n  d |&gt; select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_hard.keys,\n    resp_MR_hard.corr,\n    resp_MR_hard.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_hard.keys,\n      \"is_correct\" = resp_MR_hard.corr,\n      \"rt\" = resp_MR_hard.rt\n    ) -&gt; MR_hard # ready to use\n  \n  # bind all conditions of mental rotation task to one tibble\n  \n  bind_rows(MR_easy, MR_medium, MR_hard) -&gt; MR\n  \n  return(MR)\n  \n}\n\nst_preproc &lt;- function(d) {\n  \n  require(tidyverse)\n  \n  d |&gt; select(\n    # select columns we need\n    target_present,\n    key_resp_SE.keys,\n    key_resp_SE.corr,\n    key_resp_SE.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SE.keys,\n      \"is_correct\" = key_resp_SE.corr,\n      \"rt\" = key_resp_SE.rt\n    ) -&gt; ST_easy # ready to use\n  \n  d |&gt; select(\n    # select columns we need\n    target_present,\n    key_resp_SM.keys,\n    key_resp_SM.corr,\n    key_resp_SM.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SM.keys,\n      \"is_correct\" = key_resp_SM.corr,\n      \"rt\" = key_resp_SM.rt\n    ) -&gt; ST_medium # ready to use\n  \n  \n  d |&gt; select(\n    # select columns we need\n    target_present,\n    resp_S_H_trials.keys,\n    resp_S_H_trials.corr,\n    resp_S_H_trials.rt\n  ) |&gt;\n    drop_na() |&gt; # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |&gt; # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_S_H_trials.keys,\n      \"is_correct\" = resp_S_H_trials.corr,\n      \"rt\" = resp_S_H_trials.rt\n    ) -&gt; ST_hard # ready to use\n  \n  # bind all conditions of sternberg task to one tibble\n  bind_rows(ST_easy, ST_hard, ST_medium) -&gt; ST\n  \n  return(ST)\n  \n}\n\nms_preproc &lt;- function(d) {\n  \n  # Since we our participants could fill the fields in any order, \n  # here is a function which allows us to count correct inputs \n  # our subjects made.\n  \n  n_count &lt;- function(df) {\n    df |&gt; select(matches(\"^noun\")) |&gt; as.matrix() -&gt; s\n    df |&gt; select(matches(\"^resp\")) |&gt; as.matrix() -&gt; r\n    a &lt;- vector(mode = \"numeric\", length = 16L)\n    for (i in 1:16) {\n      a[i] &lt;- sum(r[i, ] %in% s[i, ])\n    }\n    return(a)\n  }\n  \n  if (\"mouse_MSe.time\" %in% colnames(d)) {\n    \n    d |&gt; select(\n      matches(\"^noun\"),\n      matches(\"resp\\\\d\\\\.text$\"),\n      \"mouse_MSe.time\"\n    ) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"easy\") |&gt;\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"rt\" = \"mouse_MSe.time\"\n      ) |&gt;\n      select(-c(paste0(\"noun\", 4:7))) -&gt; MS_easy\n    \n    d |&gt; select(\n      matches(\"^noun\"),\n      matches(\"MSm.text$\"),\n      \"mouse_MSm.time\"\n    ) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"medium\") |&gt; \n      rename(\"rt\" = \"mouse_MSm.time\") |&gt;\n      rename_with(.fn = str_replace_all, \n                  pattern = \"_MSm\\\\.text\", \n                  replacement = \"\") |&gt; \n      select(-noun6, -noun7) -&gt; MS_medium\n    \n    \n    d |&gt; select(\n      matches(\"^noun\"),\n      matches(\"MSh.text$\"),\n      \"mouse_MSh.time\"\n    ) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"hard\") |&gt;\n      rename(\"rt\" = \"mouse_MSh.time\") |&gt; \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\",\n                  replacement = \"\") -&gt; MS_hard\n    \n  } else {\n    \n    d |&gt; select(matches(\"^noun\"),\n                matches(\"resp\\\\d\\\\.text$\")) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"easy\",\n             rt = NA) |&gt;\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text\n      ) |&gt;\n      select(-c(paste0(\"noun\", 4:7))) -&gt; MS_easy\n    \n    d |&gt; select(matches(\"^noun\"),\n                matches(\"MSm.text$\")) |&gt;\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |&gt;\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"medium\",\n             rt = NA) |&gt;\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSm\\\\.text\",\n                  replacement = \"\") |&gt; \n      select(-noun6, -noun7) -&gt; MS_medium\n    \n    \n    d |&gt; select(matches(\"^noun\"),\n                matches(\"MSh.text$\")) |&gt;\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |&gt;\n      mutate(task = \"MS\",\n             level = \"hard\",\n             rt = NA) |&gt;\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\", \n                  replacement = \"\") -&gt; MS_hard\n  }\n  \n  tibble(\n    #id = MS_easy$id[1],\n    trials = 1:16,\n    MS_easy_n = n_count(MS_easy),\n    MS_easy_rt = MS_easy$rt,\n    MS_medium_n = n_count(MS_medium),\n    MS_medium_rt = MS_medium$rt,\n    MS_hard_n = n_count(MS_hard),\n    MS_hard_rt = MS_hard$rt\n  ) |&gt;\n    pivot_longer(cols = -c(\"trials\"), values_to = \"value\") |&gt;\n    separate(name, c(\"task\", \"level\", \"name\")) |&gt;\n    pivot_wider(values_from = value, names_from = name) |&gt;\n    mutate(acc = ifelse(level == \"easy\", n / 3,\n                        ifelse(\n                          level == \"medium\", n / 5,\n                          ifelse(level == \"hard\", n / 7, NA)\n                        ))) -&gt; MS\n  \n  return(MS)\n  \n}\n\nnasatlx_preproc &lt;- function(d) {\n  d |&gt; select(slider.response,\n              head,\n              task_type,\n              task_level) |&gt;\n    filter_at(vars(head, task_type, task_level), all_vars(!is.na(.))) |&gt;\n    rename(\"score\" = slider.response) |&gt;\n    mutate(\n      scale = recode(\n        head,\n        \"Умственная нагрузка\" = \"ME\",\n        \"Физическая нагрузка\" = \"PH\",\n        \"Давление времени\" = \"TI\",\n        \"Успешность выполнения\" = \"PE\",\n        \"Усилия\" = \"EF\",\n        \"Уровень фрустрации\" = \"FR\"\n      ),\n      task = recode(\n        task_type,\n        \"mental_rotation\" = \"MR\",\n        \"sternberg\" = \"ST\",\n        \"mental_span\" = \"MS\"\n      ),\n      level = recode(\n        task_level,\n        \"1\" = \"easy\",\n        \"2\" = \"medium\",\n        \"3\" = \"hard\"\n      )\n    ) |&gt;\n    select(scale, score, task, level) -&gt; NASATLX\n  \n  return(NASATLX)\n}\n\n# sequence_preproc &lt;- function(d) {\n#   \n#   d |&gt; select(\n#     E_rotation,\n#     M_rotation,\n#     H_rotation,\n#     E_Sternberg,\n#     M_Sternberg,\n#     H_Sternberg,\n#     E_span,\n#     M_span,\n#     H_span\n#   ) |&gt;\n#     drop_na() |&gt;\n#     sapply(function(x) which(x == 1)) -&gt; v \n#   \n#   tibble(name = names(v),\n#          order = v,\n#          id = d[[\"Индивидуальный_код\"]][1]) |&gt;\n#     arrange(order) |&gt;\n#     separate(name, c(\"level\", \"task\"), \"_\") |&gt;\n#     mutate(\n#       task = recode(\n#         task,\n#         \"rotation\" = \"MR\",\n#         \"Sternberg\" = \"ST\",\n#         \"span\" = \"MS\"\n#       ),\n#       level = recode(\n#         level,\n#         \"E\" = \"easy\",\n#         \"M\" = \"medium\",\n#         \"H\" = \"hard\"\n#       )\n#     ) -&gt; SEQUENCE\n#   \n#   return(SEQUENCE)\n#   \n# }"
  },
  {
    "objectID": "toloka-explore.html#banch-2",
    "href": "toloka-explore.html#banch-2",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "files &lt;- paste0(\"../data-toloka/banch2/\", dir(\"../data-toloka/banch2\"))\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/banch2/22.12.1976_toloka_2023-07-20_13h46.18.948.csv\"\n[1] \"../data-toloka/banch2/AA1907_toloka_2023-07-19_18h28.35.931.csv\"\n[1] \"../data-toloka/banch2/AS1907_toloka_2023-07-19_16h28.42.052.csv\"\n[1] \"../data-toloka/banch2/AT1907_toloka_2023-07-19_21h02.24.635.csv\"\n[1] \"../data-toloka/banch2/EA19.07.2023_toloka_2023-07-19_15h45.55.420.csv\"\n[1] \"../data-toloka/banch2/ES1907_toloka_2023-07-19_23h27.32.195.csv\"\n[1] \"../data-toloka/banch2/GV1907_toloka_2023-07-19_16h56.45.263.csv\"\n[1] \"../data-toloka/banch2/MA1907_toloka_2023-07-19_16h56.11.966.csv\"\n[1] \"../data-toloka/banch2/tolkacheva_toloka_2023-07-19_17h00.04.319.csv\"\n[1] \"../data-toloka/banch2/VG1907_toloka_2023-07-19_16h28.02.926.csv\"\n[1] \"../data-toloka/banch2/VN1907_toloka_2023-07-19_16h30.33.286.csv\"\n\n\n\n# MR_data |&gt; write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |&gt; write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |&gt; write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 792 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#load-fistbanch-data",
    "href": "toloka-explore.html#load-fistbanch-data",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "To compare\n\nread_csv(\"MR_firstbanch_data_agg.csv\") -&gt; MR_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"MS_firstbanch_data_agg.csv\") -&gt; MS_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"ST_firstbanch_data_agg.csv\") -&gt; ST_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "toloka-explore.html#banch-1",
    "href": "toloka-explore.html#banch-1",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "files &lt;- paste0(\"../data-toloka/banch1/\", dir(\"../data-toloka/banch1\"))\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/banch1/365de3d587a6051d9066b869baebe6e2_toloka_2023-07-18_16h41.40.855.csv\"\n[1] \"../data-toloka/banch1/6af6b02e8c1c6bd3a161eb57c5e15aec_toloka_2023-07-18_16h45.12.214.csv\"\n[1] \"../data-toloka/banch1/BM1907_toloka_2023-07-19_12h24.59.648.csv\"\n[1] \"../data-toloka/banch1/EK_87c83102d38e143f82f3ee0ba479365c_toloka_2023-07-19_10h44.00.598.csv\"\n[1] \"../data-toloka/banch1/ОВ1907_toloka_2023-07-19_10h50.37.778.csv\"\n\n\n\n# MR_data |&gt; write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |&gt; write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |&gt; write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 360 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#banch-1-banch-2-together",
    "href": "toloka-explore.html#banch-1-banch-2-together",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "files &lt;- c(\n  paste0(\"../data-toloka/banch1/\", dir(\"../data-toloka/banch1\")),\n  paste0(\"../data-toloka/banch2/\", dir(\"../data-toloka/banch2\"))\n)\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/banch1/365de3d587a6051d9066b869baebe6e2_toloka_2023-07-18_16h41.40.855.csv\"\n[1] \"../data-toloka/banch1/6af6b02e8c1c6bd3a161eb57c5e15aec_toloka_2023-07-18_16h45.12.214.csv\"\n[1] \"../data-toloka/banch1/BM1907_toloka_2023-07-19_12h24.59.648.csv\"\n[1] \"../data-toloka/banch1/EK_87c83102d38e143f82f3ee0ba479365c_toloka_2023-07-19_10h44.00.598.csv\"\n[1] \"../data-toloka/banch1/ОВ1907_toloka_2023-07-19_10h50.37.778.csv\"\n[1] \"../data-toloka/banch2/22.12.1976_toloka_2023-07-20_13h46.18.948.csv\"\n[1] \"../data-toloka/banch2/AA1907_toloka_2023-07-19_18h28.35.931.csv\"\n[1] \"../data-toloka/banch2/AS1907_toloka_2023-07-19_16h28.42.052.csv\"\n[1] \"../data-toloka/banch2/AT1907_toloka_2023-07-19_21h02.24.635.csv\"\n[1] \"../data-toloka/banch2/EA19.07.2023_toloka_2023-07-19_15h45.55.420.csv\"\n[1] \"../data-toloka/banch2/ES1907_toloka_2023-07-19_23h27.32.195.csv\"\n[1] \"../data-toloka/banch2/GV1907_toloka_2023-07-19_16h56.45.263.csv\"\n[1] \"../data-toloka/banch2/MA1907_toloka_2023-07-19_16h56.11.966.csv\"\n[1] \"../data-toloka/banch2/tolkacheva_toloka_2023-07-19_17h00.04.319.csv\"\n[1] \"../data-toloka/banch2/VG1907_toloka_2023-07-19_16h28.02.926.csv\"\n[1] \"../data-toloka/banch2/VN1907_toloka_2023-07-19_16h30.33.286.csv\"\n\n\n\n# MR_data |&gt; write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |&gt; write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |&gt; write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#assignments-check-ids",
    "href": "toloka-explore.html#assignments-check-ids",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "pool88 &lt;- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40236288__21-07-2023.tsv\")\n\nRows: 7 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:meds, OUTPUT:gender, OUTPUT:diseases,...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (13): GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GOLDEN:gender...\ndttm  (5): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:accepted, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npool87 &lt;- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40260687__21-07-2023.tsv\")\n\nRows: 4 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:id, OUTPUT:meds, OUTPUT:gender, OUTPU...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (14): GOLDEN:id, GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GO...\ndttm  (4): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:accepted, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npool68 &lt;- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40272468__21-07-2023.tsv\")\n\nRows: 20 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:id, OUTPUT:meds, OUTPUT:gender, OUTPU...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (12): GOLDEN:id, GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GO...\ndttm  (6): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:accepted, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npool16 &lt;- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40307616__21-07-2023.tsv\")\n\nRows: 43 Columns: 38\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (15): INPUT:pavlovia_link, OUTPUT:id, OUTPUT:meds, OUTPUT:gender, OUTPU...\ndbl   (5): OUTPUT:age, OUTPUT:code, OUTPUT:sleep, OUTPUT:feeling, ASSIGNMENT...\nlgl  (13): GOLDEN:id, GOLDEN:age, GOLDEN:code, GOLDEN:meds, GOLDEN:sleep, GO...\ndttm  (5): ASSIGNMENT:started, ASSIGNMENT:submitted, ASSIGNMENT:rejected, AS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npool88$`ASSIGNMENT:worker_id` %in% pool87$`ASSIGNMENT:worker_id` |&gt; sum()\n\n[1] 0\n\npool88$`ASSIGNMENT:worker_id` %in% pool68$`ASSIGNMENT:worker_id` |&gt; sum()\n\n[1] 0\n\npool88$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |&gt; sum()\n\n[1] 0\n\npool87$`ASSIGNMENT:worker_id` %in% pool68$`ASSIGNMENT:worker_id` |&gt; sum()\n\n[1] 0\n\npool87$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |&gt; sum()\n\n[1] 0\n\npool68$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |&gt; sum()\n\n[1] 2\n\n## duplicates\npool68$`ASSIGNMENT:worker_id`[pool68$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id`]\n\n[1] \"f19c1b96415fa4ebadffa0b9fdf0b666\" \"040267dc3213d9bb136605f74e9fd81f\""
  },
  {
    "objectID": "toloka-explore.html#load-first-data",
    "href": "toloka-explore.html#load-first-data",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "To compare\n\nread_csv(\"MR_firstbanch_data_agg.csv\") -&gt; MR_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"MS_firstbanch_data_agg.csv\") -&gt; MS_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"ST_firstbanch_data_agg.csv\") -&gt; ST_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "toloka-explore.html#pool-1",
    "href": "toloka-explore.html#pool-1",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "files &lt;- paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\"))\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool1/365de3d587a6051d9066b869baebe6e2_toloka_2023-07-18_16h41.40.855.csv\"\n[1] \"../data-toloka/pool1/6af6b02e8c1c6bd3a161eb57c5e15aec_toloka_2023-07-18_16h45.12.214.csv\"\n[1] \"../data-toloka/pool1/BM1907_toloka_2023-07-19_12h24.59.648.csv\"\n[1] \"../data-toloka/pool1/EK_87c83102d38e143f82f3ee0ba479365c_toloka_2023-07-19_10h44.00.598.csv\"\n[1] \"../data-toloka/pool1/ОВ1907_toloka_2023-07-19_10h50.37.778.csv\"\n\n\n\n# MR_data |&gt; write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |&gt; write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |&gt; write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 360 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#pool-2",
    "href": "toloka-explore.html#pool-2",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "files &lt;- paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\"))\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool2/22.12.1976_toloka_2023-07-20_13h46.18.948.csv\"\n[1] \"../data-toloka/pool2/AA1907_toloka_2023-07-19_18h28.35.931.csv\"\n[1] \"../data-toloka/pool2/AS1907_toloka_2023-07-19_16h28.42.052.csv\"\n[1] \"../data-toloka/pool2/AT1907_toloka_2023-07-19_21h02.24.635.csv\"\n[1] \"../data-toloka/pool2/EA19.07.2023_toloka_2023-07-19_15h45.55.420.csv\"\n[1] \"../data-toloka/pool2/ES1907_toloka_2023-07-19_23h27.32.195.csv\"\n[1] \"../data-toloka/pool2/GV1907_toloka_2023-07-19_16h56.45.263.csv\"\n[1] \"../data-toloka/pool2/tolkacheva_toloka_2023-07-19_17h00.04.319.csv\"\n[1] \"../data-toloka/pool2/VG1907_toloka_2023-07-19_16h28.02.926.csv\"\n[1] \"../data-toloka/pool2/VN1907_toloka_2023-07-19_16h30.33.286.csv\"\n\n\n\n# MR_data |&gt; write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |&gt; write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |&gt; write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 720 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#pool-1-pool-2-together",
    "href": "toloka-explore.html#pool-1-pool-2-together",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "files &lt;- c(\n  paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\")),\n  paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\"))\n)\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool1/365de3d587a6051d9066b869baebe6e2_toloka_2023-07-18_16h41.40.855.csv\"\n[1] \"../data-toloka/pool1/6af6b02e8c1c6bd3a161eb57c5e15aec_toloka_2023-07-18_16h45.12.214.csv\"\n[1] \"../data-toloka/pool1/BM1907_toloka_2023-07-19_12h24.59.648.csv\"\n[1] \"../data-toloka/pool1/EK_87c83102d38e143f82f3ee0ba479365c_toloka_2023-07-19_10h44.00.598.csv\"\n[1] \"../data-toloka/pool1/ОВ1907_toloka_2023-07-19_10h50.37.778.csv\"\n[1] \"../data-toloka/pool2/22.12.1976_toloka_2023-07-20_13h46.18.948.csv\"\n[1] \"../data-toloka/pool2/AA1907_toloka_2023-07-19_18h28.35.931.csv\"\n[1] \"../data-toloka/pool2/AS1907_toloka_2023-07-19_16h28.42.052.csv\"\n[1] \"../data-toloka/pool2/AT1907_toloka_2023-07-19_21h02.24.635.csv\"\n[1] \"../data-toloka/pool2/EA19.07.2023_toloka_2023-07-19_15h45.55.420.csv\"\n[1] \"../data-toloka/pool2/ES1907_toloka_2023-07-19_23h27.32.195.csv\"\n[1] \"../data-toloka/pool2/GV1907_toloka_2023-07-19_16h56.45.263.csv\"\n[1] \"../data-toloka/pool2/tolkacheva_toloka_2023-07-19_17h00.04.319.csv\"\n[1] \"../data-toloka/pool2/VG1907_toloka_2023-07-19_16h28.02.926.csv\"\n[1] \"../data-toloka/pool2/VN1907_toloka_2023-07-19_16h30.33.286.csv\"\n\n\n\n# MR_data |&gt; write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |&gt; write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |&gt; write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#pools-3-4",
    "href": "toloka-explore.html#pools-3-4",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "#rm(list=ls())\n\n\n## broken Column `mouse_MSh.time` doesn't exist.\nfile.remove(\"../data-toloka/pool34/21111984_toloka_2023-07-21_17h42.24.114.csv\")\n\nWarning in\nfile.remove(\"../data-toloka/pool34/21111984_toloka_2023-07-21_17h42.24.114.csv\"):\ncannot remove file\n'../data-toloka/pool34/21111984_toloka_2023-07-21_17h42.24.114.csv', reason 'No\nsuch file or directory'\n\n\n[1] FALSE\n\n\n\nfiles &lt;- paste0(\"../data-toloka/pool34/\", dir(\"../data-toloka/pool34\"))\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool34/01.09.1988_toloka_2023-07-21_16h03.32.707.csv\"\n[1] \"../data-toloka/pool34/010390_toloka_2023-07-21_13h41.57.595.csv\"\n[1] \"../data-toloka/pool34/02.10.1992_toloka_2023-07-21_13h49.46.426.csv\"\n[1] \"../data-toloka/pool34/03.07.1987_toloka_2023-07-21_18h22.46.276.csv\"\n[1] \"../data-toloka/pool34/031186_toloka_2023-07-21_13h45.33.796.csv\"\n[1] \"../data-toloka/pool34/03121996_toloka_2023-07-21_19h46.15.237.csv\"\n[1] \"../data-toloka/pool34/04.11.1995_toloka_2023-07-21_18h39.24.717.csv\"\n[1] \"../data-toloka/pool34/040485_toloka_2023-07-21_17h36.41.405.csv\"\n[1] \"../data-toloka/pool34/040485_toloka_2023-07-21_17h56.38.378.csv\"\n[1] \"../data-toloka/pool34/040897_toloka_2023-07-21_15h56.53.591.csv\"\n[1] \"../data-toloka/pool34/05011994_toloka_2023-07-21_18h04.14.803.csv\"\n[1] \"../data-toloka/pool34/060302_toloka_2023-07-21_15h02.31.748.csv\"\n[1] \"../data-toloka/pool34/06051987_toloka_2023-07-21_18h25.49.317.csv\"\n[1] \"../data-toloka/pool34/09021990_toloka_2023-07-21_13h41.16.661.csv\"\n[1] \"../data-toloka/pool34/090291_toloka_2023-07-21_23h39.02.549.csv\"\n[1] \"../data-toloka/pool34/10111988_toloka_2023-07-21_13h28.34.745.csv\"\n[1] \"../data-toloka/pool34/120786_toloka_2023-07-21_15h34.34.535.csv\"\n[1] \"../data-toloka/pool34/13.01.1989_toloka_2023-07-21_18h04.48.759.csv\"\n[1] \"../data-toloka/pool34/14021986_toloka_2023-07-21_18h07.50.397.csv\"\n[1] \"../data-toloka/pool34/140800_toloka_2023-07-21_22h35.26.001.csv\"\n[1] \"../data-toloka/pool34/1511987_toloka_2023-07-21_22h11.58.878.csv\"\n[1] \"../data-toloka/pool34/151295_toloka_2023-07-21_14h20.24.718.csv\"\n[1] \"../data-toloka/pool34/16121987_toloka_2023-07-21_14h15.15.295.csv\"\n[1] \"../data-toloka/pool34/17.06.1988_toloka_2023-07-21_13h56.37.405.csv\"\n[1] \"../data-toloka/pool34/19091998_toloka_2023-07-21_13h59.25.510.csv\"\n[1] \"../data-toloka/pool34/19121989_toloka_2023-07-21_18h44.23.764.csv\"\n[1] \"../data-toloka/pool34/201085_toloka_2023-07-21_13h48.03.696.csv\"\n[1] \"../data-toloka/pool34/20121998_toloka_2023-07-21_18h21.19.291.csv\"\n[1] \"../data-toloka/pool34/210499_toloka_2023-07-21_13h37.56.499.csv\"\n[1] \"../data-toloka/pool34/210723_toloka_2023-07-21_18h40.05.195.csv\"\n[1] \"../data-toloka/pool34/211104_toloka_2023-07-21_17h06.29.907.csv\"\n[1] \"../data-toloka/pool34/230697_toloka_2023-07-21_23h40.02.926.csv\"\n[1] \"../data-toloka/pool34/230799_toloka_2023-07-21_21h03.46.166.csv\"\n[1] \"../data-toloka/pool34/24051985_toloka_2023-07-21_14h07.46.171.csv\"\n[1] \"../data-toloka/pool34/26042003_toloka_2023-07-21_20h24.07.570.csv\"\n[1] \"../data-toloka/pool34/27.11.1987_toloka_2023-07-21_18h20.10.164.csv\"\n[1] \"../data-toloka/pool34/28101993_toloka_2023-07-21_14h03.32.293.csv\"\n[1] \"../data-toloka/pool34/281184_toloka_2023-07-21_20h40.16.637.csv\"\n[1] \"../data-toloka/pool34/291295_toloka_2023-07-21_14h47.45.284.csv\"\n[1] \"../data-toloka/pool34/300305_toloka_2023-07-21_14h46.09.683.csv\"\n[1] \"../data-toloka/pool34/301099_toloka_2023-07-22_11h34.54.059.csv\"\n[1] \"../data-toloka/pool34/31081998_toloka_2023-07-21_13h39.43.342.csv\"\n\n\n\n# MR_data |&gt; write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |&gt; write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |&gt; write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data$file |&gt; unique() |&gt; length()\n\n[1] 42\n\n\n\nMR_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMR_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\nWarning: Removed 3024 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_data |&gt; \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\n\n\n\nST_data |&gt; \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nST_data |&gt; \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "toloka-explore.html#all-toloka-files",
    "href": "toloka-explore.html#all-toloka-files",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "## dropped with low accuracy\nfile.remove(\"../data-toloka/pool2/MA1907_toloka_2023-07-19_16h56.11.966.csv\")\n\nWarning in\nfile.remove(\"../data-toloka/pool2/MA1907_toloka_2023-07-19_16h56.11.966.csv\"):\ncannot remove file\n'../data-toloka/pool2/MA1907_toloka_2023-07-19_16h56.11.966.csv', reason 'No\nsuch file or directory'\n\n\n[1] FALSE\n\n\n\nfiles &lt;- c(\n  paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\")),\n  paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\")),\n  paste0(\"../data-toloka/pool34/\", dir(\"../data-toloka/pool34\"))\n)\n\n\nMR_data &lt;- tibble()\nST_data &lt;- tibble()\nMS_data &lt;- tibble()\nNASATLX_data &lt;- tibble()\n#SEQUENCE_data &lt;- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d &lt;- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |&gt; bind_rows(mr_preproc(d) |&gt; mutate(file = files[i])) -&gt; MR_data\n  ST_data |&gt; bind_rows(st_preproc(d) |&gt; mutate(file = files[i])) -&gt; ST_data\n  MS_data |&gt; bind_rows(ms_preproc(d) |&gt; mutate(file = files[i])) -&gt; MS_data\n  NASATLX_data |&gt; bind_rows(nasatlx_preproc(d) |&gt; mutate(file = files[i])) -&gt; NASATLX_data\n  #SEQUENCE_data |&gt; bind_rows(sequence_preproc(d)) -&gt; SEQUENCE_data\n  \n}\n\n[1] \"../data-toloka/pool1/365de3d587a6051d9066b869baebe6e2_toloka_2023-07-18_16h41.40.855.csv\"\n[1] \"../data-toloka/pool1/6af6b02e8c1c6bd3a161eb57c5e15aec_toloka_2023-07-18_16h45.12.214.csv\"\n[1] \"../data-toloka/pool1/BM1907_toloka_2023-07-19_12h24.59.648.csv\"\n[1] \"../data-toloka/pool1/EK_87c83102d38e143f82f3ee0ba479365c_toloka_2023-07-19_10h44.00.598.csv\"\n[1] \"../data-toloka/pool1/ОВ1907_toloka_2023-07-19_10h50.37.778.csv\"\n[1] \"../data-toloka/pool2/22.12.1976_toloka_2023-07-20_13h46.18.948.csv\"\n[1] \"../data-toloka/pool2/AA1907_toloka_2023-07-19_18h28.35.931.csv\"\n[1] \"../data-toloka/pool2/AS1907_toloka_2023-07-19_16h28.42.052.csv\"\n[1] \"../data-toloka/pool2/AT1907_toloka_2023-07-19_21h02.24.635.csv\"\n[1] \"../data-toloka/pool2/EA19.07.2023_toloka_2023-07-19_15h45.55.420.csv\"\n[1] \"../data-toloka/pool2/ES1907_toloka_2023-07-19_23h27.32.195.csv\"\n[1] \"../data-toloka/pool2/GV1907_toloka_2023-07-19_16h56.45.263.csv\"\n[1] \"../data-toloka/pool2/tolkacheva_toloka_2023-07-19_17h00.04.319.csv\"\n[1] \"../data-toloka/pool2/VG1907_toloka_2023-07-19_16h28.02.926.csv\"\n[1] \"../data-toloka/pool2/VN1907_toloka_2023-07-19_16h30.33.286.csv\"\n[1] \"../data-toloka/pool34/01.09.1988_toloka_2023-07-21_16h03.32.707.csv\"\n[1] \"../data-toloka/pool34/010390_toloka_2023-07-21_13h41.57.595.csv\"\n[1] \"../data-toloka/pool34/02.10.1992_toloka_2023-07-21_13h49.46.426.csv\"\n[1] \"../data-toloka/pool34/03.07.1987_toloka_2023-07-21_18h22.46.276.csv\"\n[1] \"../data-toloka/pool34/031186_toloka_2023-07-21_13h45.33.796.csv\"\n[1] \"../data-toloka/pool34/03121996_toloka_2023-07-21_19h46.15.237.csv\"\n[1] \"../data-toloka/pool34/04.11.1995_toloka_2023-07-21_18h39.24.717.csv\"\n[1] \"../data-toloka/pool34/040485_toloka_2023-07-21_17h36.41.405.csv\"\n[1] \"../data-toloka/pool34/040485_toloka_2023-07-21_17h56.38.378.csv\"\n[1] \"../data-toloka/pool34/040897_toloka_2023-07-21_15h56.53.591.csv\"\n[1] \"../data-toloka/pool34/05011994_toloka_2023-07-21_18h04.14.803.csv\"\n[1] \"../data-toloka/pool34/060302_toloka_2023-07-21_15h02.31.748.csv\"\n[1] \"../data-toloka/pool34/06051987_toloka_2023-07-21_18h25.49.317.csv\"\n[1] \"../data-toloka/pool34/09021990_toloka_2023-07-21_13h41.16.661.csv\"\n[1] \"../data-toloka/pool34/090291_toloka_2023-07-21_23h39.02.549.csv\"\n[1] \"../data-toloka/pool34/10111988_toloka_2023-07-21_13h28.34.745.csv\"\n[1] \"../data-toloka/pool34/120786_toloka_2023-07-21_15h34.34.535.csv\"\n[1] \"../data-toloka/pool34/13.01.1989_toloka_2023-07-21_18h04.48.759.csv\"\n[1] \"../data-toloka/pool34/14021986_toloka_2023-07-21_18h07.50.397.csv\"\n[1] \"../data-toloka/pool34/140800_toloka_2023-07-21_22h35.26.001.csv\"\n[1] \"../data-toloka/pool34/1511987_toloka_2023-07-21_22h11.58.878.csv\"\n[1] \"../data-toloka/pool34/151295_toloka_2023-07-21_14h20.24.718.csv\"\n[1] \"../data-toloka/pool34/16121987_toloka_2023-07-21_14h15.15.295.csv\"\n[1] \"../data-toloka/pool34/17.06.1988_toloka_2023-07-21_13h56.37.405.csv\"\n[1] \"../data-toloka/pool34/19091998_toloka_2023-07-21_13h59.25.510.csv\"\n[1] \"../data-toloka/pool34/19121989_toloka_2023-07-21_18h44.23.764.csv\"\n[1] \"../data-toloka/pool34/201085_toloka_2023-07-21_13h48.03.696.csv\"\n[1] \"../data-toloka/pool34/20121998_toloka_2023-07-21_18h21.19.291.csv\"\n[1] \"../data-toloka/pool34/210499_toloka_2023-07-21_13h37.56.499.csv\"\n[1] \"../data-toloka/pool34/210723_toloka_2023-07-21_18h40.05.195.csv\"\n[1] \"../data-toloka/pool34/211104_toloka_2023-07-21_17h06.29.907.csv\"\n[1] \"../data-toloka/pool34/230697_toloka_2023-07-21_23h40.02.926.csv\"\n[1] \"../data-toloka/pool34/230799_toloka_2023-07-21_21h03.46.166.csv\"\n[1] \"../data-toloka/pool34/24051985_toloka_2023-07-21_14h07.46.171.csv\"\n[1] \"../data-toloka/pool34/26042003_toloka_2023-07-21_20h24.07.570.csv\"\n[1] \"../data-toloka/pool34/27.11.1987_toloka_2023-07-21_18h20.10.164.csv\"\n[1] \"../data-toloka/pool34/28101993_toloka_2023-07-21_14h03.32.293.csv\"\n[1] \"../data-toloka/pool34/281184_toloka_2023-07-21_20h40.16.637.csv\"\n[1] \"../data-toloka/pool34/291295_toloka_2023-07-21_14h47.45.284.csv\"\n[1] \"../data-toloka/pool34/300305_toloka_2023-07-21_14h46.09.683.csv\"\n[1] \"../data-toloka/pool34/301099_toloka_2023-07-22_11h34.54.059.csv\"\n[1] \"../data-toloka/pool34/31081998_toloka_2023-07-21_13h39.43.342.csv\"\n\n\n\n\n\nset.seed(116)\ntibble(file = MR_data$file |&gt; unique(),\n       id = stringi::stri_rand_strings(MR_data$file |&gt; unique() |&gt; length(),\n                                       length = 10)) -&gt; tolokaIDS\n\n\n\n\n\nMR_data |&gt; \n  full_join(tolokaIDS) |&gt; \n  select(-file) |&gt; \n  group_by(task, level, id) |&gt; \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -&gt; MR_data_toloka_agg\n\nJoining with `by = join_by(file)`\n`summarise()` has grouped output by 'task', 'level'. You can override using the\n`.groups` argument.\n\nST_data |&gt; \n  full_join(tolokaIDS) |&gt; \n  select(-file) |&gt; \n  group_by(task, level, id) |&gt; \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -&gt; ST_data_toloka_agg\n\nJoining with `by = join_by(file)`\n`summarise()` has grouped output by 'task', 'level'. You can override using the\n`.groups` argument.\n\nMS_data |&gt; \n  full_join(tolokaIDS) |&gt; \n  select(-file) |&gt; \n  group_by(task, level, id) |&gt; \n  summarise(rt = mean(rt),\n            acc = mean(acc)) -&gt; MS_data_toloka_agg\n\nJoining with `by = join_by(file)`\n`summarise()` has grouped output by 'task', 'level'. You can override using the\n`.groups` argument.\n\nNASATLX_data |&gt; \n  full_join(tolokaIDS) |&gt; \n  select(-file) -&gt; NASATLX_data_toloka\n\nJoining with `by = join_by(file)`\n\n\n\nMR_data_toloka_agg |&gt; write_csv(\"mental_rotation_data_toloka.csv\")\nST_data_toloka_agg |&gt; write_csv(\"sternberg_data_toloka.csv\")\nMS_data_toloka_agg |&gt; write_csv(\"mental_span_data_toloka.csv\")\nNASATLX_data_toloka |&gt; write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |&gt; write_csv(\"sequence_data_toloka.csv\")\n\n\nrm(list = ls())"
  },
  {
    "objectID": "toloka-explore.html#load-first-data-toloka-aggregated-data",
    "href": "toloka-explore.html#load-first-data-toloka-aggregated-data",
    "title": "Yandex.Toloka Data Exploration",
    "section": "",
    "text": "read_csv(\"MR_firstbanch_data_agg.csv\") -&gt; MR_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"MS_firstbanch_data_agg.csv\") -&gt; MS_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"ST_firstbanch_data_agg.csv\") -&gt; ST_fb_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"NASATLX_firstbanch_data.csv\") -&gt; NASATLX_fb\n\nRows: 4212 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): scale, task, level, id\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"mental_rotation_data_toloka.csv\") -&gt; MR_data_toloka\n\nRows: 171 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"mental_span_data_toloka.csv\") -&gt; MS_data_toloka\n\nRows: 171 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"sternberg_data_toloka.csv\") -&gt; ST_data_toloka\n\nRows: 171 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"nasa_tlx_data_toloka.csv\") -&gt; NASATLX_data_toloka\n\nRows: 3078 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): scale, task, level, id\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nMR_fb_agg |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    MR_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) -&gt; MR_full\n\nMS_fb_agg |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    MS_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) -&gt; MS_full\n\nST_fb_agg |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    ST_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) -&gt; ST_full\n\nNASATLX_fb |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    NASATLX_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) -&gt; NASATLX_full\n\n\npd &lt;- position_dodge(.3)\n\n\nMR_full |&gt; \n  ggplot(aes(level, rt, color = banch)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\", position = pd) +\n  labs(title = \"MR rt\")\n\n\n\n\n\nMR_full |&gt; \n  ggplot(aes(level, acc, color = banch)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\", position = pd) +\n  labs(title = \"MR acc\")\n\n\n\n\n\nMS_full |&gt; \n  ggplot(aes(level, rt, color = banch)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\", position = pd) +\n  labs(title = \"MS rt\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_full |&gt; \n  ggplot(aes(level, acc, color = banch)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\", position = pd) +\n  labs(title = \"MS acc\")\n\n\n\n\n\nST_full |&gt; \n  ggplot(aes(level, rt, color = banch)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\", position = pd) +\n  labs(title = \"ST rt\")\n\n\n\n\n\nST_full |&gt; \n  ggplot(aes(level, acc, color = banch)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\", position = pd) +\n  labs(title = \"ST acc\")\n\n\n\n\n\nNASATLX_full |&gt; \n  ggplot(aes(scale, score, color = level, shape = banch)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\", position = pd) +\n  facet_grid(task ~ .) +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"NASA-TLX\")\n\nWarning: Removed 17 rows containing non-finite values (`stat_summary()`)."
  },
  {
    "objectID": "analysis_toloka.html",
    "href": "analysis_toloka.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "# knitr::opts_chunk$set(eval = FALSE)\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ntheme_set(theme_bw()) # set black and white theme\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(lmerTest)\n\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(MuMIn)\nlibrary(pwr)\nlibrary(ez)\n\n\nrm(list = ls())\n\n\n\n\n\nMR_data <- read_csv(\"../preproc-data/MR-tol-data.csv\")\n\nRows: 3312 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): correctAns, base_pic, rotated_pic, key, task, level, id, pool\ndbl (3): is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nST_data <- read_csv(\"../preproc-data/ST-tol-data.csv\")\n\nRows: 3312 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): key, task, level, id, pool\ndbl (4): target_present, is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nMS_data <- read_csv(\"../preproc-data/MS-tol-data.csv\")\n\nRows: 3312 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): task, level, id, pool\ndbl (4): trials, n, rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nNASATLX_data <- read_csv(\"../preproc-data/NASATLX-tol-data.csv\")\n\nRows: 3726 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): task, level, id, pool, scale\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nSEQUENCE_data <- read_csv(\"../preproc-data/SEQ-tol-data.csv\")\n\nRows: 621 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): level, task, id, pool\ndbl (1): order\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nWEIGHTS_data <- read_csv(\"../preproc-data/WEIGHTS-tol-data.csv\")\n\nRows: 1062 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): task_type, choice, id, pool\ndbl (2): n, w\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nis_outlier <- function(x) ifelse(x > quantile(x, .25, na.rm = TRUE) - 1.5 * IQR(x, na.rm = TRUE) &\n                                   x < quantile(x, .75, na.rm = TRUE) + 1.5 * IQR(x, na.rm = TRUE),\n                                 FALSE, TRUE)\n\n\n\n\nMR_data |> \n  group_by(id, level, task) |> \n  mutate(is_outlier = is_outlier(rt)) |> \n  filter(!is_outlier) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> MR_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMR_data_agg |> write_csv(\"../preproc-data/MR_tol_data_agg.csv\")\n\n\n\n\n\nMS_data |> \n  group_by(id, level, task) |> \n  mutate(is_outlier = is_outlier(rt)) |> \n  filter(!is_outlier) |> \n  summarise(rt = mean(rt),\n            acc = mean(acc)) -> MS_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMS_data_agg |> write_csv(\"../preproc-data/MS_tol_data_agg.csv\")\n\n\n\n\n\nST_data |> \n  group_by(id, level, task) |> \n  mutate(is_outlier = is_outlier(rt)) |> \n  filter(!is_outlier) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> ST_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nST_data_agg |> write_csv(\"../preproc-data/ST_tol_data_agg.csv\")\n\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) |>\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, rt)) +\n  facet_wrap(~ task, scales = \"free_y\", \n             labeller = labeller(task = c(MR = \"Mental Rotation\",\n                                          MS = \"Memory Span\", \n                                          ST = \"Sternberg Task\"))) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(x = \"Difficulty Level\", y = \"Reaction time, s\")\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) |>\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, acc)) +\n  facet_wrap(~ task, scales = \"free_y\", \n             labeller = labeller(task = c(MR = \"Mental Rotation\",\n                                          MS = \"Memory Span\", \n                                          ST = \"Sternberg Task\"))) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(x = \"Difficulty Level\", y = \"Accuracy\")\n\n\n\n\n\n\n\n\n\n\nMR_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt),\n            median = median(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  # mutate_all(.funs = function(x) if (is.double(x)) return(round(x, 2)) else return(x)) |> \n  knitr::kable(caption = \"Mental Rotation. Reaction Time\", digits = 2)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMental Rotation. Reaction Time\n\n\nlevel\ntask\nn\nmean\nmedian\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMR\n69\n4.16\n4.02\n2.12\n0.09\n9.59\n3.66\n4.66\n\n\nhard\nMR\n69\n7.43\n5.37\n5.85\n0.67\n29.15\n6.05\n8.81\n\n\nmedium\nMR\n69\n6.17\n5.21\n3.96\n0.15\n18.82\n5.24\n7.10\n\n\n\n\n\n\nMR_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  # mutate_all(.funs = function(x) if (is.double(x)) return(round(x, 3)) else return(x)) |> \n  knitr::kable(caption = \"Mental Rotation. Accuracy\", digits = 3)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMental Rotation. Accuracy\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMR\n69\n0.728\n0.222\n0.250\n1\n0.676\n0.781\n\n\nhard\nMR\n69\n0.615\n0.185\n0.286\n1\n0.571\n0.659\n\n\nmedium\nMR\n69\n0.681\n0.233\n0.125\n1\n0.626\n0.736\n\n\n\n\n\n\n\n\n\nMS_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt, na.rm = TRUE),\n            median = median(rt, na.rm = TRUE),\n            sd = sd(rt, na.rm = TRUE),\n            min = min(rt, na.rm = TRUE),\n            max = max(rt, na.rm = TRUE),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  # mutate_all(.funs = function(x) if (is.double(x)) return(round(x, 2)) else return(x)) |> \n  knitr::kable(caption = \"Memory Span. Reaction Time\", digits = 2)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMemory Span. Reaction Time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlevel\ntask\nn\nmean\nmedian\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMS\n69\n11.12\n9.92\n3.88\n6.21\n25.69\n10.21\n12.04\n\n\nhard\nMS\n69\n24.62\n22.58\n10.82\n6.92\n56.42\n22.07\n27.18\n\n\nmedium\nMS\n69\n21.05\n17.89\n9.06\n8.70\n54.38\n18.92\n23.19\n\n\n\n\n\n\nMS_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  knitr::kable(caption = \"Memory Span. Accuracy\", digits = 3)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMemory Span. Accuracy\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMS\n69\n0.960\n0.088\n0.333\n1\n0.939\n0.980\n\n\nhard\nMS\n69\n0.722\n0.197\n0.200\n1\n0.676\n0.769\n\n\nmedium\nMS\n69\n0.896\n0.112\n0.537\n1\n0.870\n0.922\n\n\n\n\n\n\n\n\n\nST_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  knitr::kable(caption = \"Sternberg Task. Reaction Time\", digits = 2)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nSternberg Task. Reaction Time\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nST\n69\n1.15\n0.40\n0.58\n2.23\n1.06\n1.25\n\n\nhard\nST\n69\n1.64\n1.05\n0.82\n5.20\n1.39\n1.89\n\n\nmedium\nST\n69\n1.41\n0.62\n0.07\n3.51\n1.26\n1.55\n\n\n\n\n\n\nST_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  knitr::kable(caption = \"Sternberg Task. Accuracy\", digits = 3)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nSternberg Task. Accuracy\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nST\n69\n0.972\n0.064\n0.625\n1\n0.957\n0.987\n\n\nhard\nST\n69\n0.730\n0.152\n0.385\n1\n0.694\n0.765\n\n\nmedium\nST\n69\n0.856\n0.121\n0.375\n1\n0.828\n0.885\n\n\n\n\n\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) -> all_tol_data_agg\n\n\n\n\nezANOVA(data = all_tol_data_agg,\n        dv = rt,\n        wid = id,\n        within = .(task, level),\n        detailed = TRUE) |> \n  psychReport::aovEffectSize() -> rt_anova\n\nWarning: Converting \"id\" to factor for ANOVA.\n\n\nWarning: Converting \"task\" to factor for ANOVA.\n\n\nWarning: Converting \"level\" to factor for ANOVA.\n\nrt_anova$ANOVA |> \n  knitr::kable(caption = \"Accuracy ANOVA Results\", digits = 3)\n\n\nAccuracy ANOVA Results\n\n\nEffect\nDFn\nDFd\nSSn\nSSd\nF\np\np<.05\npes\n\n\n\n\n(Intercept)\n1\n68\n47557.627\n5447.339\n593.669\n0\n*\n0.897\n\n\ntask\n2\n136\n34305.286\n7996.336\n291.729\n0\n*\n0.811\n\n\nlevel\n2\n136\n3625.613\n1791.109\n137.647\n0\n*\n0.669\n\n\ntask:level\n4\n272\n3516.353\n3146.222\n76.000\n0\n*\n0.528\n\n\n\n\nrt_anova$`Mauchly's Test for Sphericity` |> \n  knitr::kable(caption = \"Mauchly's Test for Sphericity Results\", digits = 3)\n\n\nMauchly’s Test for Sphericity Results\n\n\n\nEffect\nW\np\np<.05\n\n\n\n\n2\ntask\n0.486\n0.000\n*\n\n\n3\nlevel\n0.959\n0.244\n\n\n\n4\ntask:level\n0.219\n0.000\n*\n\n\n\n\nrt_anova$`Sphericity Corrections` |> \n  knitr::kable(caption = \"Sphericity Corrections\", digits = 3)\n\n\nSphericity Corrections\n\n\n\nEffect\nGGe\np[GG]\np[GG]<.05\nHFe\np[HF]\np[HF]<.05\n\n\n\n\n2\ntask\n0.661\n0\n*\n0.669\n0\n*\n\n\n3\nlevel\n0.960\n0\n*\n0.988\n0\n*\n\n\n4\ntask:level\n0.603\n0\n*\n0.627\n0\n*\n\n\n\n\n\n\npairwise.t.test(\n  x = all_tol_data_agg$rt,\n  g = interaction(all_tol_data_agg$task,\n                  all_tol_data_agg$level),\n  # paired = TRUE\n  )\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  all_tol_data_agg$rt and interaction(all_tol_data_agg$task, all_tol_data_agg$level) \n\n          MR.easy MS.easy ST.easy MR.hard MS.hard ST.hard MR.medium MS.medium\nMS.easy   5.5e-12 -       -       -       -       -       -         -        \nST.easy   0.01073 < 2e-16 -       -       -       -       -         -        \nMR.hard   0.00429 0.00095 6.8e-10 -       -       -       -         -        \nMS.hard   < 2e-16 < 2e-16 < 2e-16 < 2e-16 -       -       -         -        \nST.hard   0.04328 < 2e-16 1.00000 1.6e-08 < 2e-16 -       -         -        \nMR.medium 0.15675 2.2e-06 1.6e-06 0.70398 < 2e-16 1.9e-05 -         -        \nMS.medium < 2e-16 < 2e-16 < 2e-16 < 2e-16 0.00143 < 2e-16 < 2e-16   -        \nST.medium 0.02327 < 2e-16 1.00000 3.6e-09 < 2e-16 1.00000 5.7e-06   < 2e-16  \n\nP value adjustment method: holm \n\n\n\n\n\n\nezANOVA(data = all_tol_data_agg,\n        dv = acc,\n        wid = id,\n        within = .(task, level),\n        detailed = TRUE) |> \n  psychReport::aovEffectSize() -> acc_anova\n\nWarning: Converting \"id\" to factor for ANOVA.\n\n\nWarning: Converting \"task\" to factor for ANOVA.\n\n\nWarning: Converting \"level\" to factor for ANOVA.\n\nacc_anova$ANOVA |> \n  knitr::kable(caption = \"Accuracy ANOVA Results\", digits = 3)\n\n\nAccuracy ANOVA Results\n\n\nEffect\nDFn\nDFd\nSSn\nSSd\nF\np\np<.05\npes\n\n\n\n\n(Intercept)\n1\n68\n392.980\n4.885\n5470.651\n0\n*\n0.988\n\n\ntask\n2\n136\n4.539\n5.700\n54.153\n0\n*\n0.443\n\n\nlevel\n2\n136\n4.115\n2.032\n137.747\n0\n*\n0.669\n\n\ntask:level\n4\n272\n0.437\n3.584\n8.298\n0\n*\n0.109\n\n\n\n\nacc_anova$`Mauchly's Test for Sphericity` |> \n  knitr::kable(caption = \"Mauchly's Test for Sphericity Results\", digits = 3)\n\n\nMauchly’s Test for Sphericity Results\n\n\n\nEffect\nW\np\np<.05\n\n\n\n\n2\ntask\n0.528\n0.000\n*\n\n\n3\nlevel\n0.928\n0.082\n\n\n\n4\ntask:level\n0.636\n0.000\n*\n\n\n\n\nacc_anova$`Sphericity Corrections` |> \n  knitr::kable(caption = \"Sphericity Corrections\", digits = 3)\n\n\nSphericity Corrections\n\n\n\nEffect\nGGe\np[GG]\np[GG]<.05\nHFe\np[HF]\np[HF]<.05\n\n\n\n\n2\ntask\n0.679\n0\n*\n0.688\n0\n*\n\n\n3\nlevel\n0.933\n0\n*\n0.958\n0\n*\n\n\n4\ntask:level\n0.818\n0\n*\n0.865\n0\n*\n\n\n\n\n\n\npairwise.t.test(\n  x = all_tol_data_agg$acc,\n  g = interaction(all_tol_data_agg$task,\n                  all_tol_data_agg$level),\n  # paired = TRUE\n  )\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  all_tol_data_agg$acc and interaction(all_tol_data_agg$task, all_tol_data_agg$level) \n\n          MR.easy MS.easy ST.easy MR.hard MS.hard ST.hard MR.medium MS.medium\nMS.easy   1.1e-14 -       -       -       -       -       -         -        \nST.easy   4.7e-16 1.00000 -       -       -       -       -         -        \nMR.hard   0.00068 < 2e-16 < 2e-16 -       -       -       -         -        \nMS.hard   1.00000 2.2e-15 < 2e-16 0.00152 -       -       -         -        \nST.hard   1.00000 1.6e-14 6.8e-16 0.00059 1.00000 -       -         -        \nMR.medium 0.62893 < 2e-16 < 2e-16 0.17600 0.80900 0.62893 -         -        \nMS.medium 5.0e-08 0.19633 0.07244 < 2e-16 1.5e-08 6.4e-08 8.0e-13   -        \nST.medium 8.5e-05 0.00242 0.00057 7.9e-16 3.2e-05 0.00010 1.1e-08   0.80900  \n\nP value adjustment method: holm \n\n\n\n\n\n\n\n\nNASATLX_data |> \n  # fix factor\n  mutate(\n    level = factor(\n      level,\n      levels = c(\"easy\", \"medium\", \"hard\"),\n      ordered = TRUE\n    )\n  ) -> NASATLX_data\n\n\nlevel_colors <- c(\"#4bd752\", \"#d7984b\", \"#d7524b\")\ntask_colors <- c(\"red4\", \"green4\", \"blue4\")\nback_histogram_color <- \"gray60\"\n\n\n\n\nWEIGHTS_data |> \n  rename(\"scale\" = choice,\n         \"task\" = task_type) |> \n  mutate(task = recode(task,\n                       \"mental_rotation\" = \"MR\",\n                       \"sternberg\" = \"ST\",\n                       \"mental_span\" = \"MS\")) |> \n  full_join(NASATLX_data,\n            by = join_by(id, task, scale)) |> \n  select(-pool.x) |> \n  rename(\"pool\" = pool.y) |> \n  mutate(n = ifelse(is.na(n), 0, n),\n         w = ifelse(is.na(w), 0, w)) |> \n  mutate(score_w = w * score,\n         scale_w = paste0(scale, \"_w\")) |> \n  select(id, task, level, scale_w, score_w) |> \n  pivot_wider(values_from = score_w, names_from = scale_w) |> \n  mutate(OW_w = ME_w + PH_w + TI_w + PE_w + EF_w + FR_w) -> nasa_tlx_weighted_wide\n  \nnasa_tlx_weighted_wide |> \n    pivot_longer(cols = -c(\"id\", \"task\", \"level\"),\n               names_to = \"scale_w\", values_to = \"score_w\") -> NASATLX_weighted\n\nnasa_tlx_weighted_wide |> \n    full_join(\n      NASATLX_data |> \n        pivot_wider(values_from = score, names_from = scale) |> \n        mutate(OW = ME + PH + TI + PE + EF + FR),\n      by = join_by(id, task, level)\n      ) -> NASATLX\n\n\nNASATLX_weighted |>\n  filter(scale_w != \"OW_w\") |> \n  ggplot(aes(scale_w, score_w, fill = level)) +\n  geom_boxplot() +\n  facet_grid(task ~ .,\n             labeller = labeller(task = c(\n               MR = \"Mental Rotation\",\n               MS = \"Memory Span\",\n               ST = \"Sternberg Task\"\n             ))) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_fill_manual(values = level_colors)\n\n\n\n\n\npd <- position_dodge(0.3)\nNASATLX_weighted |>\n  filter(scale_w != \"OW_w\") |> \n  ggplot(aes(scale_w, score_w, color = level)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n   facet_grid(task ~ .,\n             labeller = labeller(task = c(\n               MR = \"Mental Rotation\",\n               MS = \"Memory Span\",\n               ST = \"Sternberg Task\"\n             ))) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_color_manual(values = level_colors)\n\n\n\n\n\nNASATLX |>\n  pivot_longer(cols = -c(\"id\", \"task\", \"level\", \"pool\"),\n               names_to = \"scale\", values_to = \"score\") |> \n  filter(str_detect(scale, \"_w\")) |> \n  rename(\"score_w\" = score) |> \n  mutate(scale = str_remove_all(scale, \"_w\")) |> \n  full_join(\n    NASATLX |> \n      pivot_longer(cols = -c(\"id\", \"task\", \"level\", \"pool\"),\n                   names_to = \"scale\", values_to = \"score\") |> \n      filter(!str_detect(scale, \"_w\")),\n    by = join_by(\"id\", \"task\", \"level\", \"scale\", \"pool\")\n  ) -> nasatlx\n\n\nnasatlx |> \n  filter(scale != \"OW\") |> \n  ggplot(aes(score, score_w, color = level)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\") +\n  facet_grid(task ~ scale) +\n  scale_color_manual(values = level_colors) +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nnasatlx |> \n  group_by(task, level, scale) |> \n  summarise(cor = cor(score, score_w)) |> \n  knitr::kable(caption = \"Correlations between raw and weighted scores\",\n               digits = 2)\n\n`summarise()` has grouped output by 'task', 'level'. You can override using the\n`.groups` argument.\n\n\n\nCorrelations between raw and weighted scores\n\n\ntask\nlevel\nscale\ncor\n\n\n\n\nMR\neasy\nEF\n0.91\n\n\nMR\neasy\nFR\n0.77\n\n\nMR\neasy\nME\n0.89\n\n\nMR\neasy\nOW\n0.97\n\n\nMR\neasy\nPE\n0.67\n\n\nMR\neasy\nPH\n0.53\n\n\nMR\neasy\nTI\n0.78\n\n\nMR\nmedium\nEF\n0.91\n\n\nMR\nmedium\nFR\n0.72\n\n\nMR\nmedium\nME\n0.84\n\n\nMR\nmedium\nOW\n0.95\n\n\nMR\nmedium\nPE\n0.52\n\n\nMR\nmedium\nPH\n0.62\n\n\nMR\nmedium\nTI\n0.64\n\n\nMR\nhard\nEF\n0.88\n\n\nMR\nhard\nFR\n0.74\n\n\nMR\nhard\nME\n0.84\n\n\nMR\nhard\nOW\n0.94\n\n\nMR\nhard\nPE\n0.40\n\n\nMR\nhard\nPH\n0.71\n\n\nMR\nhard\nTI\n0.68\n\n\nMS\neasy\nEF\n0.85\n\n\nMS\neasy\nFR\n0.75\n\n\nMS\neasy\nME\n0.88\n\n\nMS\neasy\nOW\n0.98\n\n\nMS\neasy\nPE\n0.71\n\n\nMS\neasy\nPH\n0.55\n\n\nMS\neasy\nTI\n0.87\n\n\nMS\nmedium\nEF\n0.77\n\n\nMS\nmedium\nFR\n0.69\n\n\nMS\nmedium\nME\n0.75\n\n\nMS\nmedium\nOW\n0.96\n\n\nMS\nmedium\nPE\n0.66\n\n\nMS\nmedium\nPH\n0.62\n\n\nMS\nmedium\nTI\n0.75\n\n\nMS\nhard\nEF\n0.67\n\n\nMS\nhard\nFR\n0.63\n\n\nMS\nhard\nME\n0.62\n\n\nMS\nhard\nOW\n0.92\n\n\nMS\nhard\nPE\n0.61\n\n\nMS\nhard\nPH\n0.56\n\n\nMS\nhard\nTI\n0.66\n\n\nST\neasy\nEF\n0.86\n\n\nST\neasy\nFR\n0.73\n\n\nST\neasy\nME\n0.81\n\n\nST\neasy\nOW\n0.97\n\n\nST\neasy\nPE\n0.69\n\n\nST\neasy\nPH\n0.58\n\n\nST\neasy\nTI\n0.87\n\n\nST\nmedium\nEF\n0.69\n\n\nST\nmedium\nFR\n0.61\n\n\nST\nmedium\nME\n0.63\n\n\nST\nmedium\nOW\n0.93\n\n\nST\nmedium\nPE\n0.42\n\n\nST\nmedium\nPH\n0.62\n\n\nST\nmedium\nTI\n0.74\n\n\nST\nhard\nEF\n0.76\n\n\nST\nhard\nFR\n0.62\n\n\nST\nhard\nME\n0.69\n\n\nST\nhard\nOW\n0.86\n\n\nST\nhard\nPE\n0.46\n\n\nST\nhard\nPH\n0.60\n\n\nST\nhard\nTI\n0.74\n\n\n\n\n\n\n\n\n\n\n\nmix_ME_w <- lmer(ME_w ~ task * level + (1|id), \n               nasa_tlx_weighted_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ME_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ME_w ~ task * level + (1 | id)\n   Data: nasa_tlx_weighted_wide\n\nREML criterion at convergence: 4185.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4591 -0.6587 -0.0439  0.6360  2.5992 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 34.13    5.842   \n Residual             40.42    6.358   \nNumber of obs: 621, groups:  id, 69\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          13.028      1.040 228.636  12.533  < 2e-16 ***\ntaskMS               -4.252      1.082 544.000  -3.928 9.66e-05 ***\ntaskST               -5.996      1.082 544.000  -5.539 4.73e-08 ***\nlevelmedium           2.491      1.082 544.000   2.301 0.021766 *  \nlevelhard             3.155      1.082 544.000   2.914 0.003712 ** \ntaskMS:levelmedium    5.288      1.531 544.000   3.454 0.000595 ***\ntaskST:levelmedium    2.875      1.531 544.000   1.878 0.060876 .  \ntaskMS:levelhard      7.388      1.531 544.000   4.826 1.81e-06 ***\ntaskST:levelhard      4.767      1.531 544.000   3.114 0.001942 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.521                                                             \ntaskST      -0.521  0.500                                                      \nlevelmedium -0.521  0.500  0.500                                               \nlevelhard   -0.521  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.368 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.368 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.368 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.368 -0.354 -0.707 -0.354 -0.707  0.250      0.500      0.500    \n\nanova(mix_ME_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \ntask       1628.6  814.31     2   544 20.1438 3.635e-09 ***\nlevel      5732.2 2866.09     2   544 70.8991 < 2.2e-16 ***\ntask:level 1029.4  257.35     4   544  6.3661 5.192e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ME_w)[1]\n\nWarning: 'r.squaredGLMM' now calculates a revised statistic. See the help page.\n\n\n[1] 0.1536195\n\n\n\n\n\n\nmix_PH_w <- lmer(PH_w ~ task * level + (1|id), \n               nasa_tlx_weighted_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PH_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PH_w ~ task * level + (1 | id)\n   Data: nasa_tlx_weighted_wide\n\nREML criterion at convergence: 3350.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.5630 -0.4214 -0.0591  0.1998  6.3665 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 10.46    3.234   \n Residual             10.13    3.183   \nNumber of obs: 621, groups:  id, 69\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)          2.0918     0.5463 199.7198   3.829 0.000172 ***\ntaskMS              -0.4271     0.5420 544.0000  -0.788 0.431052    \ntaskST              -0.3816     0.5420 544.0000  -0.704 0.481616    \nlevelmedium          0.5556     0.5420 544.0000   1.025 0.305778    \nlevelhard            0.4329     0.5420 544.0000   0.799 0.424827    \ntaskMS:levelmedium   1.1758     0.7664 544.0000   1.534 0.125574    \ntaskST:levelmedium   0.2271     0.7664 544.0000   0.296 0.767159    \ntaskMS:levelhard     1.7614     0.7664 544.0000   2.298 0.021936 *  \ntaskST:levelhard     0.8570     0.7664 544.0000   1.118 0.263995    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.496                                                             \ntaskST      -0.496  0.500                                                      \nlevelmedium -0.496  0.500  0.500                                               \nlevelhard   -0.496  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.351 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.351 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.351 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.351 -0.354 -0.707 -0.354 -0.707  0.250      0.500      0.500    \n\nanova(mix_PH_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \ntask        43.654  21.827     2   544  2.1540    0.1170    \nlevel      195.365  97.682     2   544  9.6397 7.691e-05 ***\ntask:level  59.268  14.817     4   544  1.4622    0.2123    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PH_w)[1]\n\n[1] 0.02282704\n\n\n\n\n\n\nmix_TI_w <- lmer(TI_w ~ task * level + (1|id), \n               nasa_tlx_weighted_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_TI_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: TI_w ~ task * level + (1 | id)\n   Data: nasa_tlx_weighted_wide\n\nREML criterion at convergence: 4224.7\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.80483 -0.61342 -0.06484  0.68723  2.57780 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 22.17    4.709   \n Residual             45.41    6.739   \nNumber of obs: 621, groups:  id, 69\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)          3.1459     0.9897 328.8539   3.179 0.001620 ** \ntaskMS               4.2386     1.1473 544.0000   3.694 0.000243 ***\ntaskST               6.6792     1.1473 544.0000   5.822 9.96e-09 ***\nlevelmedium         -0.3295     1.1473 544.0000  -0.287 0.774090    \nlevelhard            0.1150     1.1473 544.0000   0.100 0.920210    \ntaskMS:levelmedium   7.7546     1.6225 544.0000   4.779 2.27e-06 ***\ntaskST:levelmedium  10.5430     1.6225 544.0000   6.498 1.84e-10 ***\ntaskMS:levelhard    11.9227     1.6225 544.0000   7.348 7.40e-13 ***\ntaskST:levelhard    13.1488     1.6225 544.0000   8.104 3.53e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.580                                                             \ntaskST      -0.580  0.500                                                      \nlevelmedium -0.580  0.500  0.500                                               \nlevelhard   -0.580  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.410 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.410 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.410 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.410 -0.354 -0.707 -0.354 -0.707  0.250      0.500      0.500    \n\nanova(mix_TI_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \ntask       23690.8 11845.4     2   544 260.846 < 2.2e-16 ***\nlevel       7753.5  3876.8     2   544  85.370 < 2.2e-16 ***\ntask:level  4003.6  1000.9     4   544  22.041 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_TI_w)[1]\n\n[1] 0.4582838\n\n\n\n\n\n\nmix_PE_w <- lmer(PE_w ~ task * level + (1|id), \n               nasa_tlx_weighted_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PE_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PE_w ~ task * level + (1 | id)\n   Data: nasa_tlx_weighted_wide\n\nREML criterion at convergence: 3645.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.3286 -0.6693 -0.1207  0.5176  4.2801 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept)  9.475   3.078   \n Residual             17.443   4.177   \nNumber of obs: 621, groups:  id, 69\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)          5.8802     0.6246 307.3472   9.414  < 2e-16 ***\ntaskMS              -4.9362     0.7111 544.0000  -6.942 1.10e-11 ***\ntaskST              -4.6232     0.7111 544.0000  -6.502 1.80e-10 ***\nlevelmedium          0.8676     0.7111 544.0000   1.220 0.222919    \nlevelhard            2.0203     0.7111 544.0000   2.841 0.004662 ** \ntaskMS:levelmedium   2.4029     1.0056 544.0000   2.390 0.017209 *  \ntaskST:levelmedium   3.3507     1.0056 544.0000   3.332 0.000921 ***\ntaskMS:levelhard     4.8164     1.0056 544.0000   4.790 2.16e-06 ***\ntaskST:levelhard     4.7034     1.0056 544.0000   4.677 3.67e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.569                                                             \ntaskST      -0.569  0.500                                                      \nlevelmedium -0.569  0.500  0.500                                               \nlevelhard   -0.569  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.402 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.402 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.402 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.402 -0.354 -0.707 -0.354 -0.707  0.250      0.500      0.500    \n\nanova(mix_PE_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \ntask        725.0  362.50     2   544 20.7814 2.009e-09 ***\nlevel      2796.6 1398.31     2   544 80.1628 < 2.2e-16 ***\ntask:level  552.1  138.02     4   544  7.9127 3.331e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PE_w)[1]\n\n[1] 0.196197\n\n\n\n\n\n\nmix_EF_w <- lmer(EF_w ~ task * level + (1|id), \n               nasa_tlx_weighted_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_EF_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF_w ~ task * level + (1 | id)\n   Data: nasa_tlx_weighted_wide\n\nREML criterion at convergence: 4001.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.8519 -0.6249  0.0449  0.6306  3.1487 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 27.50    5.244   \n Residual             29.66    5.446   \nNumber of obs: 621, groups:  id, 69\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)         10.6377     0.9102 214.5876  11.688  < 2e-16 ***\ntaskMS              -3.1362     0.9272 544.0000  -3.383  0.00077 ***\ntaskST              -1.9053     0.9272 544.0000  -2.055  0.04036 *  \nlevelmedium          1.3768     0.9272 544.0000   1.485  0.13814    \nlevelhard            2.5101     0.9272 544.0000   2.707  0.00700 ** \ntaskMS:levelmedium   5.2406     1.3112 544.0000   3.997 7.31e-05 ***\ntaskST:levelmedium   2.8647     1.3112 544.0000   2.185  0.02933 *  \ntaskMS:levelhard     6.1932     1.3112 544.0000   4.723 2.96e-06 ***\ntaskST:levelhard     2.8367     1.3112 544.0000   2.163  0.03094 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.509                                                             \ntaskST      -0.509  0.500                                                      \nlevelmedium -0.509  0.500  0.500                                               \nlevelhard   -0.509  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.360 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.360 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.360 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.360 -0.354 -0.707 -0.354 -0.707  0.250      0.500      0.500    \n\nanova(mix_EF_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \ntask         63.3   31.67     2   544  1.0678    0.3445    \nlevel      3393.7 1696.87     2   544 57.2144 < 2.2e-16 ***\ntask:level  773.2  193.30     4   544  6.5178 3.968e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_EF_w)[1]\n\n[1] 0.1066379\n\n\n\n\n\n\nmix_FR_w <- lmer(FR_w ~ task * level + (1|id), \n               nasa_tlx_weighted_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_FR_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: FR_w ~ task * level + (1 | id)\n   Data: nasa_tlx_weighted_wide\n\nREML criterion at convergence: 4117.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6275 -0.6258 -0.1229  0.5307  3.3016 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 16.38    4.048   \n Residual             38.57    6.211   \nNumber of obs: 621, groups:  id, 69\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)          7.6290     0.8924 357.6922   8.549 3.67e-16 ***\ntaskMS              -1.8734     1.0574 544.0000  -1.772 0.076988 .  \ntaskST              -2.3275     1.0574 544.0000  -2.201 0.028136 *  \nlevelmedium          0.6725     1.0574 544.0000   0.636 0.525055    \nlevelhard            1.7101     1.0574 544.0000   1.617 0.106378    \ntaskMS:levelmedium   3.7237     1.4953 544.0000   2.490 0.013065 *  \ntaskST:levelmedium   3.7652     1.4953 544.0000   2.518 0.012089 *  \ntaskMS:levelhard     5.6560     1.4953 544.0000   3.782 0.000173 ***\ntaskST:levelhard     5.2628     1.4953 544.0000   3.519 0.000469 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.592                                                             \ntaskST      -0.592  0.500                                                      \nlevelmedium -0.592  0.500  0.500                                               \nlevelhard   -0.592  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.419 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.419 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.419 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.419 -0.354 -0.707 -0.354 -0.707  0.250      0.500      0.500    \n\nanova(mix_FR_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \ntask        162.95   81.48     2   544  2.1124  0.121944    \nlevel      2995.82 1497.91     2   544 38.8347 < 2.2e-16 ***\ntask:level  721.07  180.27     4   544  4.6736  0.001024 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_FR_w)[1]\n\n[1] 0.1022324\n\n\n\n\n\n\nmix_OW_w <- lmer(OW_w ~ task * level + (1|id), \n               nasa_tlx_weighted_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_OW_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: OW_w ~ task * level + (1 | id)\n   Data: nasa_tlx_weighted_wide\n\nREML criterion at convergence: 5271.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5968 -0.5987 -0.0564  0.6900  3.1702 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 194.2    13.93   \n Residual             239.5    15.48   \nNumber of obs: 621, groups:  id, 69\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          42.413      2.507 235.058  16.917  < 2e-16 ***\ntaskMS              -10.386      2.635 544.000  -3.942 9.14e-05 ***\ntaskST               -8.555      2.635 544.000  -3.247 0.001240 ** \nlevelmedium           5.634      2.635 544.000   2.138 0.032951 *  \nlevelhard             9.943      2.635 544.000   3.774 0.000179 ***\ntaskMS:levelmedium   25.586      3.726 544.000   6.866 1.81e-11 ***\ntaskST:levelmedium   23.626      3.726 544.000   6.340 4.82e-10 ***\ntaskMS:levelhard     37.738      3.726 544.000  10.127  < 2e-16 ***\ntaskST:levelhard     31.576      3.726 544.000   8.474 2.24e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.525                                                             \ntaskST      -0.525  0.500                                                      \nlevelmedium -0.525  0.500  0.500                                               \nlevelhard   -0.525  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.372 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.372 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.372 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.372 -0.354 -0.707 -0.354 -0.707  0.250      0.500      0.500    \n\nanova(mix_OW_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \ntask        14674    7337     2   544  30.630 2.481e-13 ***\nlevel      117233   58616     2   544 244.717 < 2.2e-16 ***\ntask:level  29934    7483     4   544  31.242 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_OW_w)[1]\n\n[1] 0.3757273"
  },
  {
    "objectID": "analysis_pavlovia.html",
    "href": "analysis_pavlovia.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "knitr::opts_chunk$set(error = TRUE)\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ntheme_set(theme_bw()) # set black and white theme\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(lmerTest)\n\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(MuMIn)\nlibrary(pwr)\nlibrary(ez)\n\n\nrm(list = ls())\n\n\n\n\n\nMR_data <- read_csv(\"../preproc-data/MR_pav_data.csv\")\n\nRows: 3936 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): correctAns, key, task, level, id\ndbl (3): is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nST_data <- read_csv(\"../preproc-data/ST_pav_data.csv\")\n\nRows: 3936 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): key, task, level, id\ndbl (4): target_present, is_correct, rt, trial\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nMS_data <- read_csv(\"../preproc-data/MS_pav_data.csv\")\n\nRows: 3936 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (4): trials, n, rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nNASATLX_data <- read_csv(\"../preproc-data/NASATLX_pav_data.csv\")\n\nRows: 4428 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): task, level, id, scale\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nSEQUENCE_data <- read_csv(\"../preproc-data/SEQ_pav_data.csv\")\n\nRows: 738 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, task, id\ndbl (1): order\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nis_outlier <- function(x) ifelse(x > quantile(x, .25, na.rm = TRUE) - 1.5 * IQR(x, na.rm = TRUE) &\n                                   x < quantile(x, .75, na.rm = TRUE) + 1.5 * IQR(x, na.rm = TRUE),\n                                 FALSE, TRUE)\n\n\n\n\nMR_data |> \n  group_by(id, level, task) |> \n  mutate(is_outlier = is_outlier(rt)) |> \n  filter(!is_outlier) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> MR_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMR_data_agg |> write_csv(\"../preproc-data/MR_pav_data_agg.csv\")\n\n\n\n\n\nMS_data |> \n  group_by(id, level, task) |> \n  mutate(is_outlier = is_outlier(rt)) |> \n  mutate(is_outlier = ifelse(is.na(is_outlier), FALSE, is_outlier)) |> \n  filter(!is_outlier) |> \n  summarise(rt = mean(rt),\n            acc = mean(acc)) -> MS_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nMS_data_agg |> write_csv(\"../preproc-data/MS_pav_data_agg.csv\")\n\n\n\n\n\nST_data |> \n  group_by(id, level, task) |> \n  mutate(is_outlier = is_outlier(rt)) |> \n  filter(!is_outlier) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> ST_data_agg\n\n`summarise()` has grouped output by 'id', 'level'. You can override using the\n`.groups` argument.\n\n\n\nST_data_agg |> write_csv(\"../preproc-data/ST_firstbanch_data_agg.csv\")\n\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) |>\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, rt)) +\n  facet_wrap(~ task, scales = \"free_y\", \n             labeller = labeller(task = c(MR = \"Mental Rotation\",\n                                          MS = \"Memory Span\", \n                                          ST = \"Sternberg Task\"))) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(x = \"Difficulty Level\", y = \"Reaction time, s\")\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) |>\n  mutate(level = factor(level, \n                        ordered = TRUE, \n                        levels = c(\"easy\", \"medium\", \"hard\"))) |> \n  ggplot(aes(level, acc)) +\n  facet_wrap(~ task, scales = \"free_y\", \n             labeller = labeller(task = c(MR = \"Mental Rotation\",\n                                          MS = \"Memory Span\", \n                                          ST = \"Sternberg Task\"))) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(x = \"Difficulty Level\", y = \"Accuracy\")\n\n\n\n\n\n\n\n\n\n\nMR_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt),\n            median = median(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  # mutate_all(.funs = function(x) if (is.double(x)) return(round(x, 2)) else return(x)) |> \n  knitr::kable(caption = \"Mental Rotation. Reaction Time\", digits = 2)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMental Rotation. Reaction Time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlevel\ntask\nn\nmean\nmedian\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMR\n82\n6.48\n5.41\n4.03\n1.17\n25.47\n5.61\n7.35\n\n\nhard\nMR\n82\n10.85\n8.43\n8.02\n0.50\n44.55\n9.11\n12.59\n\n\nmedium\nMR\n82\n8.22\n7.02\n5.51\n0.31\n33.12\n7.02\n9.41\n\n\n\n\n\n\nMR_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  # mutate_all(.funs = function(x) if (is.double(x)) return(round(x, 3)) else return(x)) |> \n  knitr::kable(caption = \"Mental Rotation. Accuracy\", digits = 3)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMental Rotation. Accuracy\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMR\n82\n0.849\n0.169\n0.286\n1\n0.813\n0.886\n\n\nhard\nMR\n82\n0.720\n0.183\n0.333\n1\n0.680\n0.759\n\n\nmedium\nMR\n82\n0.750\n0.180\n0.250\n1\n0.711\n0.789\n\n\n\n\n\n\n\n\n\nMS_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt, na.rm = TRUE),\n            median = median(rt, na.rm = TRUE),\n            sd = sd(rt, na.rm = TRUE),\n            min = min(rt, na.rm = TRUE),\n            max = max(rt, na.rm = TRUE),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  # mutate_all(.funs = function(x) if (is.double(x)) return(round(x, 2)) else return(x)) |> \n  knitr::kable(caption = \"Memory Span. Reaction Time\", digits = 2)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMemory Span. Reaction Time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlevel\ntask\nn\nmean\nmedian\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMS\n82\n10.50\n10.03\n2.78\n5.47\n23.47\n9.90\n11.10\n\n\nhard\nMS\n82\n20.59\n19.92\n5.91\n11.24\n39.57\n19.31\n21.87\n\n\nmedium\nMS\n82\n17.83\n16.83\n4.68\n9.47\n32.31\n16.82\n18.85\n\n\n\n\n\n\nMS_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  knitr::kable(caption = \"Memory Span. Accuracy\", digits = 3)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nMemory Span. Accuracy\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nMS\n82\n0.955\n0.161\n0\n1.000\n0.921\n0.990\n\n\nhard\nMS\n82\n0.635\n0.169\n0\n0.989\n0.599\n0.672\n\n\nmedium\nMS\n82\n0.883\n0.169\n0\n1.000\n0.846\n0.919\n\n\n\n\n\n\n\n\n\nST_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(rt),\n            sd = sd(rt),\n            min = min(rt),\n            max = max(rt),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  knitr::kable(caption = \"Sternberg Task. Reaction Time\", digits = 2)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nSternberg Task. Reaction Time\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nST\n82\n1.04\n0.29\n0.61\n2.23\n0.98\n1.11\n\n\nhard\nST\n82\n1.27\n0.39\n0.72\n2.73\n1.18\n1.35\n\n\nmedium\nST\n82\n1.24\n0.39\n0.69\n2.92\n1.16\n1.32\n\n\n\n\n\n\nST_data_agg |> \n  group_by(level, task) |> \n  summarise(n = unique(id) |> length(),\n            mean = mean(acc),\n            sd = sd(acc),\n            min = min(acc),\n            max = max(acc),\n            CI_lower = mean - 1.96 * sd / sqrt(n),\n            CI_upper = mean + 1.96 * sd / sqrt(n)) |> \n  knitr::kable(caption = \"Sternberg Task. Accuracy\", digits = 3)\n\n`summarise()` has grouped output by 'level'. You can override using the\n`.groups` argument.\n\n\n\nSternberg Task. Accuracy\n\n\nlevel\ntask\nn\nmean\nsd\nmin\nmax\nCI_lower\nCI_upper\n\n\n\n\neasy\nST\n82\n0.981\n0.034\n0.857\n1\n0.974\n0.988\n\n\nhard\nST\n82\n0.693\n0.140\n0.286\n1\n0.663\n0.724\n\n\nmedium\nST\n82\n0.833\n0.112\n0.600\n1\n0.809\n0.857\n\n\n\n\n\n\n\n\n\n\nMR_data_agg |> \n  bind_rows(MS_data_agg, ST_data_agg) -> all_pav_data_agg\n\n\n\n\nlmer(rt ~ task * level + (1|id), all_pav_data_agg) |> anova()\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask       21801.9 10900.9     2 597.41 726.399 < 2.2e-16 ***\nlevel       2648.6  1324.3     2 579.04  88.248 < 2.2e-16 ***\ntask:level  1837.9   459.5     4 579.04  30.618 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\npairwise.t.test(\n  x = all_pav_data_agg$rt,\n  g = interaction(all_pav_data_agg$task,\n                  all_pav_data_agg$level),\n  # paired = TRUE\n  )\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  all_pav_data_agg$rt and interaction(all_pav_data_agg$task, all_pav_data_agg$level) \n\n          MR.easy MS.easy ST.easy MR.hard MS.hard ST.hard MR.medium MS.medium\nMS.easy   1.2e-06 -       -       -       -       -       -         -        \nST.easy   1.4e-13 < 2e-16 -       -       -       -       -         -        \nMR.hard   3.7e-09 1.0000  < 2e-16 -       -       -       -         -        \nMS.hard   < 2e-16 < 2e-16 < 2e-16 < 2e-16 -       -       -         -        \nST.hard   1.2e-12 < 2e-16 1.0000  < 2e-16 < 2e-16 -       -         -        \nMR.medium 0.0586  0.0153  < 2e-16 0.0011  < 2e-16 < 2e-16 -         -        \nMS.medium < 2e-16 < 2e-16 < 2e-16 < 2e-16 0.0054  < 2e-16 < 2e-16   -        \nST.medium 9.7e-13 < 2e-16 1.0000  < 2e-16 < 2e-16 1.0000  < 2e-16   < 2e-16  \n\nP value adjustment method: holm \n\n\n\n\n\n\nezANOVA(data = all_pav_data_agg,\n        dv = acc,\n        wid = id,\n        within = .(task, level),\n        detailed = TRUE) |> \n  psychReport::aovEffectSize() -> acc_anova\n\nWarning: Converting \"id\" to factor for ANOVA.\n\n\nWarning: Converting \"task\" to factor for ANOVA.\n\n\nWarning: Converting \"level\" to factor for ANOVA.\n\nacc_anova$ANOVA |> \n  knitr::kable(caption = \"Accuracy ANOVA Results\", digits = 3)\n\n\nAccuracy ANOVA Results\n\n\nEffect\nDFn\nDFd\nSSn\nSSd\nF\np\np<.05\npes\n\n\n\n\n(Intercept)\n1\n81\n485.579\n5.747\n6844.383\n0.000\n*\n0.988\n\n\ntask\n2\n162\n0.551\n6.378\n6.996\n0.001\n*\n0.080\n\n\nlevel\n2\n162\n7.473\n1.750\n345.896\n0.000\n*\n0.810\n\n\ntask:level\n4\n324\n1.288\n3.198\n32.635\n0.000\n*\n0.287\n\n\n\n\nacc_anova$`Mauchly's Test for Sphericity` |> \n  knitr::kable(caption = \"Mauchly's Test for Sphericity Results\", digits = 3)\n\n\nMauchly’s Test for Sphericity Results\n\n\n\nEffect\nW\np\np<.05\n\n\n\n\n2\ntask\n0.944\n0.101\n\n\n\n3\nlevel\n0.952\n0.138\n\n\n\n4\ntask:level\n0.558\n0.000\n*\n\n\n\n\nacc_anova$`Sphericity Corrections` |> \n  knitr::kable(caption = \"Sphericity Corrections\", digits = 3)\n\n\nSphericity Corrections\n\n\n\nEffect\nGGe\np[GG]\np[GG]<.05\nHFe\np[HF]\np[HF]<.05\n\n\n\n\n2\ntask\n0.947\n0.002\n*\n0.969\n0.001\n*\n\n\n3\nlevel\n0.954\n0.000\n*\n0.976\n0.000\n*\n\n\n4\ntask:level\n0.825\n0.000\n*\n0.864\n0.000\n*\n\n\n\n\n\n\npairwise.t.test(\n  x = all_pav_data_agg$acc,\n  g = interaction(all_pav_data_agg$task,\n                  all_pav_data_agg$level),\n  # paired = TRUE\n  )\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  all_pav_data_agg$acc and interaction(all_pav_data_agg$task, all_pav_data_agg$level) \n\n          MR.easy MS.easy ST.easy MR.hard MS.hard ST.hard MR.medium MS.medium\nMS.easy   0.00015 -       -       -       -       -       -         -        \nST.easy   9.8e-07 0.81992 -       -       -       -       -         -        \nMR.hard   1.4e-06 < 2e-16 < 2e-16 -       -       -       -         -        \nMS.hard   < 2e-16 < 2e-16 < 2e-16 0.00506 -       -       -         -        \nST.hard   2.8e-09 < 2e-16 < 2e-16 0.81992 0.12511 -       -         -        \nMR.medium 0.00047 1.4e-15 < 2e-16 0.80900 3.1e-05 0.12544 -         -        \nMS.medium 0.80888 0.02269 0.00055 4.2e-10 < 2e-16 2.1e-13 7.7e-07   -        \nST.medium 0.81992 6.7e-06 2.2e-08 3.8e-05 1.7e-14 1.6e-07 0.00554   0.22252  \n\nP value adjustment method: holm \n\n\n\n\n\n\n\n\nNASATLX_data |> \n  # fix factor\n  mutate(\n    level = factor(\n      level,\n      levels = c(\"easy\", \"medium\", \"hard\"),\n      ordered = TRUE\n    )\n  ) -> NASATLX_data\n\n\nlevel_colors <- c(\"#4bd752\", \"#d7984b\", \"#d7524b\")\ntask_colors <- c(\"red4\", \"green4\", \"blue4\")\nback_histogram_color <- \"gray60\"\n\n\nNASATLX_data |>\n  ggplot(aes(scale, score, fill = level)) +\n  geom_boxplot() +\n  facet_grid(task ~ .,\n             labeller = labeller(task = c(\n               MR = \"Mental Rotation\",\n               MS = \"Memory Span\",\n               ST = \"Sternberg Task\"\n             ))) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_fill_manual(values = level_colors)\n\nWarning: Removed 17 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\npd <- position_dodge(0.3)\nNASATLX_data |>\n  ggplot(aes(scale, score, color = level)) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n   facet_grid(task ~ .,\n             labeller = labeller(task = c(\n               MR = \"Mental Rotation\",\n               MS = \"Memory Span\",\n               ST = \"Sternberg Task\"\n             ))) +\n  theme(legend.position = \"bottom\") +\n  labs(x = \"NASA-TLX Scale\",\n       y = \"NASA-TLX Score (raw)\",\n       fill = \"Difficulty Level\") +\n  scale_color_manual(values = level_colors)\n\nWarning: Removed 17 rows containing non-finite values (`stat_summary()`).\nRemoved 17 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\n\n\nNASATLX_data |> \n  pivot_wider(values_from = score, names_from = scale) |> \n  mutate(OW = ME + PH + TI + PE + EF + FR) -> nasa_tlx_wide\n\n\nr2tof2 <- function(r2) r2 / (1 - r2)\n\n\n\n\nmix_ME <- lmer(ME ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ME)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ME ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6410.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1726 -0.5600  0.0696  0.6668  3.1041 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 170.0    13.04   \n Residual             302.7    17.40   \nNumber of obs: 737, groups:  id, 82\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          46.805      2.401 358.129  19.496  < 2e-16 ***\ntaskMS              -17.098      2.717 647.017  -6.293 5.74e-10 ***\ntaskST              -18.915      2.717 647.017  -6.962 8.27e-12 ***\nlevelmedium          12.280      2.717 647.017   4.520 7.35e-06 ***\nlevelhard            20.744      2.717 647.017   7.635 8.14e-14 ***\ntaskMS:levelmedium   19.012      3.842 647.017   4.948 9.57e-07 ***\ntaskST:levelmedium   13.756      3.842 647.017   3.580 0.000369 ***\ntaskMS:levelhard     27.195      3.842 647.017   7.078 3.82e-12 ***\ntaskST:levelhard     18.786      3.849 647.106   4.881 1.33e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.566                                                             \ntaskST      -0.566  0.500                                                      \nlevelmedium -0.566  0.500  0.500                                               \nlevelhard   -0.566  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.400 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.400 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.400 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.399 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_ME)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask         8876    4438     2 647.06  14.664 5.913e-07 ***\nlevel      164121   82060     2 647.06 271.138 < 2.2e-16 ***\ntask:level  16796    4199     4 647.06  13.874 7.280e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ME)[1]\n\nWarning: 'r.squaredGLMM' now calculates a revised statistic. See the help page.\n\n\n[1] 0.3532078\n\nr2tof2(r.squaredGLMM(mix_ME)[1])\n\n[1] 0.5460916\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_ME)[1]),\n            u = 8,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 8\n              v = 27.02187\n             f2 = 0.5460916\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_PH <- lmer(PH ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PH)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PH ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6010.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4289 -0.4807 -0.0901  0.3849  4.8395 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 423.5    20.58   \n Residual             161.6    12.71   \nNumber of obs: 730, groups:  id, 82\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)         16.9324     2.6764 141.3648   6.327  3.1e-09 ***\ntaskMS              -2.5980     2.0136 640.2532  -1.290 0.197442    \ntaskST              -5.1763     1.9924 640.0904  -2.598 0.009593 ** \nlevelmedium          0.8481     1.9924 640.0904   0.426 0.670511    \nlevelhard            5.6407     1.9924 640.0904   2.831 0.004785 ** \ntaskMS:levelmedium   9.4686     2.8328 640.1745   3.343 0.000879 ***\ntaskST:levelmedium   7.9455     2.8178 640.0960   2.820 0.004954 ** \ntaskMS:levelhard     8.4367     2.8366 640.1449   2.974 0.003047 ** \ntaskST:levelhard     7.0056     2.8129 640.0683   2.491 0.013008 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.371                                                             \ntaskST      -0.375  0.498                                                      \nlevelmedium -0.375  0.498  0.503                                               \nlevelhard   -0.375  0.498  0.503  0.503                                        \ntskMS:lvlmd  0.264 -0.711 -0.354 -0.703 -0.354                                 \ntskST:lvlmd  0.265 -0.352 -0.707 -0.707 -0.356  0.497                          \ntskMS:lvlhr  0.263 -0.709 -0.354 -0.354 -0.702  0.504      0.250               \ntskST:lvlhr  0.265 -0.353 -0.708 -0.357 -0.708  0.251      0.501      0.498    \n\nanova(mix_PH)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask        1935.5   967.8     2 640.15  5.9870  0.002654 ** \nlevel      14371.3  7185.7     2 640.11 44.4535 < 2.2e-16 ***\ntask:level  2508.2   627.0     4 640.13  3.8792  0.004018 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PH)[1]\n\n[1] 0.04227157\n\nr2tof2(r.squaredGLMM(mix_PH)[1])\n\n[1] 0.04413732\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PH)[1]),\n            u = 8,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 8\n              v = 339.176\n             f2 = 0.04413732\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_TI <- lmer(TI ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_TI)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: TI ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6555.1\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-3.10715 -0.61638 -0.03702  0.64252  2.91380 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 152.5    12.35   \n Residual             380.8    19.51   \nNumber of obs: 737, groups:  id, 82\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          14.659      2.550 440.326   5.748 1.69e-08 ***\ntaskMS                4.232      3.047 646.980   1.389    0.165    \ntaskST               12.317      3.047 646.980   4.042 5.94e-05 ***\nlevelmedium           1.841      3.047 646.980   0.604    0.546    \nlevelhard             4.207      3.047 646.980   1.381    0.168    \ntaskMS:levelmedium   31.646      4.310 646.980   7.343 6.30e-13 ***\ntaskST:levelmedium   34.093      4.317 647.095   7.897 1.23e-14 ***\ntaskMS:levelhard     52.732      4.310 646.980  12.235  < 2e-16 ***\ntaskST:levelhard     51.561      4.310 646.980  11.964  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.598                                                             \ntaskST      -0.598  0.500                                                      \nlevelmedium -0.598  0.500  0.500                                               \nlevelhard   -0.598  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.423 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.422 -0.353 -0.706 -0.706 -0.353  0.499                          \ntskMS:lvlhr  0.423 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.423 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_TI)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask       228453  114227     2 647.03 299.989 < 2.2e-16 ***\nlevel      189789   94895     2 647.03 249.219 < 2.2e-16 ***\ntask:level  76282   19070     4 647.03  50.084 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_TI)[1]\n\n[1] 0.5574484\n\nr2tof2(r.squaredGLMM(mix_TI)[1])\n\n[1] 1.259623\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_TI)[1]),\n            u = 8,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 8\n              v = 12.06727\n             f2 = 1.259623\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_PE <- lmer(PE ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PE)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PE ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6385.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5601 -0.6543 -0.0360  0.6434  3.4304 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 115.2    10.73   \n Residual             303.0    17.41   \nNumber of obs: 737, groups:  id, 82\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          33.817      2.258 453.292  14.975  < 2e-16 ***\ntaskMS              -26.098      2.718 647.019  -9.601  < 2e-16 ***\ntaskST              -24.024      2.718 647.019  -8.838  < 2e-16 ***\nlevelmedium           9.280      2.718 647.019   3.414  0.00068 ***\nlevelhard            15.915      2.718 647.019   5.855 7.61e-09 ***\ntaskMS:levelmedium   17.415      3.844 647.019   4.530 7.02e-06 ***\ntaskST:levelmedium   29.085      3.844 647.019   7.566 1.33e-13 ***\ntaskMS:levelhard     41.341      3.844 647.019  10.754  < 2e-16 ***\ntaskST:levelhard     45.397      3.851 647.139  11.789  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.602                                                             \ntaskST      -0.602  0.500                                                      \nlevelmedium -0.602  0.500  0.500                                               \nlevelhard   -0.602  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.426 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.426 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.426 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.425 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_PE)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask         7910    3955     2 647.07  13.055 2.765e-06 ***\nlevel      247571  123786     2 647.07 408.583 < 2.2e-16 ***\ntask:level  54333   13583     4 647.07  44.835 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PE)[1]\n\n[1] 0.5013575\n\nr2tof2(r.squaredGLMM(mix_PE)[1])\n\n[1] 1.005445\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_PE)[1]),\n            u = 8,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 8\n              v = 14.89568\n             f2 = 1.005445\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_EF <- lmer(EF ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_EF)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6377.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1404 -0.5979  0.0386  0.6274  3.5447 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 256.7    16.02   \n Residual             279.1    16.71   \nNumber of obs: 736, groups:  id, 82\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          44.963      2.556 256.886  17.591  < 2e-16 ***\ntaskMS              -12.573      2.609 646.022  -4.819 1.80e-06 ***\ntaskST              -11.463      2.609 646.022  -4.394 1.30e-05 ***\nlevelmedium          10.110      2.609 646.022   3.875 0.000118 ***\nlevelhard            18.390      2.609 646.022   7.049 4.65e-12 ***\ntaskMS:levelmedium   17.142      3.696 646.081   4.638 4.26e-06 ***\ntaskST:levelmedium   12.802      3.696 646.081   3.464 0.000568 ***\ntaskMS:levelhard     24.098      3.690 646.022   6.531 1.32e-10 ***\ntaskST:levelhard     13.232      3.690 646.022   3.586 0.000361 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.510                                                             \ntaskST      -0.510  0.500                                                      \nlevelmedium -0.510  0.500  0.500                                               \nlevelhard   -0.510  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.360 -0.706 -0.353 -0.706 -0.353                                 \ntskST:lvlmd  0.360 -0.353 -0.706 -0.706 -0.353  0.498                          \ntskMS:lvlhr  0.361 -0.707 -0.354 -0.354 -0.707  0.499      0.250               \ntskST:lvlhr  0.361 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_EF)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask         2026    1013     2 646.07   3.629   0.02709 *  \nlevel      120497   60249     2 646.07 215.884 < 2.2e-16 ***\ntask:level  13130    3283     4 646.07  11.762 3.152e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_EF)[1]\n\n[1] 0.2562229\n\nr2tof2(r.squaredGLMM(mix_EF)[1])\n\n[1] 0.3444888\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_EF)[1]),\n            u = 8,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 8\n              v = 42.87323\n             f2 = 0.3444888\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_FR <- lmer(FR ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_FR)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: FR ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 6628.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.9347 -0.6775 -0.0439  0.6278  2.9644 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 361.5    19.01   \n Residual             405.3    20.13   \nNumber of obs: 734, groups:  id, 82\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)          34.659      3.058 261.667  11.334  < 2e-16 ***\ntaskMS              -11.152      3.166 644.144  -3.523 0.000458 ***\ntaskST              -13.037      3.144 643.872  -4.147 3.83e-05 ***\nlevelmedium           7.159      3.144 643.872   2.277 0.023118 *  \nlevelhard            13.437      3.155 643.992   4.259 2.35e-05 ***\ntaskMS:levelmedium   11.847      4.462 644.009   2.655 0.008122 ** \ntaskST:levelmedium   19.561      4.446 643.872   4.399 1.27e-05 ***\ntaskMS:levelhard     22.604      4.469 644.064   5.058 5.54e-07 ***\ntaskST:levelhard     29.743      4.462 644.010   6.667 5.64e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.511                                                             \ntaskST      -0.514  0.497                                                      \nlevelmedium -0.514  0.497  0.500                                               \nlevelhard   -0.512  0.495  0.498  0.498                                        \ntskMS:lvlmd  0.362 -0.710 -0.352 -0.705 -0.351                                 \ntskST:lvlmd  0.364 -0.351 -0.707 -0.707 -0.352  0.498                          \ntskMS:lvlhr  0.362 -0.708 -0.352 -0.352 -0.706  0.503      0.249               \ntskST:lvlhr  0.362 -0.349 -0.705 -0.352 -0.707  0.248      0.498      0.499    \n\nanova(mix_FR)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF  F value    Pr(>F)    \ntask         1718     859     2 643.96   2.1199    0.1209    \nlevel      117101   58551     2 643.96 144.4761 < 2.2e-16 ***\ntask:level  20377    5094     4 644.01  12.5702 7.462e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_FR)[1]\n\n[1] 0.1983774\n\nr2tof2(r.squaredGLMM(mix_FR)[1])\n\n[1] 0.2474698\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_FR)[1]),\n            u = 8,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 8\n              v = 59.83663\n             f2 = 0.2474698\n      sig.level = 0.05\n          power = 0.8\n\n\n\n\n\n\nmix_OW <- lmer(OW ~ task * level + (1|id), \n               nasa_tlx_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_OW)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: OW ~ task * level + (1 | id)\n   Data: nasa_tlx_wide\n\nREML criterion at convergence: 8255.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1352 -0.6239 -0.0043  0.6245  3.5547 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 4434     66.59   \n Residual             4664     68.30   \nNumber of obs: 721, groups:  id, 82\n\nFixed effects:\n                   Estimate Std. Error     df t value Pr(>|t|)    \n(Intercept)          192.30      10.57 252.49  18.191  < 2e-16 ***\ntaskMS               -65.57      10.89 631.57  -6.023 2.91e-09 ***\ntaskST               -60.77      10.70 631.17  -5.678 2.09e-08 ***\nlevelmedium           41.05      10.70 631.17   3.836 0.000138 ***\nlevelhard             77.97      10.74 631.28   7.260 1.14e-12 ***\ntaskMS:levelmedium   107.41      15.29 631.45   7.023 5.63e-12 ***\ntaskST:levelmedium   116.56      15.19 631.29   7.674 6.36e-14 ***\ntaskMS:levelhard     176.10      15.31 631.36  11.500  < 2e-16 ***\ntaskST:levelhard     165.29      15.22 631.35  10.863  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.500                                                             \ntaskST      -0.510  0.494                                                      \nlevelmedium -0.510  0.494  0.503                                               \nlevelhard   -0.508  0.492  0.502  0.502                                        \ntskMS:lvlmd  0.356 -0.712 -0.352 -0.699 -0.351                                 \ntskST:lvlmd  0.359 -0.348 -0.705 -0.705 -0.354  0.493                          \ntskMS:lvlhr  0.356 -0.710 -0.351 -0.351 -0.701  0.506      0.247               \ntskST:lvlhr  0.359 -0.347 -0.703 -0.354 -0.706  0.247      0.496      0.495    \n\nanova(mix_OW)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \ntask        157643   78822     2 631.43  16.899 7.088e-08 ***\nlevel      4460235 2230117     2 631.65 478.126 < 2.2e-16 ***\ntask:level  814298  203575     4 631.44  43.645 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_OW)[1]\n\n[1] 0.4524251\n\nr2tof2(r.squaredGLMM(mix_OW)[1])\n\n[1] 0.8262341\n\npwr.f2.test(f2 = r2tof2(r.squaredGLMM(mix_OW)[1]),\n            u = 7,\n            sig.level = .05,\n            power = .8)\n\n\n     Multiple regression power calculation \n\n              u = 7\n              v = 17.33739\n             f2 = 0.8262341\n      sig.level = 0.05\n          power = 0.8"
  },
  {
    "objectID": "analysis_toloka.html#packages",
    "href": "analysis_toloka.html#packages",
    "title": "Analysis. Toloka Banch",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_bw())\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(lmerTest)\n\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:stats':\n\n    step\n\nlibrary(MuMIn)"
  },
  {
    "objectID": "analysis_toloka.html#load-pavlovia-toloka-aggregated-data",
    "href": "analysis_toloka.html#load-pavlovia-toloka-aggregated-data",
    "title": "Analysis. Toloka Banch",
    "section": "",
    "text": "read_csv(\"../preproc-data/MR_firstbanch_data_agg.csv\") -&gt; MR_pav_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/MS_firstbanch_data_agg.csv\") -&gt; MS_pav_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/ST_firstbanch_data_agg.csv\") -&gt; ST_pav_agg\n\nRows: 234 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): id, level, task\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/NASATLX_firstbanch_data.csv\") -&gt; NASATLX_pav\n\nRows: 4212 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): scale, task, level, id\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/SEQ_firstbanch_data.csv\") -&gt; SEQ_data_pav\n\nRows: 702 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, task, id\ndbl (1): order\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/mental_rotation_data_toloka.csv\") -&gt; MR_data_toloka\n\nRows: 171 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/mental_span_data_toloka.csv\") -&gt; MS_data_toloka\n\nRows: 171 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/sternberg_data_toloka.csv\") -&gt; ST_data_toloka\n\nRows: 171 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task, level, id\ndbl (2): rt, acc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/nasa_tlx_data_toloka.csv\") -&gt; NASATLX_data_toloka\n\nRows: 3078 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): task, level, id, scale\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/sequence_data_toloka.csv\") -&gt; SEQ_data_toloka\n\nRows: 513 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): level, task, id\ndbl (1): order\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nread_csv(\"../preproc-data/weights_data_toloka.csv\") -&gt; WEIGHTS_data_toloka\n\nRows: 882 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): task_type, choice, id\ndbl (2): n, w\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nMR_data_toloka$id |&gt; unique() |&gt; length()\n\n[1] 57\n\nMR_pav_agg$id |&gt; unique() |&gt; length()\n\n[1] 78\n\nMS_data_toloka$id |&gt; unique() |&gt; length()\n\n[1] 57\n\nMS_pav_agg$id |&gt; unique() |&gt; length()\n\n[1] 78\n\nST_data_toloka$id |&gt; unique() |&gt; length()\n\n[1] 57\n\nST_pav_agg$id |&gt; unique() |&gt; length()\n\n[1] 78\n\nNASATLX_data_toloka$id |&gt; unique() |&gt; length()\n\n[1] 57\n\nNASATLX_pav$id |&gt; unique() |&gt; length()\n\n[1] 78\n\n\n\nMR_pav_agg |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    MR_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) %&gt;% \n  mutate(level = factor(level, ordered = TRUE,\n                        levels = c(\"easy\", \"medium\", \"hard\"))) -&gt; MR_full\n\nMS_pav_agg |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    MS_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) %&gt;% \n  mutate(level = factor(level, ordered = TRUE,\n                        levels = c(\"easy\", \"medium\", \"hard\"))) -&gt; MS_full\n\nST_pav_agg |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    ST_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) %&gt;% \n  mutate(level = factor(level, ordered = TRUE,\n                        levels = c(\"easy\", \"medium\", \"hard\"))) -&gt; ST_full\n\nNASATLX_pav |&gt; \n  mutate(banch = \"manual\") |&gt; \n  bind_rows(\n    NASATLX_data_toloka |&gt; \n      mutate(banch = \"toloka\")\n  ) %&gt;% \n  mutate(level = factor(level, ordered = TRUE,\n                        levels = c(\"easy\", \"medium\", \"hard\"))) -&gt; NASATLX_full\n\nSEQ_data_pav %&gt;% \n  mutate(banch = \"manual\") %&gt;% \n  bind_rows(\n    SEQ_data_toloka %&gt;% \n    mutate(banch = \"toloka\")\n  ) %&gt;% \n  mutate(level = factor(level, ordered = TRUE,\n                        levels = c(\"easy\", \"medium\", \"hard\"))) -&gt; SEQ_full"
  },
  {
    "objectID": "analysis_toloka.html#plotting",
    "href": "analysis_toloka.html#plotting",
    "title": "Analysis. Toloka Banch",
    "section": "",
    "text": "pd &lt;- position_dodge(.3)\nlevel_colors &lt;- c(\"#4bd752\", \"#d7984b\", \"#d7524b\")\ntask_colors &lt;- c(\"red4\", \"green4\", \"blue4\")\n\n\n\n\nMR_full |&gt; \n  ggplot() +\n  stat_summary(aes(level, rt, color = banch),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd) +\n  stat_summary(aes(level, rt),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd, color = \"gray30\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"Mental Rotation\",\n       subtitle = \"Reaction time\",\n       x = \"Difficulty level\",\n       y = \"Reaction time (s)\")\n\n\n\n\n\nMR_full |&gt; \n  ggplot() +\n  stat_summary(aes(level, acc, color = banch),\n               fun.data = mean_cl_boot, geom = \"pointrange\",\n               position = pd) +\n  stat_summary(aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd, color = \"gray30\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"Mental Rotation\",\n       subtitle = \"Accuracy\",\n       x = \"Difficulty level\",\n       y = \"Accuracy\")\n\n\n\n\n\n\n\n\nMS_full |&gt; \n  ggplot() +\n  stat_summary(aes(level, rt, color = banch),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd) +\n  stat_summary(aes(level, rt),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd, color = \"gray30\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"Memory Span\",\n       subtitle = \"Reaction time\",\n       x = \"Difficulty level\",\n       y = \"Reaction time (s)\")\n\nWarning: Removed 72 rows containing non-finite values (`stat_summary()`).\nRemoved 72 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nMS_full |&gt; \n  ggplot() +\n  stat_summary(aes(level, acc, color = banch),\n               fun.data = mean_cl_boot, geom = \"pointrange\",\n               position = pd) +\n  stat_summary(aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd, color = \"gray30\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"Memory Span\",\n       subtitle = \"Accuracy\",\n       x = \"Difficulty level\",\n       y = \"Accuracy\")\n\n\n\n\n\n\n\n\nST_full |&gt; \n  ggplot() +\n  stat_summary(aes(level, rt, color = banch),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd) +\n  stat_summary(aes(level, rt),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd, color = \"gray30\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"Sternberg Task\",\n       subtitle = \"Reaction time\",\n       x = \"Difficulty level\",\n       y = \"Reaction time (s)\")\n\n\n\n\n\nST_full |&gt; \n  ggplot() +\n  stat_summary(aes(level, acc, color = banch),\n               fun.data = mean_cl_boot, geom = \"pointrange\",\n               position = pd) +\n  stat_summary(aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd, color = \"gray30\") +\n  theme(legend.position = \"bottom\") +\n  labs(title = \"Sternberg Task\",\n       subtitle = \"Accuracy\",\n       x = \"Difficulty level\",\n       y = \"Accuracy\")\n\n\n\n\n\n\n\n\nNASATLX_full |&gt; \n  ggplot() +\n  stat_summary(aes(scale, score, color = level, shape = banch),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd) +\n  stat_summary(aes(scale, score, color = level),\n               fun.data = mean_cl_boot, geom = \"pointrange\", \n               position = pd, shape = 15) +\n  facet_grid(task ~ .) +\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values = level_colors) +\n  labs(title = \"NASA-TLX\",\n       x = \"Subscale\",\n       y = \"Score (raw)\")\n\nWarning: Removed 17 rows containing non-finite values (`stat_summary()`).\nRemoved 17 rows containing non-finite values (`stat_summary()`)."
  },
  {
    "objectID": "analysis_toloka.html#behavioral-data",
    "href": "analysis_toloka.html#behavioral-data",
    "title": "Analysis. Toloka Banch",
    "section": "",
    "text": "MR_full %&gt;% \n  bind_rows(MS_full, ST_full) -&gt; behave_full\n\n\nr2tof2 &lt;- function(r2) r2 / (1 - r2)\n\n\n\n\nmix_MR_rt &lt;- lmer(rt ~ level + (1|id), \n               MR_full,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_MR_rt)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: rt ~ level + (1 | id)\n   Data: MR_full\n\nREML criterion at convergence: 2485.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.9059 -0.3694 -0.0741  0.2847  7.4686 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 27.61    5.255   \n Residual             14.50    3.808   \nNumber of obs: 405, groups:  id, 135\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)   5.8323     0.5585 216.1411  10.443  &lt; 2e-16 ***\nlevelmedium   1.7789     0.4635 268.0000   3.838 0.000155 ***\nlevelhard     4.0789     0.4635 268.0000   8.801  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) lvlmdm\nlevelmedium -0.415       \nlevelhard   -0.415  0.500\n\nanova(mix_MR_rt)\n\nType III Analysis of Variance Table with Satterthwaite's method\n      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nlevel 1129.2  564.58     2   268  38.941 1.425e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_MR_rt)\n\nWarning: 'r.squaredGLMM' now calculates a revised statistic. See the help page.\n\n\n            R2m       R2c\n[1,] 0.06224137 0.6771338\n\nr2tof2(r.squaredGLMM(mix_MR_rt)[1])\n\n[1] 0.06637248\n\n\n\nmix_MR_acc &lt;- lmer(acc ~ level + (1|id), \n               MR_full,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_MR_acc)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: acc ~ level + (1 | id)\n   Data: MR_full\n\nREML criterion at convergence: -288\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.5588 -0.5281  0.1090  0.5608  2.4378 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.02485  0.1576  \n Residual             0.01528  0.1236  \nNumber of obs: 405, groups:  id, 135\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   0.79121    0.01724 227.49422  45.891  &lt; 2e-16 ***\nlevelmedium  -0.08417    0.01504 268.00000  -5.595 5.45e-08 ***\nlevelhard    -0.12197    0.01504 268.00000  -8.107 1.86e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) lvlmdm\nlevelmedium -0.436       \nlevelhard   -0.436  0.500\n\nanova(mix_MR_acc)\n\nType III Analysis of Variance Table with Satterthwaite's method\n      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nlevel 1.0525 0.52625     2   268  34.447 4.851e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_MR_acc)\n\n            R2m       R2c\n[1,] 0.06096289 0.6425134\n\nr2tof2(r.squaredGLMM(mix_MR_acc)[1])\n\n[1] 0.06492063\n\n\n\n\n\n\nmix_MS_rt &lt;- lmer(rt ~ level + (1|id), \n               MS_full,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_MS_rt)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: rt ~ level + (1 | id)\n   Data: MS_full\n\nREML criterion at convergence: 2263.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.2010 -0.4372 -0.0651  0.3614  7.3893 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 42.57    6.525   \n Residual             31.01    5.569   \nNumber of obs: 333, groups:  id, 111\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)  11.5608     0.8142 197.6781   14.20   &lt;2e-16 ***\nlevelmedium   8.9879     0.7475 220.0000   12.02   &lt;2e-16 ***\nlevelhard    12.6773     0.7475 220.0000   16.96   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) lvlmdm\nlevelmedium -0.459       \nlevelhard   -0.459  0.500\n\nanova(mix_MS_rt)\n\nType III Analysis of Variance Table with Satterthwaite's method\n      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nlevel   9439  4719.5     2   220  152.17 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_MS_rt)\n\n           R2m       R2c\n[1,] 0.2786894 0.6959852\n\nr2tof2(r.squaredGLMM(mix_MS_rt)[1])\n\n[1] 0.3863652\n\n\n\nmix_MS_acc &lt;- lmer(acc ~ level + (1|id), \n               MS_full,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_MS_acc)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: acc ~ level + (1 | id)\n   Data: MS_full\n\nREML criterion at convergence: -448.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.1847 -0.5063  0.0315  0.4828  3.3933 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.01493  0.1222  \n Residual             0.01067  0.1033  \nNumber of obs: 405, groups:  id, 135\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   0.95163    0.01377 239.30532  69.107  &lt; 2e-16 ***\nlevelmedium  -0.06638    0.01258 268.00000  -5.279 2.69e-07 ***\nlevelhard    -0.27058    0.01258 268.00000 -21.517  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) lvlmdm\nlevelmedium -0.457       \nlevelhard   -0.457  0.500\n\nanova(mix_MS_acc)\n\nType III Analysis of Variance Table with Satterthwaite's method\n      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nlevel 5.3692  2.6846     2   268  251.51 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_MS_acc)\n\n           R2m       R2c\n[1,] 0.3417443 0.7255312\n\nr2tof2(r.squaredGLMM(mix_MS_acc)[1])\n\n[1] 0.5191665\n\n\n\n\n\n\nmix_ST_rt &lt;- lmer(rt ~ level + (1|id), \n               ST_full,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ST_rt)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: rt ~ level + (1 | id)\n   Data: ST_full\n\nREML criterion at convergence: 628\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5894 -0.4558 -0.0900  0.2796  5.4778 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.1992   0.4463  \n Residual             0.1604   0.4005  \nNumber of obs: 405, groups:  id, 135\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   1.13580    0.05161 249.13888  22.007  &lt; 2e-16 ***\nlevelmedium   0.26432    0.04875 268.00000   5.422 1.32e-07 ***\nlevelhard     0.41349    0.04875 268.00000   8.482 1.52e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) lvlmdm\nlevelmedium -0.472       \nlevelhard   -0.472  0.500\n\nanova(mix_ST_rt)\n\nType III Analysis of Variance Table with Satterthwaite's method\n      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nlevel 11.839  5.9196     2   268    36.9 6.992e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ST_rt)\n\n            R2m       R2c\n[1,] 0.07535396 0.5874935\n\nr2tof2(r.squaredGLMM(mix_ST_rt)[1])\n\n[1] 0.08149492\n\n\n\nmix_ST_acc &lt;- lmer(acc ~ level + (1|id), \n               ST_full,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ST_acc)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: acc ~ level + (1 | id)\n   Data: ST_full\n\nREML criterion at convergence: -637.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2588 -0.4977  0.0861  0.5317  2.3553 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.003150 0.05612 \n Residual             0.009112 0.09545 \nNumber of obs: 405, groups:  id, 135\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   0.97483    0.00953 355.12831  102.29   &lt;2e-16 ***\nlevelmedium  -0.13166    0.01162 268.00000  -11.33   &lt;2e-16 ***\nlevelhard    -0.26709    0.01162 268.00000  -22.99   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) lvlmdm\nlevelmedium -0.610       \nlevelhard   -0.610  0.500\n\nanova(mix_ST_acc)\n\nType III Analysis of Variance Table with Satterthwaite's method\n      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \nlevel 4.8154  2.4077     2   268  264.24 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ST_acc)\n\n           R2m       R2c\n[1,] 0.4929231 0.6231862\n\nr2tof2(r.squaredGLMM(mix_ST_acc)[1])\n\n[1] 0.9720873"
  },
  {
    "objectID": "analysis_toloka.html#nasa-tlx-glmm-scales",
    "href": "analysis_toloka.html#nasa-tlx-glmm-scales",
    "title": "Analysis. Toloka Banch",
    "section": "",
    "text": "NASATLX_full |&gt; \n  pivot_wider(values_from = score, names_from = scale) %&gt;% \n  mutate(OW = ME + PH + TI + PE + EF + FR) -&gt; NASATLX_wide\n\n\n\n\nmix_ME &lt;- lmer(ME ~ task * level + (1|id), \n               NASATLX_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ME)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ME ~ task * level + (1 | id)\n   Data: NASATLX_wide\n\nREML criterion at convergence: 10291.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.6972 -0.4117 -0.0179  0.4625  4.1646 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 775.5    27.85   \n Residual             193.4    13.91   \nNumber of obs: 1214, groups:  id, 135\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)          27.360      2.679  196.893  10.213  &lt; 2e-16 ***\ntaskMS               -7.676      1.693 1071.002  -4.535 6.42e-06 ***\ntaskST               -6.741      1.693 1071.002  -3.982 7.29e-05 ***\nlevelmedium           5.014      1.693 1071.002   2.962  0.00313 ** \nlevelhard             6.922      1.693 1071.002   4.090 4.65e-05 ***\ntaskMS:levelmedium   12.874      2.394 1071.002   5.378 9.25e-08 ***\ntaskST:levelmedium    9.459      2.394 1071.002   3.951 8.28e-05 ***\ntaskMS:levelhard     18.243      2.394 1071.002   7.621 5.54e-14 ***\ntaskST:levelhard     12.475      2.396 1071.017   5.206 2.31e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.316                                                             \ntaskST      -0.316  0.500                                                      \nlevelmedium -0.316  0.500  0.500                                               \nlevelhard   -0.316  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.223 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.223 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.223 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.223 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_ME)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF DenDF  F value    Pr(&gt;F)    \ntask         1635     817     2  1071   4.2268   0.01484 *  \nlevel       63641   31820     2  1071 164.5243 &lt; 2.2e-16 ***\ntask:level  12480    3120     4  1071  16.1315  7.79e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ME)\n\n            R2m       R2c\n[1,] 0.06205627 0.8127718\n\nr2tof2(r.squaredGLMM(mix_ME)[1])\n\n[1] 0.06616204\n\n\n\n\n\n\nmix_PH &lt;- lmer(PH ~ task * level + (1|id), \n               NASATLX_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PH)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PH ~ task * level + (1 | id)\n   Data: NASATLX_wide\n\nREML criterion at convergence: 9961.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7755 -0.3669  0.0319  0.2791  5.8080 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 485.9    22.04   \n Residual             158.5    12.59   \nNumber of obs: 1207, groups:  id, 135\n\nFixed effects:\n                    Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)          14.7930     2.1871  218.1677   6.764 1.22e-10 ***\ntaskMS               -1.5701     1.5456 1064.2254  -1.016 0.309921    \ntaskST               -2.7968     1.5358 1064.0852  -1.821 0.068878 .  \nlevelmedium           1.5747     1.5358 1064.0852   1.025 0.305442    \nlevelhard             0.8371     1.5358 1064.0852   0.545 0.585838    \ntaskMS:levelmedium    7.5445     2.1789 1064.1567   3.462 0.000556 ***\ntaskST:levelmedium    2.9463     2.1720 1064.0904   1.356 0.175230    \ntaskMS:levelhard     12.9095     2.1807 1064.1313   5.920 4.34e-09 ***\ntaskST:levelhard      7.1225     2.1697 1064.0660   3.283 0.001062 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.350                                                             \ntaskST      -0.353  0.499                                                      \nlevelmedium -0.353  0.499  0.502                                               \nlevelhard   -0.353  0.499  0.502  0.502                                        \ntskMS:lvlmd  0.249 -0.709 -0.354 -0.705 -0.354                                 \ntskST:lvlmd  0.249 -0.352 -0.707 -0.707 -0.355  0.498                          \ntskMS:lvlhr  0.248 -0.708 -0.354 -0.354 -0.704  0.503      0.250               \ntskST:lvlhr  0.250 -0.353 -0.708 -0.355 -0.708  0.251      0.501      0.499    \n\nanova(mix_PH)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask        6644.9  3322.5     2 1064.1 20.9555 1.185e-09 ***\nlevel      11798.7  5899.4     2 1064.1 37.2086 2.402e-16 ***\ntask:level  5709.4  1427.4     4 1064.1  9.0027 3.758e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PH)\n\n            R2m       R2c\n[1,] 0.03012612 0.7613929\n\nr2tof2(r.squaredGLMM(mix_PH)[1])\n\n[1] 0.0310619\n\n\n\n\n\n\nmix_TI &lt;- lmer(TI ~ task * level + (1|id), \n               NASATLX_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_TI)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: TI ~ task * level + (1 | id)\n   Data: NASATLX_wide\n\nREML criterion at convergence: 10719.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3751 -0.6192  0.0937  0.5056  3.2392 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 549.2    23.43   \n Residual             299.9    17.32   \nNumber of obs: 1214, groups:  id, 135\n\nFixed effects:\n                    Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)          12.1284     2.5078  277.4358   4.836 2.20e-06 ***\ntaskMS                4.8780     2.1078 1071.0092   2.314   0.0208 *  \ntaskST                9.1284     2.1078 1071.0092   4.331 1.63e-05 ***\nlevelmedium           0.9646     2.1078 1071.0092   0.458   0.6473    \nlevelhard             2.0912     2.1078 1071.0092   0.992   0.3214    \ntaskMS:levelmedium   16.4068     2.9809 1071.0092   5.504 4.65e-08 ***\ntaskST:levelmedium   18.2197     2.9840 1071.0408   6.106 1.43e-09 ***\ntaskMS:levelhard     25.7502     2.9809 1071.0092   8.638  &lt; 2e-16 ***\ntaskST:levelhard     22.1109     2.9809 1071.0092   7.417 2.42e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.420                                                             \ntaskST      -0.420  0.500                                                      \nlevelmedium -0.420  0.500  0.500                                               \nlevelhard   -0.420  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.297 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.297 -0.353 -0.706 -0.706 -0.353  0.499                          \ntskMS:lvlhr  0.297 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.297 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_TI)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \ntask       118864   59432     2  1071 198.175 &lt; 2.2e-16 ***\nlevel       69209   34605     2  1071 115.389 &lt; 2.2e-16 ***\ntask:level  28521    7130     4  1071  23.775 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_TI)\n\n           R2m       R2c\n[1,] 0.1737067 0.7081437\n\nr2tof2(r.squaredGLMM(mix_TI)[1])\n\n[1] 0.210224\n\n\n\n\n\n\nmix_PE &lt;- lmer(PE ~ task * level + (1|id), \n               NASATLX_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PE)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PE ~ task * level + (1 | id)\n   Data: NASATLX_wide\n\nREML criterion at convergence: 10496.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2669 -0.5802 -0.0963  0.6187  3.9993 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 225.9    15.03   \n Residual             270.0    16.43   \nNumber of obs: 1214, groups:  id, 135\n\nFixed effects:\n                    Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)          22.9495     1.9164  453.2690  11.975  &lt; 2e-16 ***\ntaskMS               -7.8113     1.9998 1071.0148  -3.906 9.97e-05 ***\ntaskST               -7.5804     1.9998 1071.0148  -3.791 0.000159 ***\nlevelmedium           0.7631     1.9998 1071.0148   0.382 0.702858    \nlevelhard             2.0883     1.9998 1071.0148   1.044 0.296614    \ntaskMS:levelmedium    5.9872     2.8282 1071.0148   2.117 0.034492 *  \ntaskST:levelmedium    8.0419     2.8282 1071.0148   2.844 0.004547 ** \ntaskMS:levelhard      9.9998     2.8282 1071.0148   3.536 0.000424 ***\ntaskST:levelhard     11.1546     2.8311 1071.0787   3.940 8.67e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.522                                                             \ntaskST      -0.522  0.500                                                      \nlevelmedium -0.522  0.500  0.500                                               \nlevelhard   -0.522  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.369 -0.707 -0.354 -0.707 -0.354                                 \ntskST:lvlmd  0.369 -0.354 -0.707 -0.707 -0.354  0.500                          \ntskMS:lvlhr  0.369 -0.707 -0.354 -0.354 -0.707  0.500      0.250               \ntskST:lvlhr  0.369 -0.353 -0.706 -0.353 -0.706  0.250      0.499      0.499    \n\nanova(mix_PE)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \ntask        1248.8   624.4     2  1071  2.3130 0.0994588 .  \nlevel      17099.5  8549.8     2  1071 31.6715 4.331e-14 ***\ntask:level  5353.5  1338.4     4  1071  4.9579 0.0005806 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PE)\n\n            R2m       R2c\n[1,] 0.03789665 0.4761788\n\nr2tof2(r.squaredGLMM(mix_PE)[1])\n\n[1] 0.03938937\n\n\n\n\n\n\nmix_EF &lt;- lmer(EF ~ task * level + (1|id), \n               NASATLX_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_EF)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF ~ task * level + (1 | id)\n   Data: NASATLX_wide\n\nREML criterion at convergence: 10237.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.7297 -0.4067  0.0167  0.4174  5.0330 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 767.7    27.71   \n Residual             185.5    13.62   \nNumber of obs: 1213, groups:  id, 135\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)          26.143      2.657  194.836   9.839  &lt; 2e-16 ***\ntaskMS               -5.271      1.658 1070.006  -3.180 0.001515 ** \ntaskST               -2.460      1.658 1070.006  -1.484 0.138090    \nlevelmedium           3.574      1.658 1070.006   2.156 0.031300 *  \nlevelhard             6.313      1.658 1070.006   3.809 0.000148 ***\ntaskMS:levelmedium   12.652      2.347 1070.021   5.391 8.61e-08 ***\ntaskST:levelmedium    8.173      2.347 1070.021   3.483 0.000516 ***\ntaskMS:levelhard     16.970      2.344 1070.006   7.239 8.63e-13 ***\ntaskST:levelhard      7.381      2.344 1070.006   3.148 0.001687 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.312                                                             \ntaskST      -0.312  0.500                                                      \nlevelmedium -0.312  0.500  0.500                                               \nlevelhard   -0.312  0.500  0.500  0.500                                        \ntskMS:lvlmd  0.220 -0.706 -0.353 -0.706 -0.353                                 \ntskST:lvlmd  0.220 -0.353 -0.706 -0.706 -0.353  0.499                          \ntskMS:lvlhr  0.221 -0.707 -0.354 -0.354 -0.707  0.499      0.250               \ntskST:lvlhr  0.221 -0.354 -0.707 -0.354 -0.707  0.250      0.499      0.500    \n\nanova(mix_EF)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \ntask         4332  2166.2     2  1070  11.679 9.602e-06 ***\nlevel       45097 22548.4     2  1070 121.571 &lt; 2.2e-16 ***\ntask:level  10899  2724.6     4  1070  14.690 1.093e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_EF)\n\n            R2m       R2c\n[1,] 0.04961338 0.8150619\n\nr2tof2(r.squaredGLMM(mix_EF)[1])\n\n[1] 0.05220337\n\n\n\n\n\n\nmix_FR &lt;- lmer(FR ~ task * level + (1|id), \n               NASATLX_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_FR)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: FR ~ task * level + (1 | id)\n   Data: NASATLX_wide\n\nREML criterion at convergence: 10511.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1687 -0.4341 -0.0084  0.3954  3.9651 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 618.3    24.87   \n Residual             249.5    15.80   \nNumber of obs: 1211, groups:  id, 135\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)          21.510      2.535  238.224   8.484 2.33e-15 ***\ntaskMS               -4.122      1.931 1068.124  -2.135  0.03302 *  \ntaskST               -5.057      1.923 1068.016  -2.630  0.00865 ** \nlevelmedium           3.160      1.923 1068.016   1.644  0.10054    \nlevelhard             5.322      1.927 1068.063   2.763  0.00583 ** \ntaskMS:levelmedium   10.678      2.725 1068.070   3.919 9.47e-05 ***\ntaskST:levelmedium   11.347      2.719 1068.016   4.173 3.25e-05 ***\ntaskMS:levelhard     16.430      2.728 1068.093   6.023 2.35e-09 ***\ntaskST:levelhard     16.793      2.725 1068.070   6.163 1.01e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.378                                                             \ntaskST      -0.379  0.498                                                      \nlevelmedium -0.379  0.498  0.500                                               \nlevelhard   -0.378  0.497  0.499  0.499                                        \ntskMS:lvlmd  0.268 -0.709 -0.353 -0.706 -0.352                                 \ntskST:lvlmd  0.268 -0.352 -0.707 -0.707 -0.353  0.499                          \ntskMS:lvlhr  0.267 -0.708 -0.352 -0.352 -0.706  0.502      0.249               \ntskST:lvlhr  0.268 -0.351 -0.706 -0.353 -0.707  0.249      0.499      0.499    \n\nanova(mix_FR)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask         5809  2904.7     2 1068.0  11.641 9.967e-06 ***\nlevel       55585 27792.4     2 1068.0 111.384 &lt; 2.2e-16 ***\ntask:level  12820  3205.1     4 1068.1  12.845 3.233e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_FR)\n\n            R2m       R2c\n[1,] 0.06603895 0.7314739\n\nr2tof2(r.squaredGLMM(mix_FR)[1])\n\n[1] 0.07070846\n\n\n\n\n\n\nmix_OW &lt;- lmer(OW ~ task * level + (1|id), \n               NASATLX_wide,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_OW)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: OW ~ task * level + (1 | id)\n   Data: NASATLX_wide\n\nREML criterion at convergence: 13840.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6936 -0.5540  0.0616  0.5283  3.5176 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 18006    134.19  \n Residual              4248     65.18  \nNumber of obs: 1198, groups:  id, 135\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)         124.663     12.850  193.836   9.702  &lt; 2e-16 ***\ntaskMS              -22.843      8.032 1055.181  -2.844  0.00454 ** \ntaskST              -15.285      7.950 1055.078  -1.923  0.05479 .  \nlevelmedium          15.272      7.950 1055.078   1.921  0.05500 .  \nlevelhard            23.758      7.967 1055.107   2.982  0.00293 ** \ntaskMS:levelmedium   67.791     11.313 1055.147   5.992 2.84e-09 ***\ntaskST:levelmedium   58.356     11.267 1055.110   5.179 2.67e-07 ***\ntaskMS:levelhard    102.365     11.322 1055.126   9.041  &lt; 2e-16 ***\ntaskST:levelhard     77.588     11.279 1055.125   6.879 1.03e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlmdm lvlhrd tskMS:lvlm tskST:lvlm tskMS:lvlh\ntaskMS      -0.307                                                             \ntaskST      -0.311  0.496                                                      \nlevelmedium -0.311  0.496  0.502                                               \nlevelhard   -0.310  0.495  0.501  0.501                                        \ntskMS:lvlmd  0.218 -0.710 -0.352 -0.702 -0.352                                 \ntskST:lvlmd  0.219 -0.350 -0.706 -0.706 -0.354  0.496                          \ntskMS:lvlhr  0.218 -0.709 -0.352 -0.352 -0.703  0.503      0.248               \ntskST:lvlhr  0.219 -0.350 -0.705 -0.354 -0.706  0.248      0.497      0.497    \n\nanova(mix_OW)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask        275392  137696     2 1055.2  32.413 2.181e-14 ***\nlevel      1459469  729735     2 1055.2 171.776 &lt; 2.2e-16 ***\ntask:level  399259   99815     4 1055.2  23.496 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_OW)\n\n            R2m       R2c\n[1,] 0.07404047 0.8232386\n\nr2tof2(r.squaredGLMM(mix_OW)[1])\n\n[1] 0.07996081\n\n\n\n\n\n\nNASATLX_wide |&gt; \n  pivot_longer(cols = c(\"ME\", \"PH\", \"EF\", \"PE\", \"TI\", \"FR\", \"OW\"),\n               names_to = \"scale\", values_to = \"raw_score\") %&gt;% \n  filter(scale != \"OW\") %&gt;% \n  ggplot() + \n  stat_summary(aes(level, raw_score),\n               fun.data = mean_cl_boot, geom = \"errorbar\", \n               width = .5,\n               position = pd) +\n  stat_summary(aes(level, raw_score),\n               fun = mean, geom = \"point\",\n               size = 2,\n               position = pd) +\n  facet_grid(task ~ scale, scales = \"free_y\") +\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values = level_colors) +\n  labs(title = \"NASA-TLX\",\n       x = \"Difficulty Level\",\n       y = \"Score (raw)\")\n\nWarning: Removed 17 rows containing non-finite values (`stat_summary()`).\nRemoved 17 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nNASATLX_wide |&gt; \n  pivot_longer(cols = c(\"ME\", \"PH\", \"EF\", \"PE\", \"TI\", \"FR\", \"OW\"),\n               names_to = \"scale\", values_to = \"raw_score\") %&gt;% \n  filter(scale == \"OW\") %&gt;% \n  ggplot() + \n  stat_summary(aes(level, raw_score),\n               fun.data = mean_cl_boot, geom = \"errorbar\", \n               width = .3,\n               position = pd) +\n  stat_summary(aes(level, raw_score),\n               fun = mean, geom = \"point\",\n               size = 2,\n               position = pd) +\n  facet_grid(task ~ scale, scales = \"free_y\") +\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values = level_colors) +\n  labs(title = \"NASA-TLX\",\n       x = \"Difficulty Level\",\n       y = \"Score (raw)\")\n\nWarning: Removed 17 rows containing non-finite values (`stat_summary()`).\nRemoved 17 rows containing non-finite values (`stat_summary()`)."
  },
  {
    "objectID": "analysis_toloka.html#nasa-tlx-glmm-weighted-scales",
    "href": "analysis_toloka.html#nasa-tlx-glmm-weighted-scales",
    "title": "Analysis. Toloka Banch",
    "section": "",
    "text": "WEIGHTS_data_toloka %&gt;% \n  rename(\"scale\" = choice,\n         \"task\" = task_type) %&gt;% \n  mutate(task = recode(task,\n                       \"mental_rotation\" = \"MR\",\n                       \"sternberg\" = \"ST\",\n                       \"mental_span\" = \"MS\")) %&gt;% \n  full_join(NASATLX_data_toloka,\n            by = join_by(id, task, scale)) %&gt;% \n  mutate(score_w = w * score) %&gt;% \n  select(-c(\"n\", \"w\", \"score\")) %&gt;% \n  pivot_wider(values_from = score_w, names_from = scale) %&gt;% \n  mutate(OW = ME + PH + TI + PE + EF + FR) -&gt; NASATLX_weighted_toloka\n\n\n\n\nmix_ME_w &lt;- lmer(ME ~ task * level + (1|id), \n               NASATLX_weighted_toloka,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_ME_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ME ~ task * level + (1 | id)\n   Data: NASATLX_weighted_toloka\n\nREML criterion at convergence: 3384\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7792 -0.6906  0.0104  0.6192  2.7138 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 33.49    5.787   \n Residual             38.08    6.171   \nNumber of obs: 507, groups:  id, 57\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)          13.655      1.121 182.799  12.185  &lt; 2e-16 ***\ntaskMS               -3.560      1.162 442.383  -3.064 0.002317 ** \ntaskST               -5.661      1.162 442.383  -4.873 1.54e-06 ***\nlevelhard             2.763      1.156 442.187   2.390 0.017272 *  \nlevelmedium           2.235      1.156 442.187   1.934 0.053806 .  \ntaskMS:levelhard      8.277      1.642 442.187   5.040 6.78e-07 ***\ntaskST:levelhard      4.567      1.642 442.187   2.781 0.005644 ** \ntaskMS:levelmedium    6.190      1.642 442.187   3.770 0.000186 ***\ntaskST:levelmedium    3.046      1.642 442.187   1.855 0.064272 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlhrd lvlmdm tskMS:lvlh tskST:lvlh tskMS:lvlm\ntaskMS      -0.513                                                             \ntaskST      -0.513  0.495                                                      \nlevelhard   -0.516  0.497  0.497                                               \nlevelmedium -0.516  0.497  0.497  0.500                                        \ntskMS:lvlhr  0.363 -0.707 -0.350 -0.704 -0.352                                 \ntskST:lvlhr  0.363 -0.350 -0.707 -0.704 -0.352  0.496                          \ntskMS:lvlmd  0.363 -0.707 -0.350 -0.352 -0.704  0.500      0.248               \ntskST:lvlmd  0.363 -0.350 -0.707 -0.352 -0.704  0.248      0.500      0.496    \n\nanova(mix_ME_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask       1701.6  850.78     2 442.97 22.3407 5.706e-10 ***\nlevel      4553.9 2276.97     2 442.19 59.7908 &lt; 2.2e-16 ***\ntask:level 1052.5  263.12     4 442.19  6.9092 2.114e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_ME_w)\n\n           R2m      R2c\n[1,] 0.1675231 0.557085\n\nr2tof2(r.squaredGLMM(mix_ME_w)[1])\n\n[1] 0.2012346\n\n\n\n\n\n\nmix_PH_w &lt;- lmer(PH ~ task * level + (1|id), \n               NASATLX_weighted_toloka,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PH_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PH ~ task * level + (1 | id)\n   Data: NASATLX_weighted_toloka\n\nREML criterion at convergence: 1407.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.8287 -0.5162 -0.1339  0.4465  5.1533 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 12.92    3.594   \n Residual             13.31    3.648   \nNumber of obs: 249, groups:  id, 42\n\nFixed effects:\n                    Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)          4.07914    0.86362 134.29576   4.723 5.77e-06 ***\ntaskMS              -0.79728    1.00454 210.04071  -0.794 0.428282    \ntaskST               0.03722    1.01793 210.51273   0.037 0.970868    \nlevelhard            0.56042    0.91208 199.72124   0.614 0.539626    \nlevelmedium          0.68542    0.91208 199.72124   0.751 0.453245    \ntaskMS:levelhard     4.72420    1.36226 199.72124   3.468 0.000642 ***\ntaskST:levelhard     1.84492    1.37721 199.72124   1.340 0.181898    \ntaskMS:levelmedium   3.48125    1.36226 199.72124   2.555 0.011348 *  \ntaskST:levelmedium   0.92792    1.37721 199.72124   0.674 0.501241    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlhrd lvlmdm tskMS:lvlh tskST:lvlh tskMS:lvlm\ntaskMS      -0.514                                                             \ntaskST      -0.509  0.456                                                      \nlevelhard   -0.528  0.454  0.448                                               \nlevelmedium -0.528  0.454  0.448  0.500                                        \ntskMS:lvlhr  0.354 -0.678 -0.300 -0.670 -0.335                                 \ntskST:lvlhr  0.350 -0.301 -0.676 -0.662 -0.331  0.443                          \ntskMS:lvlmd  0.354 -0.678 -0.300 -0.335 -0.670  0.500      0.222               \ntskST:lvlmd  0.350 -0.301 -0.676 -0.331 -0.662  0.222      0.500      0.443    \n\nanova(mix_PH_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n           Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask       128.02  64.008     2 222.12  4.8089  0.009025 ** \nlevel      343.50 171.748     2 199.72 12.9034 5.367e-06 ***\ntask:level 175.57  43.893     4 199.72  3.2976  0.012102 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PH_w)\n\n            R2m       R2c\n[1,] 0.09073874 0.5385182\n\nr2tof2(r.squaredGLMM(mix_PH_w)[1])\n\n[1] 0.09979391\n\n\n\n\n\n\nmix_TI_w &lt;- lmer(TI ~ task * level + (1|id), \n               NASATLX_weighted_toloka,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_TI_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: TI ~ task * level + (1 | id)\n   Data: NASATLX_weighted_toloka\n\nREML criterion at convergence: 3086.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.72162 -0.63424 -0.03131  0.70317  2.45285 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 25.48    5.048   \n Residual             45.75    6.764   \nNumber of obs: 453, groups:  id, 57\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)          4.9189     1.2919 312.9061   3.808 0.000169 ***\ntaskMS               3.4741     1.4229 392.8901   2.442 0.015064 *  \ntaskST               6.1505     1.4335 392.8109   4.290 2.25e-05 ***\nlevelhard            0.4205     1.5317 387.3563   0.275 0.783821    \nlevelmedium         -0.1368     1.5317 387.3563  -0.089 0.928906    \ntaskMS:levelhard    11.7339     1.9878 387.3563   5.903 7.81e-09 ***\ntaskST:levelhard    12.2728     2.0025 387.3563   6.129 2.18e-09 ***\ntaskMS:levelmedium   7.5730     1.9878 387.3563   3.810 0.000162 ***\ntaskST:levelmedium  10.4883     2.0025 387.3563   5.238 2.67e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlhrd lvlmdm tskMS:lvlh tskST:lvlh tskMS:lvlm\ntaskMS      -0.665                                                             \ntaskST      -0.659  0.598                                                      \nlevelhard   -0.593  0.538  0.534                                               \nlevelmedium -0.593  0.538  0.534  0.500                                        \ntskMS:lvlhr  0.457 -0.699 -0.412 -0.771 -0.385                                 \ntskST:lvlhr  0.453 -0.412 -0.698 -0.765 -0.382  0.589                          \ntskMS:lvlmd  0.457 -0.699 -0.412 -0.385 -0.771  0.500      0.295               \ntskST:lvlmd  0.453 -0.412 -0.698 -0.382 -0.765  0.295      0.500      0.589    \n\nanova(mix_TI_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask       12262.5  6131.3     2 397.60 134.013 &lt; 2.2e-16 ***\nlevel       5475.6  2737.8     2 387.36  59.841 &lt; 2.2e-16 ***\ntask:level  2391.1   597.8     4 387.36  13.066  5.43e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_TI_w)\n\n           R2m       R2c\n[1,] 0.4124144 0.6225992\n\nr2tof2(r.squaredGLMM(mix_TI_w)[1])\n\n[1] 0.7018797\n\n\n\n\n\n\nmix_PE_w &lt;- lmer(PE ~ task * level + (1|id), \n               NASATLX_weighted_toloka,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_PE_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: PE ~ task * level + (1 | id)\n   Data: NASATLX_weighted_toloka\n\nREML criterion at convergence: 2534.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4038 -0.6227 -0.1395  0.4967  4.3351 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept)  9.315   3.052   \n Residual             16.765   4.095   \nNumber of obs: 435, groups:  id, 55\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)          6.0120     0.6986 224.2745   8.606 1.34e-15 ***\ntaskMS              -5.1217     0.8316 374.9002  -6.159 1.89e-09 ***\ntaskST              -4.5701     0.8316 374.9002  -5.495 7.22e-08 ***\nlevelhard            1.7572     0.7954 369.9646   2.209 0.027767 *  \nlevelmedium          0.8755     0.7954 369.9646   1.101 0.271749    \ntaskMS:levelhard     5.4848     1.1669 369.9646   4.700 3.67e-06 ***\ntaskST:levelhard     5.9123     1.1669 369.9646   5.067 6.40e-07 ***\ntaskMS:levelmedium   2.6608     1.1669 369.9646   2.280 0.023159 *  \ntaskST:levelmedium   3.8767     1.1669 369.9646   3.322 0.000982 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlhrd lvlmdm tskMS:lvlh tskST:lvlh tskMS:lvlm\ntaskMS      -0.547                                                             \ntaskST      -0.547  0.464                                                      \nlevelhard   -0.569  0.478  0.478                                               \nlevelmedium -0.569  0.478  0.478  0.500                                        \ntskMS:lvlhr  0.388 -0.702 -0.326 -0.682 -0.341                                 \ntskST:lvlhr  0.388 -0.326 -0.702 -0.682 -0.341  0.465                          \ntskMS:lvlmd  0.388 -0.702 -0.326 -0.341 -0.682  0.500      0.232               \ntskST:lvlmd  0.388 -0.326 -0.702 -0.341 -0.682  0.232      0.500      0.465    \n\nanova(mix_PE_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask        411.64  205.82     2 383.44 12.2767 6.793e-06 ***\nlevel      2235.64 1117.82     2 369.96 66.6757 &lt; 2.2e-16 ***\ntask:level  567.45  141.86     4 369.96  8.4618 1.530e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_PE_w)\n\n           R2m       R2c\n[1,] 0.2149063 0.4953086\n\nr2tof2(r.squaredGLMM(mix_PE_w)[1])\n\n[1] 0.2737332\n\n\n\n\n\n\nmix_EF_w &lt;- lmer(EF ~ task * level + (1|id), \n               NASATLX_weighted_toloka,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_EF_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF ~ task * level + (1 | id)\n   Data: NASATLX_weighted_toloka\n\nREML criterion at convergence: 3269.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9884 -0.5890  0.0287  0.6587  3.1021 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 29.92    5.470   \n Residual             28.61    5.349   \nNumber of obs: 510, groups:  id, 57\n\nFixed effects:\n                   Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)          11.209      1.013 162.351  11.062  &lt; 2e-16 ***\ntaskMS               -3.359      1.002 444.802  -3.353 0.000869 ***\ntaskST               -1.801      1.007 444.975  -1.788 0.074451 .  \nlevelhard             2.077      1.002 444.802   2.073 0.038728 *  \nlevelmedium           1.182      1.002 444.802   1.180 0.238557    \ntaskMS:levelhard      6.007      1.417 444.802   4.239 2.73e-05 ***\ntaskST:levelhard      2.509      1.423 444.802   1.763 0.078665 .  \ntaskMS:levelmedium    4.863      1.417 444.802   3.432 0.000655 ***\ntaskST:levelmedium    2.560      1.423 444.802   1.799 0.072698 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlhrd lvlmdm tskMS:lvlh tskST:lvlh tskMS:lvlm\ntaskMS      -0.494                                                             \ntaskST      -0.492  0.497                                                      \nlevelhard   -0.494  0.500  0.497                                               \nlevelmedium -0.494  0.500  0.497  0.500                                        \ntskMS:lvlhr  0.350 -0.707 -0.352 -0.707 -0.354                                 \ntskST:lvlhr  0.348 -0.352 -0.707 -0.704 -0.352  0.498                          \ntskMS:lvlmd  0.350 -0.707 -0.352 -0.354 -0.707  0.500      0.249               \ntskST:lvlmd  0.348 -0.352 -0.707 -0.352 -0.704  0.249      0.500      0.498    \n\nanova(mix_EF_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask         12.60    6.30     2 445.14  0.2202 0.8024532    \nlevel      2216.76 1108.38     2 444.80 38.7414 3.088e-16 ***\ntask:level  588.05  147.01     4 444.80  5.1386 0.0004689 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_EF_w)\n\n            R2m       R2c\n[1,] 0.08644249 0.5534284\n\nr2tof2(r.squaredGLMM(mix_EF_w)[1])\n\n[1] 0.09462184\n\n\n\n\n\n\nmix_FR_w &lt;- lmer(FR ~ task * level + (1|id), \n               NASATLX_weighted_toloka,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_FR_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: FR ~ task * level + (1 | id)\n   Data: NASATLX_weighted_toloka\n\nREML criterion at convergence: 3242.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6261 -0.6446 -0.1407  0.5539  3.2182 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 14.39    3.794   \n Residual             37.79    6.148   \nNumber of obs: 492, groups:  id, 57\n\nFixed effects:\n                   Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)          8.1170     0.9637 309.0817   8.423  1.4e-15 ***\ntaskMS              -2.1394     1.1816 429.6511  -1.811 0.070905 .  \ntaskST              -2.0890     1.1692 428.9150  -1.787 0.074698 .  \nlevelhard            1.8595     1.1618 427.3609   1.601 0.110212    \nlevelmedium          0.8464     1.1618 427.3609   0.729 0.466674    \ntaskMS:levelhard     6.4373     1.6661 427.3609   3.864 0.000129 ***\ntaskST:levelhard     5.7223     1.6505 427.3609   3.467 0.000579 ***\ntaskMS:levelmedium   4.1724     1.6661 427.3609   2.504 0.012641 *  \ntaskST:levelmedium   3.9742     1.6505 427.3609   2.408 0.016467 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlhrd lvlmdm tskMS:lvlh tskST:lvlh tskMS:lvlm\ntaskMS      -0.594                                                             \ntaskST      -0.600  0.491                                                      \nlevelhard   -0.603  0.492  0.497                                               \nlevelmedium -0.603  0.492  0.497  0.500                                        \ntskMS:lvlhr  0.420 -0.705 -0.346 -0.697 -0.349                                 \ntskST:lvlhr  0.424 -0.346 -0.706 -0.704 -0.352  0.491                          \ntskMS:lvlmd  0.420 -0.705 -0.346 -0.349 -0.697  0.500      0.245               \ntskST:lvlmd  0.424 -0.346 -0.706 -0.352 -0.704  0.245      0.500      0.491    \n\nanova(mix_FR_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask        180.15   90.07     2 432.57  2.3833 0.0934540 .  \nlevel      2905.32 1452.66     2 427.36 38.4370 4.463e-16 ***\ntask:level  713.79  178.45     4 427.36  4.7216 0.0009745 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_FR_w)\n\n           R2m       R2c\n[1,] 0.1276934 0.3682543\n\nr2tof2(r.squaredGLMM(mix_FR_w)[1])\n\n[1] 0.1463859\n\n\n\n\n\n\nmix_OW_w &lt;- lmer(OW ~ task * level + (1|id), \n               NASATLX_weighted_toloka,\n               contrasts = list(level=\"contr.treatment\"))\nsummary(mix_OW_w)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: OW ~ task * level + (1 | id)\n   Data: NASATLX_weighted_toloka\n\nREML criterion at convergence: 646.5\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.24644 -0.57182 -0.03982  0.54243  2.50481 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 197.0    14.04   \n Residual             251.4    15.86   \nNumber of obs: 81, groups:  id, 19\n\nFixed effects:\n                   Estimate Std. Error     df t value Pr(&gt;|t|)    \n(Intercept)          37.704      6.498 66.090   5.802 2.02e-07 ***\ntaskMS               -8.343      7.997 65.860  -1.043 0.300617    \ntaskST                3.023      8.352 64.152   0.362 0.718567    \nlevelhard             6.822      7.474 54.932   0.913 0.365363    \nlevelmedium           8.430      7.474 54.932   1.128 0.264304    \ntaskMS:levelhard     38.511     10.303 54.932   3.738 0.000444 ***\ntaskST:levelhard     24.361     10.896 54.932   2.236 0.029444 *  \ntaskMS:levelmedium   18.404     10.303 54.932   1.786 0.079570 .  \ntaskST:levelmedium   14.570     10.896 54.932   1.337 0.186648    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) taskMS taskST lvlhrd lvlmdm tskMS:lvlh tskST:lvlh tskMS:lvlm\ntaskMS      -0.636                                                             \ntaskST      -0.583  0.421                                                      \nlevelhard   -0.575  0.467  0.447                                               \nlevelmedium -0.575  0.467  0.447  0.500                                        \ntskMS:lvlhr  0.417 -0.644 -0.325 -0.725 -0.363                                 \ntskST:lvlhr  0.395 -0.321 -0.652 -0.686 -0.343  0.498                          \ntskMS:lvlmd  0.417 -0.644 -0.325 -0.363 -0.725  0.500      0.249               \ntskST:lvlmd  0.395 -0.321 -0.652 -0.343 -0.686  0.249      0.500      0.498    \n\nanova(mix_OW_w)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value    Pr(&gt;F)    \ntask        2438.6  1219.3     2 66.213  4.8500   0.01082 *  \nlevel      10878.1  5439.0     2 54.932 21.6352 1.176e-07 ***\ntask:level  3592.3   898.1     4 54.932  3.5723   0.01165 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nr.squaredGLMM(mix_OW_w)\n\n           R2m       R2c\n[1,] 0.3386421 0.6292144\n\nr2tof2(r.squaredGLMM(mix_OW_w)[1])\n\n[1] 0.5120405\n\n\n\n\n\n\nNASATLX_weighted_toloka |&gt; \n  mutate(level = factor(level, ordered = TRUE,\n                        levels = c(\"easy\", \"medium\", \"hard\"))) %&gt;% \n  pivot_longer(cols = c(\"ME\", \"PH\", \"EF\", \"PE\", \"TI\", \"FR\", \"OW\"),\n               names_to = \"scale\", values_to = \"weighted_score\") %&gt;% \n  filter(scale != \"OW\") %&gt;% \n  ggplot() + \n  stat_summary(aes(level, weighted_score),\n               fun.data = mean_cl_boot, geom = \"errorbar\", \n               width = .5,\n               position = pd) +\n  stat_summary(aes(level, weighted_score),\n               fun = mean, geom = \"point\",\n               size = 2,\n               position = pd) +\n  facet_grid(task ~ scale, scales = \"free_y\") +\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values = level_colors) +\n  labs(title = \"NASA-TLX\",\n       x = \"Difficulty Level\",\n       y = \"Score (weighted)\")\n\nWarning: Removed 432 rows containing non-finite values (`stat_summary()`).\nRemoved 432 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\n\nNASATLX_weighted_toloka |&gt; \n  mutate(level = factor(level, ordered = TRUE,\n                        levels = c(\"easy\", \"medium\", \"hard\"))) %&gt;% \n  pivot_longer(cols = c(\"ME\", \"PH\", \"EF\", \"PE\", \"TI\", \"FR\", \"OW\"),\n               names_to = \"scale\", values_to = \"weighted_score\") %&gt;% \n  filter(scale == \"OW\") %&gt;% \n  ggplot() + \n  stat_summary(aes(level, weighted_score),\n               fun.data = mean_cl_boot, geom = \"errorbar\", \n               width = .3,\n               position = pd) +\n  stat_summary(aes(level, weighted_score),\n               fun = mean, geom = \"point\",\n               size = 2,\n               position = pd) +\n  facet_grid(task ~ scale, scales = \"free_y\") +\n  theme(legend.position = \"bottom\") +\n  scale_color_manual(values = level_colors) +\n  labs(title = \"NASA-TLX\",\n       x = \"Difficulty Level\",\n       y = \"Score (weighted)\")\n\nWarning: Removed 432 rows containing non-finite values (`stat_summary()`).\nRemoved 432 rows containing non-finite values (`stat_summary()`)."
  },
  {
    "objectID": "analysis_toloka.html#correlation-matrix",
    "href": "analysis_toloka.html#correlation-matrix",
    "title": "Analysis. Toloka Banch",
    "section": "",
    "text": "corrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"MR\" & level == \"hard\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"MR\" & level == \"medium\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"MR\" & level == \"easy\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"MS\" & level == \"hard\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"MS\" & level == \"medium\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"MS\" & level == \"easy\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"MS\" & level == \"easy\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"ST\" & level == \"hard\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"ST\" & level == \"medium\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)\n\n\n\n\n\n\n\n\ncorrplot::corrplot.mixed(\n  cor(NASATLX_full %&gt;% \n        filter(task == \"ST\" & level == \"easy\") %&gt;% \n        select(scale, score, id) %&gt;% \n        pivot_wider(names_from = scale, values_from = score) %&gt;% \n        select(-id)\n      )\n)"
  },
  {
    "objectID": "preproc_pavlovia.html",
    "href": "preproc_pavlovia.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\n\n\n\n\nmr_preproc <- function(d) {\n\n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_easy.keys,\n    resp_MR_easy.corr,\n    resp_MR_easy.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      \"id\" = \"Индивидуальный_код\",\n      # rename columns for handy usage\n      \"key\" = resp_MR_easy.keys,\n      \"is_correct\" = resp_MR_easy.corr,\n      \"rt\" = resp_MR_easy.rt\n    ) -> MR_easy # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_medium.keys,\n    resp_MR_medium.corr,\n    resp_MR_medium.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |>  # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_MR_medium.keys,\n      \"is_correct\" = resp_MR_medium.corr,\n      \"rt\" = resp_MR_medium.rt\n    ) -> MR_medium # ready to use\n  \n  \n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_hard.keys,\n    resp_MR_hard.corr,\n    resp_MR_hard.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_MR_hard.keys,\n      \"is_correct\" = resp_MR_hard.corr,\n      \"rt\" = resp_MR_hard.rt\n    ) -> MR_hard # ready to use\n  \n  # bind all conditions of mental rotation task to one tibble\n  \n  bind_rows(MR_easy, MR_medium, MR_hard) -> MR\n  \n  return(MR)\n  \n}\n\n\nms_preproc <- function(d) {\n  \n  # Since we our participants could fill the fields in any order, \n  # here is a function which allows us to count correct inputs \n  # our subjects made.\n  \n  n_count <- function(df) {\n    df |> select(matches(\"^noun\")) |> as.matrix() -> s\n    df |> select(matches(\"^resp\")) |> as.matrix() -> r\n    a <- vector(mode = \"numeric\", length = 16L)\n    for (i in 1:16) {\n      a[i] <- sum(r[i, ] %in% s[i, ])\n    }\n    return(a)\n  }\n  \n  if (\"mouse_MSe.time\" %in% colnames(d)) {\n    \n    d |> select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"resp\\\\d\\\\.text$\"),\n      \"mouse_MSe.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\") |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"id\" = \"Индивидуальный_код\",\n        \"rt\" = \"mouse_MSe.time\"\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"MSm.text$\"),\n      \"mouse_MSm.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\") |> \n      rename(\"id\" = \"Индивидуальный_код\",\n             \"rt\" = \"mouse_MSm.time\") |>\n      rename_with(.fn = str_replace_all, \n                  pattern = \"_MSm\\\\.text\", \n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(\n      \"Индивидуальный_код\",\n      matches(\"^noun\"),\n      matches(\"MSh.text$\"),\n      \"mouse_MSh.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\") |>\n      rename(\"id\" = \"Индивидуальный_код\",\n             \"rt\" = \"mouse_MSh.time\") |> \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\",\n                  replacement = \"\") -> MS_hard\n    \n  } else {\n    \n    d |> select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"resp\\\\d\\\\.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\",\n             rt = NA) |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"id\" = \"Индивидуальный_код\"\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"MSm.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\",\n             rt = NA) |>\n      rename(\"id\" = \"Индивидуальный_код\") |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSm\\\\.text\",\n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(\"Индивидуальный_код\",\n                matches(\"^noun\"),\n                matches(\"MSh.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\",\n             rt = NA) |>\n      rename(\"id\" = \"Индивидуальный_код\") |> \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\", \n                  replacement = \"\") -> MS_hard\n  }\n  \n  tibble(\n    id = MS_easy$id[1],\n    trials = 1:16,\n    MS_easy_n = n_count(MS_easy),\n    MS_easy_rt = MS_easy$rt,\n    MS_medium_n = n_count(MS_medium),\n    MS_medium_rt = MS_medium$rt,\n    MS_hard_n = n_count(MS_hard),\n    MS_hard_rt = MS_hard$rt\n  ) |>\n    pivot_longer(cols = -c(\"id\", \"trials\"), values_to = \"value\") |>\n    separate(name, c(\"task\", \"level\", \"name\")) |>\n    pivot_wider(values_from = value, names_from = name) |>\n    mutate(acc = ifelse(level == \"easy\", n / 3,\n                        ifelse(\n                          level == \"medium\", n / 5,\n                          ifelse(level == \"hard\", n / 7, NA)\n                        ))) -> MS\n  \n  return(MS)\n  \n}\n\n\nst_preproc <- function(d) {\n\n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    key_resp_SE.keys,\n    key_resp_SE.corr,\n    key_resp_SE.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = key_resp_SE.keys,\n      \"is_correct\" = key_resp_SE.corr,\n      \"rt\" = key_resp_SE.rt\n    ) -> ST_easy # ready to use\n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    key_resp_SM.keys,\n    key_resp_SM.corr,\n    key_resp_SM.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = key_resp_SM.keys,\n      \"is_correct\" = key_resp_SM.corr,\n      \"rt\" = key_resp_SM.rt\n    ) -> ST_medium # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    \"Индивидуальный_код\",\n    target_present,\n    resp_S_H_trials.keys,\n    resp_S_H_trials.corr,\n    resp_S_H_trials.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"id\" = \"Индивидуальный_код\",\n      \"key\" = resp_S_H_trials.keys,\n      \"is_correct\" = resp_S_H_trials.corr,\n      \"rt\" = resp_S_H_trials.rt\n    ) -> ST_hard # ready to use\n  \n  # bind all conditions of sternberg task to one tibble\n  bind_rows(ST_easy, ST_hard, ST_medium) -> ST\n  \n  return(ST)\n\n}\n\n\nnasatlx_preproc <- function(d) {\n  d |> select(\"Индивидуальный_код\",\n              slider.response,\n              head,\n              task_type,\n              task_level) |>\n    filter_at(vars(head, task_type, task_level), all_vars(!is.na(.))) |>\n    rename(\"id\" = \"Индивидуальный_код\",\n           \"score\" = slider.response) |>\n    mutate(\n      scale = recode(\n        head,\n        \"Умственная нагрузка\" = \"ME\",\n        \"Физическая нагрузка\" = \"PH\",\n        \"Давление времени\" = \"TI\",\n        \"Успешность выполнения\" = \"PE\",\n        \"Усилия\" = \"EF\",\n        \"Уровень фрустрации\" = \"FR\"\n      ),\n      task = recode(\n        task_type,\n        \"mental_rotation\" = \"MR\",\n        \"sternberg\" = \"ST\",\n        \"mental_span\" = \"MS\"\n      ),\n      level = recode(\n        task_level,\n        \"1\" = \"easy\",\n        \"2\" = \"medium\",\n        \"3\" = \"hard\"\n      )\n    ) |>\n    select(id, scale, score, task, level) -> NASATLX\n  \n  return(NASATLX)\n}\n\n\nsequence_preproc <- function(d) {\n  \n  d |> select(\n    E_rotation,\n    M_rotation,\n    H_rotation,\n    E_Sternberg,\n    M_Sternberg,\n    H_Sternberg,\n    E_span,\n    M_span,\n    H_span\n  ) |>\n    drop_na() |>\n    sapply(function(x) which(x == 1)) -> v \n    \n  tibble(name = names(v),\n           order = v,\n           id = d[[\"Индивидуальный_код\"]][1]) |>\n    arrange(order) |>\n    separate(name, c(\"level\", \"task\"), \"_\") |>\n    mutate(\n      task = recode(\n        task,\n        \"rotation\" = \"MR\",\n        \"Sternberg\" = \"ST\",\n        \"span\" = \"MS\"\n      ),\n      level = recode(\n        level,\n        \"E\" = \"easy\",\n        \"M\" = \"medium\",\n        \"H\" = \"hard\"\n      )\n    ) -> SEQUENCE\n  \n  return(SEQUENCE)\n  \n}\n\n\n\n\n\nfiles <- paste0(\"../data-pav/\", dir(\"../data-pav\"))\nlength(files)\n\n[1] 82\n\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\nSEQUENCE_data <- tibble()\n\n\n## broken files\n## file.remove(\"../data-pav/043SSMZ_entire_exp_2022-08-17_14h14.50.460.csv\")\n\n\n# files <- paste0(\"../data-pav/\", dir(\"../data-pav\"))\n# length(files)\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  SEQUENCE_data |> bind_rows(sequence_preproc(d) |> mutate(file = files[i])) -> SEQUENCE_data\n\n}\n\n[1] \"../data-pav/001SSMS_entire_exp_2022-05-31_18h24.17.csv\"\n[1] \"../data-pav/003SSKS_entire_exp_2022-06-16_20h02.35.389.csv\"\n[1] \"../data-pav/004SSDR_entire_exp_2022-06-02_21h35.09.567.csv\"\n[1] \"../data-pav/005SSDR_entire_exp_2022-05-31_20h43.50.910.csv\"\n[1] \"../data-pav/006SSEE_entire_exp_2022-06-02_22h14.18.092.csv\"\n[1] \"../data-pav/007SSJM_entire_exp_2022-06-01_15h12.27.341.csv\"\n[1] \"../data-pav/008SSEP_entire_exp_2022-09-15_21h36.55.631.csv\"\n[1] \"../data-pav/009SSAP_entire_exp_2022-06-04_15h48.30.436.csv\"\n[1] \"../data-pav/010SSEA_entire_exp_2022-06-07_24h08.05.064.csv\"\n[1] \"../data-pav/011SSAB_entire_exp_2022-06-01_14h54.48.csv\"\n[1] \"../data-pav/012EROP_entire_exp_2022-07-14_20h26.20.219.csv\"\n[1] \"../data-pav/013ERVB_entire_exp_2022-06-23_15h53.22.750.csv\"\n[1] \"../data-pav/014ERAI_entire_exp_2022-06-16_13h57.46.683.csv\"\n[1] \"../data-pav/015ERIG_entire_exp_2022-08-17_23h56.01.csv\"\n[1] \"../data-pav/016ERSA_entire_exp_2022-06-16_14h19.07.981.csv\"\n[1] \"../data-pav/017ERVZ_entire_exp_2022-08-20_16h11.35.184.csv\"\n[1] \"../data-pav/019ERSM_entire_exp_2022-06-18_21h43.19.372.csv\"\n[1] \"../data-pav/021SSAZ_entire_exp_2022-07-15_03h19.45.491.csv\"\n[1] \"../data-pav/022ERVS_entire_exp_2022-07-15_21h42.11.588.csv\"\n[1] \"../data-pav/023ERRS_entire_exp_2022-07-11_18h59.41.csv\"\n[1] \"../data-pav/024SSSV_entire_exp_2022-07-24_18h50.18.841.csv\"\n[1] \"../data-pav/025ARAS_entire_exp_2023-05-02_19h18.58.479.csv\"\n[1] \"../data-pav/026SSDM_entire_exp_2022-07-16_12h26.44.968.csv\"\n[1] \"../data-pav/027ARDB_entire_exp_2022-07-18_10h37.13.819.csv\"\n[1] \"../data-pav/029SSDL_entire_exp_2022-07-16_09h09.20.517.csv\"\n[1] \"../data-pav/030SSPM_entire_exp_2022-08-17_21h31.18.058.csv\"\n[1] \"../data-pav/031SSAS_entire_exp_2022-07-16_08h00.03.221.csv\"\n[1] \"../data-pav/032SSAP_entire_exp_2022-07-17_13h28.21.518.csv\"\n[1] \"../data-pav/033SSML_entire_exp_2022-07-26_18h52.18.365.csv\"\n[1] \"../data-pav/035SSDD_entire_exp_2022-08-14_12h43.23.036.csv\"\n[1] \"../data-pav/037ARDL_entire_exp_2022-07-16_22h20.51.764.csv\"\n[1] \"../data-pav/038AREN_entire_exp_2022-07-19_11h25.52.006.csv\"\n[1] \"../data-pav/039ARVP_entire_exp_2022-08-08_15h15.43.173.csv\"\n[1] \"../data-pav/040ARKK_entire_exp_2023-04-23_17h12.22.533.csv\"\n[1] \"../data-pav/042SSAA_entire_exp_2022-08-17_14h03.26.713.csv\"\n[1] \"../data-pav/045SSEM_entire_exp_2022-08-17_14h07.54.819.csv\"\n[1] \"../data-pav/046SSVS_entire_exp_2022-08-20_13h21.07.492.csv\"\n[1] \"../data-pav/047SSAK_entire_exp_2022-08-20_23h14.23.266.csv\"\n[1] \"../data-pav/048SSAG_entire_exp_2022-08-18_20h28.36.828.csv\"\n[1] \"../data-pav/050SSAA_entire_exp_2023-04-21_13h38.45.765.csv\"\n[1] \"../data-pav/052SSME_entire_exp_2022-08-26_10h32.55.991.csv\"\n[1] \"../data-pav/053SSAF_entire_exp_2022-08-25_21h56.58.660.csv\"\n[1] \"../data-pav/054SSEB_entire_exp_2022-08-25_18h20.01.028.csv\"\n[1] \"../data-pav/055SSNS_entire_exp_2022-08-27_10h54.17.951.csv\"\n[1] \"../data-pav/056SSKA_entire_exp_2022-08-26_10h55.02.575.csv\"\n[1] \"../data-pav/058SSAB_entire_exp_2022-09-01_19h07.29.229.csv\"\n[1] \"../data-pav/059SSAS_entire_exp_2022-08-28_11h50.43.886.csv\"\n[1] \"../data-pav/062SSON_entire_exp_2022-09-03_18h24.04.978.csv\"\n[1] \"../data-pav/063SSMP_entire_exp_2022-08-31_09h41.09.233.csv\"\n[1] \"../data-pav/064SSAB_entire_exp_2022-09-09_24h56.58.121.csv\"\n[1] \"../data-pav/065SSTM_entire_exp_2022-09-08_13h04.21.029.csv\"\n[1] \"../data-pav/066SSKA_entire_exp_2023-04-20_19h55.36.813.csv\"\n[1] \"../data-pav/067SSDA_entire_exp_2022-09-08_15h14.26.648.csv\"\n[1] \"../data-pav/068SSMT_entire_exp_2022-09-08_14h02.24.512.csv\"\n[1] \"../data-pav/069SSMV_entire_exp_2022-09-09_15h05.56.561.csv\"\n[1] \"../data-pav/070SSAK_entire_exp_2022-09-08_15h22.31.854.csv\"\n[1] \"../data-pav/071SSEB_entire_exp_2022-09-13_13h34.34.403.csv\"\n[1] \"../data-pav/073SSMS_entire_exp_2022-09-17_12h41.16.219.csv\"\n[1] \"../data-pav/074SSKS_entire_exp_2022-09-09_08h40.26.331.csv\"\n[1] \"../data-pav/076SSRK_entire_exp_2022-09-10_24h29.10.709.csv\"\n[1] \"../data-pav/077SSKK_entire_exp_2022-09-09_18h47.59.035.csv\"\n[1] \"../data-pav/078SSRR_entire_exp_2023-04-23_12h12.09.879.csv\"\n[1] \"../data-pav/079SSRR_entire_exp_2022-09-18_20h01.24.482.csv\"\n[1] \"../data-pav/080SSAF_entire_exp_2022-09-09_18h48.13.239.csv\"\n[1] \"../data-pav/083SSAN_entire_exp_2022-09-10_09h01.25.268.csv\"\n[1] \"../data-pav/086SSAI_entire_exp_2022-09-09_19h50.26.340.csv\"\n[1] \"../data-pav/087SSVC_entire_exp_2022-09-17_17h38.47.991.csv\"\n[1] \"../data-pav/088SSDR_entire_exp_2022-09-16_17h28.38.834.csv\"\n[1] \"../data-pav/089SSDM_entire_exp_2023-04-25_14h12.30.529.csv\"\n[1] \"../data-pav/091SSJP_entire_exp_2022-09-14_23h28.30.070.csv\"\n[1] \"../data-pav/092SSAG_entire_exp_2022-09-10_16h20.00.504.csv\"\n[1] \"../data-pav/093SSEG_entire_exp_2022-09-14_17h20.12.899.csv\"\n[1] \"../data-pav/095SSVH_entire_exp_2022-09-15_24h16.25.521.csv\"\n[1] \"../data-pav/096SSMR_entire_exp_2023-05-06_17h41.53.790.csv\"\n[1] \"../data-pav/097SSAO_entire_exp_2022-10-30_20h04.41.269.csv\"\n[1] \"../data-pav/098SSDM_entire_exp_2023-04-23_16h09.02.953.csv\"\n[1] \"../data-pav/099SSDA_entire_exp_04-20-2023_18h41.33.261.csv\"\n[1] \"../data-pav/100SSNT_entire_exp_2023-04-25_13h53.44.583.csv\"\n[1] \"../data-pav/101SSOK_entire_exp_2023-04-25_15h56.39.280.csv\"\n[1] \"../data-pav/104SSAM_entire_exp_2022-10-30_21h32.22.451.csv\"\n[1] \"../data-pav/106SSVV_entire_exp_2022-12-15_19h50.09.372.csv\"\n[1] \"../data-pav/107SSIS_entire_exp_2023-01-28_01h20.55.238.csv\"\n\n\n\nunique(MR_data$file) |> length()\n\n[1] 82\n\nunique(ST_data$file) |> length()\n\n[1] 82\n\nunique(MS_data$file) |> length()\n\n[1] 82\n\nunique(NASATLX_data$file) |> length()\n\n[1] 82\n\nunique(SEQUENCE_data$file) |> length()\n\n[1] 82\n\n\n\n\n\n\nexptime <- tibble()\n\nfor (j in 1:length(files)) {\n  \n  print(files[j])\n  \n  tibble(file = files[j],\n         start = files[j] |> \n           str_extract(\"\\\\d{4}-\\\\d{2}-\\\\d{2}_\\\\d+h\\\\d+\\\\.\\\\d+\") |> \n           str_replace(\"h\", \":\") |> \n           str_replace(\"\\\\.\", \":\") |> \n           str_replace(\"_\", \" \") |> \n           as_datetime(tz = \"Etc/GMT-3\"),\n         end = file.info(files[j])$mtime |> \n           as_datetime(tz = \"UTC\")\n  ) |> \n    bind_rows(exptime) -> exptime\n  \n}\n\n[1] \"../data-pav/001SSMS_entire_exp_2022-05-31_18h24.17.csv\"\n[1] \"../data-pav/003SSKS_entire_exp_2022-06-16_20h02.35.389.csv\"\n[1] \"../data-pav/004SSDR_entire_exp_2022-06-02_21h35.09.567.csv\"\n[1] \"../data-pav/005SSDR_entire_exp_2022-05-31_20h43.50.910.csv\"\n[1] \"../data-pav/006SSEE_entire_exp_2022-06-02_22h14.18.092.csv\"\n[1] \"../data-pav/007SSJM_entire_exp_2022-06-01_15h12.27.341.csv\"\n[1] \"../data-pav/008SSEP_entire_exp_2022-09-15_21h36.55.631.csv\"\n[1] \"../data-pav/009SSAP_entire_exp_2022-06-04_15h48.30.436.csv\"\n[1] \"../data-pav/010SSEA_entire_exp_2022-06-07_24h08.05.064.csv\"\n[1] \"../data-pav/011SSAB_entire_exp_2022-06-01_14h54.48.csv\"\n[1] \"../data-pav/012EROP_entire_exp_2022-07-14_20h26.20.219.csv\"\n[1] \"../data-pav/013ERVB_entire_exp_2022-06-23_15h53.22.750.csv\"\n[1] \"../data-pav/014ERAI_entire_exp_2022-06-16_13h57.46.683.csv\"\n[1] \"../data-pav/015ERIG_entire_exp_2022-08-17_23h56.01.csv\"\n[1] \"../data-pav/016ERSA_entire_exp_2022-06-16_14h19.07.981.csv\"\n[1] \"../data-pav/017ERVZ_entire_exp_2022-08-20_16h11.35.184.csv\"\n[1] \"../data-pav/019ERSM_entire_exp_2022-06-18_21h43.19.372.csv\"\n[1] \"../data-pav/021SSAZ_entire_exp_2022-07-15_03h19.45.491.csv\"\n[1] \"../data-pav/022ERVS_entire_exp_2022-07-15_21h42.11.588.csv\"\n[1] \"../data-pav/023ERRS_entire_exp_2022-07-11_18h59.41.csv\"\n[1] \"../data-pav/024SSSV_entire_exp_2022-07-24_18h50.18.841.csv\"\n[1] \"../data-pav/025ARAS_entire_exp_2023-05-02_19h18.58.479.csv\"\n[1] \"../data-pav/026SSDM_entire_exp_2022-07-16_12h26.44.968.csv\"\n[1] \"../data-pav/027ARDB_entire_exp_2022-07-18_10h37.13.819.csv\"\n[1] \"../data-pav/029SSDL_entire_exp_2022-07-16_09h09.20.517.csv\"\n[1] \"../data-pav/030SSPM_entire_exp_2022-08-17_21h31.18.058.csv\"\n[1] \"../data-pav/031SSAS_entire_exp_2022-07-16_08h00.03.221.csv\"\n[1] \"../data-pav/032SSAP_entire_exp_2022-07-17_13h28.21.518.csv\"\n[1] \"../data-pav/033SSML_entire_exp_2022-07-26_18h52.18.365.csv\"\n[1] \"../data-pav/035SSDD_entire_exp_2022-08-14_12h43.23.036.csv\"\n[1] \"../data-pav/037ARDL_entire_exp_2022-07-16_22h20.51.764.csv\"\n[1] \"../data-pav/038AREN_entire_exp_2022-07-19_11h25.52.006.csv\"\n[1] \"../data-pav/039ARVP_entire_exp_2022-08-08_15h15.43.173.csv\"\n[1] \"../data-pav/040ARKK_entire_exp_2023-04-23_17h12.22.533.csv\"\n[1] \"../data-pav/042SSAA_entire_exp_2022-08-17_14h03.26.713.csv\"\n[1] \"../data-pav/045SSEM_entire_exp_2022-08-17_14h07.54.819.csv\"\n[1] \"../data-pav/046SSVS_entire_exp_2022-08-20_13h21.07.492.csv\"\n[1] \"../data-pav/047SSAK_entire_exp_2022-08-20_23h14.23.266.csv\"\n[1] \"../data-pav/048SSAG_entire_exp_2022-08-18_20h28.36.828.csv\"\n[1] \"../data-pav/050SSAA_entire_exp_2023-04-21_13h38.45.765.csv\"\n[1] \"../data-pav/052SSME_entire_exp_2022-08-26_10h32.55.991.csv\"\n[1] \"../data-pav/053SSAF_entire_exp_2022-08-25_21h56.58.660.csv\"\n[1] \"../data-pav/054SSEB_entire_exp_2022-08-25_18h20.01.028.csv\"\n[1] \"../data-pav/055SSNS_entire_exp_2022-08-27_10h54.17.951.csv\"\n[1] \"../data-pav/056SSKA_entire_exp_2022-08-26_10h55.02.575.csv\"\n[1] \"../data-pav/058SSAB_entire_exp_2022-09-01_19h07.29.229.csv\"\n[1] \"../data-pav/059SSAS_entire_exp_2022-08-28_11h50.43.886.csv\"\n[1] \"../data-pav/062SSON_entire_exp_2022-09-03_18h24.04.978.csv\"\n[1] \"../data-pav/063SSMP_entire_exp_2022-08-31_09h41.09.233.csv\"\n[1] \"../data-pav/064SSAB_entire_exp_2022-09-09_24h56.58.121.csv\"\n[1] \"../data-pav/065SSTM_entire_exp_2022-09-08_13h04.21.029.csv\"\n[1] \"../data-pav/066SSKA_entire_exp_2023-04-20_19h55.36.813.csv\"\n[1] \"../data-pav/067SSDA_entire_exp_2022-09-08_15h14.26.648.csv\"\n[1] \"../data-pav/068SSMT_entire_exp_2022-09-08_14h02.24.512.csv\"\n[1] \"../data-pav/069SSMV_entire_exp_2022-09-09_15h05.56.561.csv\"\n[1] \"../data-pav/070SSAK_entire_exp_2022-09-08_15h22.31.854.csv\"\n[1] \"../data-pav/071SSEB_entire_exp_2022-09-13_13h34.34.403.csv\"\n[1] \"../data-pav/073SSMS_entire_exp_2022-09-17_12h41.16.219.csv\"\n[1] \"../data-pav/074SSKS_entire_exp_2022-09-09_08h40.26.331.csv\"\n[1] \"../data-pav/076SSRK_entire_exp_2022-09-10_24h29.10.709.csv\"\n[1] \"../data-pav/077SSKK_entire_exp_2022-09-09_18h47.59.035.csv\"\n[1] \"../data-pav/078SSRR_entire_exp_2023-04-23_12h12.09.879.csv\"\n[1] \"../data-pav/079SSRR_entire_exp_2022-09-18_20h01.24.482.csv\"\n[1] \"../data-pav/080SSAF_entire_exp_2022-09-09_18h48.13.239.csv\"\n[1] \"../data-pav/083SSAN_entire_exp_2022-09-10_09h01.25.268.csv\"\n[1] \"../data-pav/086SSAI_entire_exp_2022-09-09_19h50.26.340.csv\"\n[1] \"../data-pav/087SSVC_entire_exp_2022-09-17_17h38.47.991.csv\"\n[1] \"../data-pav/088SSDR_entire_exp_2022-09-16_17h28.38.834.csv\"\n[1] \"../data-pav/089SSDM_entire_exp_2023-04-25_14h12.30.529.csv\"\n[1] \"../data-pav/091SSJP_entire_exp_2022-09-14_23h28.30.070.csv\"\n[1] \"../data-pav/092SSAG_entire_exp_2022-09-10_16h20.00.504.csv\"\n[1] \"../data-pav/093SSEG_entire_exp_2022-09-14_17h20.12.899.csv\"\n[1] \"../data-pav/095SSVH_entire_exp_2022-09-15_24h16.25.521.csv\"\n[1] \"../data-pav/096SSMR_entire_exp_2023-05-06_17h41.53.790.csv\"\n[1] \"../data-pav/097SSAO_entire_exp_2022-10-30_20h04.41.269.csv\"\n[1] \"../data-pav/098SSDM_entire_exp_2023-04-23_16h09.02.953.csv\"\n[1] \"../data-pav/099SSDA_entire_exp_04-20-2023_18h41.33.261.csv\"\n[1] \"../data-pav/100SSNT_entire_exp_2023-04-25_13h53.44.583.csv\"\n[1] \"../data-pav/101SSOK_entire_exp_2023-04-25_15h56.39.280.csv\"\n[1] \"../data-pav/104SSAM_entire_exp_2022-10-30_21h32.22.451.csv\"\n[1] \"../data-pav/106SSVV_entire_exp_2022-12-15_19h50.09.372.csv\"\n[1] \"../data-pav/107SSIS_entire_exp_2023-01-28_01h20.55.238.csv\"\n\n\n\nexptime |> \n  mutate(dur = abs(start - end)) -> exptime\n\n\n\n\n\nset.seed(123)\ntibble(\n  file = exptime$file,\n  id = stringi::stri_rand_strings(length(exptime$file), 10)) -> IDS\n\n\nMR_data |> \n  select(-id) |> \n  full_join(IDS, by = \"file\") |> \n  select(-file,\n         -base_pic,\n         -rotated_pic,\n         ) -> MR_data_prep\n\nST_data |> \n  select(-id) |> \n  full_join(IDS, by = \"file\") |> \n  select(-file) -> ST_data_prep\n\nMS_data |> \n  select(-id) |> \n  full_join(IDS, by = \"file\") |> \n  select(-file) -> MS_data_prep\n\nNASATLX_data |> \n  select(-id) |> \n  full_join(IDS, by = \"file\") |>\n  select(-file) |> \n  pivot_wider(names_from = scale, values_from = score) |> \n  mutate(PE = 20 - PE) |> # reverse PE scale\n  pivot_longer(cols = -c(\"task\", \"level\", \"id\"),\n               names_to = \"scale\", values_to = \"score\")  |>  \n  mutate(score = (score * 5) |> round()) -> NASATLX_data_prep\n\nSEQUENCE_data |> \n  select(-id) |> \n  full_join(IDS, by = \"file\") |> \n  select(-file) -> SEQUENCE_data_prep\n\nexptime |> \n  full_join(IDS, by = \"file\") |> \n  select(-file) -> exptime_prep\n\n\n\n\n\nMR_data_prep |> \n  write_csv(\"../preproc-data/MR_pav_data.csv\")\nST_data_prep |> \n  write_csv(\"../preproc-data/ST_pav_data.csv\")\nMS_data_prep |> \n  write_csv(\"../preproc-data/MS_pav_data.csv\")\nNASATLX_data_prep |> \n  write_csv(\"../preproc-data/NASATLX_pav_data.csv\")\nSEQUENCE_data_prep |> \n  write_csv(\"../preproc-data/SEQ_pav_data.csv\")\nexptime |> \n  write_csv(\"../preproc-data/EXPTIME_pav_data.csv\")\nIDS |> \n  write_csv(\"../preproc-data/IDS_pav_data.csv\")"
  },
  {
    "objectID": "toloka_explore.html",
    "href": "toloka_explore.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "knitr::opts_chunk$set(eval = FALSE)\n\n\n\n\nlibrary(tidyverse)\ntheme_set(theme_bw())\n\n\nrm(list=ls())\n\n\nmr_preproc <- function(d) {\n  \n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_easy.keys,\n    resp_MR_easy.corr,\n    resp_MR_easy.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_easy.keys,\n      \"is_correct\" = resp_MR_easy.corr,\n      \"rt\" = resp_MR_easy.rt\n    ) -> MR_easy # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_medium.keys,\n    resp_MR_medium.corr,\n    resp_MR_medium.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |>  # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_medium.keys,\n      \"is_correct\" = resp_MR_medium.corr,\n      \"rt\" = resp_MR_medium.rt\n    ) -> MR_medium # ready to use\n  \n  \n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_hard.keys,\n    resp_MR_hard.corr,\n    resp_MR_hard.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_hard.keys,\n      \"is_correct\" = resp_MR_hard.corr,\n      \"rt\" = resp_MR_hard.rt\n    ) -> MR_hard # ready to use\n  \n  # bind all conditions of mental rotation task to one tibble\n  \n  bind_rows(MR_easy, MR_medium, MR_hard) -> MR\n  \n  return(MR)\n  \n}\n\nst_preproc <- function(d) {\n  \n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    target_present,\n    key_resp_SE.keys,\n    key_resp_SE.corr,\n    key_resp_SE.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SE.keys,\n      \"is_correct\" = key_resp_SE.corr,\n      \"rt\" = key_resp_SE.rt\n    ) -> ST_easy # ready to use\n  \n  d |> select(\n    # select columns we need\n    target_present,\n    key_resp_SM.keys,\n    key_resp_SM.corr,\n    key_resp_SM.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SM.keys,\n      \"is_correct\" = key_resp_SM.corr,\n      \"rt\" = key_resp_SM.rt\n    ) -> ST_medium # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    target_present,\n    resp_S_H_trials.keys,\n    resp_S_H_trials.corr,\n    resp_S_H_trials.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_S_H_trials.keys,\n      \"is_correct\" = resp_S_H_trials.corr,\n      \"rt\" = resp_S_H_trials.rt\n    ) -> ST_hard # ready to use\n  \n  # bind all conditions of sternberg task to one tibble\n  bind_rows(ST_easy, ST_hard, ST_medium) -> ST\n  \n  return(ST)\n  \n}\n\nms_preproc <- function(d) {\n  \n  # Since we our participants could fill the fields in any order, \n  # here is a function which allows us to count correct inputs \n  # our subjects made.\n  \n  n_count <- function(df) {\n    df |> select(matches(\"^noun\")) |> as.matrix() -> s\n    df |> select(matches(\"^resp\")) |> as.matrix() -> r\n    a <- vector(mode = \"numeric\", length = 16L)\n    for (i in 1:16) {\n      a[i] <- sum(r[i, ] %in% s[i, ])\n    }\n    return(a)\n  }\n  \n  if (\"mouse_MSe.time\" %in% colnames(d)) {\n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"resp\\\\d\\\\.text$\"),\n      \"mouse_MSe.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\") |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"rt\" = \"mouse_MSe.time\"\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"MSm.text$\"),\n      \"mouse_MSm.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\") |> \n      rename(\"rt\" = \"mouse_MSm.time\") |>\n      rename_with(.fn = str_replace_all, \n                  pattern = \"_MSm\\\\.text\", \n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"MSh.text$\"),\n      \"mouse_MSh.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\") |>\n      rename(\"rt\" = \"mouse_MSh.time\") |> \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\",\n                  replacement = \"\") -> MS_hard\n    \n  } else {\n    \n    d |> select(matches(\"^noun\"),\n                matches(\"resp\\\\d\\\\.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\",\n             rt = NA) |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(matches(\"^noun\"),\n                matches(\"MSm.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\",\n             rt = NA) |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSm\\\\.text\",\n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(matches(\"^noun\"),\n                matches(\"MSh.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\",\n             rt = NA) |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\", \n                  replacement = \"\") -> MS_hard\n  }\n  \n  tibble(\n    #id = MS_easy$id[1],\n    trials = 1:16,\n    MS_easy_n = n_count(MS_easy),\n    MS_easy_rt = MS_easy$rt,\n    MS_medium_n = n_count(MS_medium),\n    MS_medium_rt = MS_medium$rt,\n    MS_hard_n = n_count(MS_hard),\n    MS_hard_rt = MS_hard$rt\n  ) |>\n    pivot_longer(cols = -c(\"trials\"), values_to = \"value\") |>\n    separate(name, c(\"task\", \"level\", \"name\")) |>\n    pivot_wider(values_from = value, names_from = name) |>\n    mutate(acc = ifelse(level == \"easy\", n / 3,\n                        ifelse(\n                          level == \"medium\", n / 5,\n                          ifelse(level == \"hard\", n / 7, NA)\n                        ))) -> MS\n  \n  return(MS)\n  \n}\n\nnasatlx_preproc <- function(d) {\n  d |> select(slider.response,\n              head,\n              task_type,\n              task_level) |>\n    filter_at(vars(head, task_type, task_level), all_vars(!is.na(.))) |>\n    rename(\"score\" = slider.response) |>\n    mutate(\n      scale = recode(\n        head,\n        \"Умственная нагрузка\" = \"ME\",\n        \"Физическая нагрузка\" = \"PH\",\n        \"Давление времени\" = \"TI\",\n        \"Успешность выполнения\" = \"PE\",\n        \"Усилия\" = \"EF\",\n        \"Уровень фрустрации\" = \"FR\"\n      ),\n      task = recode(\n        task_type,\n        \"mental_rotation\" = \"MR\",\n        \"sternberg\" = \"ST\",\n        \"mental_span\" = \"MS\"\n      ),\n      level = recode(\n        task_level,\n        \"1\" = \"easy\",\n        \"2\" = \"medium\",\n        \"3\" = \"hard\"\n      )\n    ) |>\n    select(scale, score, task, level) -> NASATLX\n  \n  return(NASATLX)\n}\n\n# sequence_preproc <- function(d) {\n#   \n#   d |> select(\n#     E_rotation,\n#     M_rotation,\n#     H_rotation,\n#     E_Sternberg,\n#     M_Sternberg,\n#     H_Sternberg,\n#     E_span,\n#     M_span,\n#     H_span\n#   ) |>\n#     drop_na() |>\n#     sapply(function(x) which(x == 1)) -> v \n#   \n#   tibble(name = names(v),\n#          order = v,\n#          id = d[[\"Индивидуальный_код\"]][1]) |>\n#     arrange(order) |>\n#     separate(name, c(\"level\", \"task\"), \"_\") |>\n#     mutate(\n#       task = recode(\n#         task,\n#         \"rotation\" = \"MR\",\n#         \"Sternberg\" = \"ST\",\n#         \"span\" = \"MS\"\n#       ),\n#       level = recode(\n#         level,\n#         \"E\" = \"easy\",\n#         \"M\" = \"medium\",\n#         \"H\" = \"hard\"\n#       )\n#     ) -> SEQUENCE\n#   \n#   return(SEQUENCE)\n#   \n# }\n\n\n\n\nTo compare\n\nread_csv(\"../preproc-data/MR_firstbanch_data_agg.csv\") -> MR_fb_agg\nread_csv(\"../preproc-data/MS_firstbanch_data_agg.csv\") -> MS_fb_agg\nread_csv(\"../preproc-data/ST_firstbanch_data_agg.csv\") -> ST_fb_agg\n\n\n\n\n\nfiles <- paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\"))\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nfiles <- paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\"))\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\n\n\n\nfiles <- c(\n  paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\")),\n  paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\"))\n)\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MR\")\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  labs(title = \"MR\")\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"MS\")\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  labs(title = \"MS\")\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  labs(title = \"ST\")\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  labs(title = \"ST\")\n\n\n\n\n\npool88 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40236288__21-07-2023.tsv\")\npool87 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40260687__21-07-2023.tsv\")\npool68 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40272468__21-07-2023.tsv\")\npool16 <- read_tsv(\"../data-toloka/assignments/assignments_from_pool_40307616__21-07-2023.tsv\")\n\n\npool88$`ASSIGNMENT:worker_id` %in% pool87$`ASSIGNMENT:worker_id` |> sum()\npool88$`ASSIGNMENT:worker_id` %in% pool68$`ASSIGNMENT:worker_id` |> sum()\npool88$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |> sum()\npool87$`ASSIGNMENT:worker_id` %in% pool68$`ASSIGNMENT:worker_id` |> sum()\npool87$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |> sum()\npool68$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id` |> sum()\n\n## duplicates\npool68$`ASSIGNMENT:worker_id`[pool68$`ASSIGNMENT:worker_id` %in% pool16$`ASSIGNMENT:worker_id`]\n\n\n\n\n\n#rm(list=ls())\n\n\n## broken Column `mouse_MSh.time` doesn't exist.\nfile.remove(\"../data-toloka/pool34/21111984_toloka_2023-07-21_17h42.24.114.csv\")\n\n\nfiles <- paste0(\"../data-toloka/pool34/\", dir(\"../data-toloka/pool34\"))\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\n#SEQUENCE_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  #SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data\n  \n}\n\n\n# MR_data |> write_csv(\"mentral_rotation_data_toloka.csv\")\n# ST_data |> write_csv(\"sternberg_data_toloka.csv\")\n# MS_data |> write_csv(\"mental_span_data_toloka.csv\")\n# NASATLX_data |> write_csv(\"nasa_tlx_data_toloka.csv\")\n# SEQUENCE_data |> write_csv(\"sequence_data_toloka.csv\")\n\n\nMR_data$file |> unique() |> length()\n\n\nMR_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\nMR_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct), fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MR\")\n\n\nMS_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MS_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\nMS_data |> \n  ggplot(aes(level, acc)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"MS\")\n\n\nST_data |> \n  ggplot(aes(level, rt)) +\n  stat_summary(data = MR_fb_agg,\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"pointrange\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")\n\n\nST_data |> \n  ggplot() +\n  stat_summary(data = MR_fb_agg,\n               aes(level, acc),\n               fun.data = mean_cl_boot, geom = \"pointrange\", color = \"darkred\") +\n  stat_summary(aes(level, is_correct),\n               fun = mean, geom = \"point\") +\n  facet_wrap(~ file) +\n  labs(title = \"ST\")"
  },
  {
    "objectID": "preproc_toloka.html",
    "href": "preproc_toloka.html",
    "title": "NASA-TLX",
    "section": "",
    "text": "knitr::opts_chunk$set(eval = FALSE)\n\n\n\n\nlibrary(tidyverse)\ntheme_set(theme_bw())\n\n\n\n\n\nmr_preproc <- function(d) {\n  \n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_easy.keys,\n    resp_MR_easy.corr,\n    resp_MR_easy.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_easy.keys,\n      \"is_correct\" = resp_MR_easy.corr,\n      \"rt\" = resp_MR_easy.rt\n    ) -> MR_easy # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_medium.keys,\n    resp_MR_medium.corr,\n    resp_MR_medium.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |>  # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_medium.keys,\n      \"is_correct\" = resp_MR_medium.corr,\n      \"rt\" = resp_MR_medium.rt\n    ) -> MR_medium # ready to use\n  \n  \n  \n  d |> select(\n    # select columns we need\n    correctAns,\n    base_pic,\n    rotated_pic,\n    resp_MR_hard.keys,\n    resp_MR_hard.corr,\n    resp_MR_hard.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"MR\",\n           # add task name (mental rotation)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_MR_hard.keys,\n      \"is_correct\" = resp_MR_hard.corr,\n      \"rt\" = resp_MR_hard.rt\n    ) -> MR_hard # ready to use\n  \n  # bind all conditions of mental rotation task to one tibble\n  \n  bind_rows(MR_easy, MR_medium, MR_hard) -> MR\n  \n  return(MR)\n  \n}\n\nst_preproc <- function(d) {\n  \n  require(tidyverse)\n  \n  d |> select(\n    # select columns we need\n    target_present,\n    key_resp_SE.keys,\n    key_resp_SE.corr,\n    key_resp_SE.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"easy\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SE.keys,\n      \"is_correct\" = key_resp_SE.corr,\n      \"rt\" = key_resp_SE.rt\n    ) -> ST_easy # ready to use\n  \n  d |> select(\n    # select columns we need\n    target_present,\n    key_resp_SM.keys,\n    key_resp_SM.corr,\n    key_resp_SM.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"medium\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = key_resp_SM.keys,\n      \"is_correct\" = key_resp_SM.corr,\n      \"rt\" = key_resp_SM.rt\n    ) -> ST_medium # ready to use\n  \n  \n  d |> select(\n    # select columns we need\n    target_present,\n    resp_S_H_trials.keys,\n    resp_S_H_trials.corr,\n    resp_S_H_trials.rt\n  ) |>\n    drop_na() |> # remove technical NAs (recording artefacts, not missing data)\n    mutate(task = \"ST\",\n           # add task name (Sternberg task)\n           level = \"hard\",\n           # add difficulty level\n           trial = 1:16) |> # number trials\n    rename(\n      # rename columns for handy usage\n      \"key\" = resp_S_H_trials.keys,\n      \"is_correct\" = resp_S_H_trials.corr,\n      \"rt\" = resp_S_H_trials.rt\n    ) -> ST_hard # ready to use\n  \n  # bind all conditions of sternberg task to one tibble\n  bind_rows(ST_easy, ST_hard, ST_medium) -> ST\n  \n  return(ST)\n  \n}\n\nms_preproc <- function(d) {\n  \n  # Since we our participants could fill the fields in any order, \n  # here is a function which allows us to count correct inputs \n  # our subjects made.\n  \n  n_count <- function(df) {\n    df |> select(matches(\"^noun\")) |> as.matrix() -> s\n    df |> select(matches(\"^resp\")) |> as.matrix() -> r\n    a <- vector(mode = \"numeric\", length = 16L)\n    for (i in 1:16) {\n      a[i] <- sum(r[i, ] %in% s[i, ])\n    }\n    return(a)\n  }\n  \n  if (\"mouse_MSe.time\" %in% colnames(d)) {\n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"resp\\\\d\\\\.text$\"),\n      \"mouse_MSe.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\") |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text,\n        \"rt\" = \"mouse_MSe.time\"\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"MSm.text$\"),\n      \"mouse_MSm.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\") |> \n      rename(\"rt\" = \"mouse_MSm.time\") |>\n      rename_with(.fn = str_replace_all, \n                  pattern = \"_MSm\\\\.text\", \n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(\n      matches(\"^noun\"),\n      matches(\"MSh.text$\"),\n      \"mouse_MSh.time\"\n    ) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\") |>\n      rename(\"rt\" = \"mouse_MSh.time\") |> \n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\",\n                  replacement = \"\") -> MS_hard\n    \n  } else {\n    \n    d |> select(matches(\"^noun\"),\n                matches(\"resp\\\\d\\\\.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:3)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 4:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"easy\",\n             rt = NA) |>\n      rename(\n        \"resp1\" = resp1.text,\n        \"resp2\" = resp2.text,\n        \"resp3\" = resp3.text\n      ) |>\n      select(-c(paste0(\"noun\", 4:7))) -> MS_easy\n    \n    d |> select(matches(\"^noun\"),\n                matches(\"MSm.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 4:5)), all_vars(!is.na(.))) |>\n      filter_at(vars(paste0(\"noun\", 6:7)), all_vars(is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"medium\",\n             rt = NA) |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSm\\\\.text\",\n                  replacement = \"\") |> \n      select(-noun6, -noun7) -> MS_medium\n    \n    \n    d |> select(matches(\"^noun\"),\n                matches(\"MSh.text$\")) |>\n      filter_at(vars(paste0(\"noun\", 1:7)), all_vars(!is.na(.))) |>\n      mutate(task = \"MS\",\n             level = \"hard\",\n             rt = NA) |>\n      rename_with(.fn = str_replace_all,\n                  pattern = \"_MSh\\\\.text\", \n                  replacement = \"\") -> MS_hard\n  }\n  \n  tibble(\n    #id = MS_easy$id[1],\n    trials = 1:16,\n    MS_easy_n = n_count(MS_easy),\n    MS_easy_rt = MS_easy$rt,\n    MS_medium_n = n_count(MS_medium),\n    MS_medium_rt = MS_medium$rt,\n    MS_hard_n = n_count(MS_hard),\n    MS_hard_rt = MS_hard$rt\n  ) |>\n    pivot_longer(cols = -c(\"trials\"), values_to = \"value\") |>\n    separate(name, c(\"task\", \"level\", \"name\")) |>\n    pivot_wider(values_from = value, names_from = name) |>\n    mutate(acc = ifelse(level == \"easy\", n / 3,\n                        ifelse(\n                          level == \"medium\", n / 5,\n                          ifelse(level == \"hard\", n / 7, NA)\n                        ))) -> MS\n  \n  return(MS)\n  \n}\n\nnasatlx_preproc <- function(d) {\n  d |> select(slider.response,\n              head,\n              task_type,\n              task_level) |>\n    filter_at(vars(head, task_type, task_level), all_vars(!is.na(.))) |>\n    rename(\"score\" = slider.response) |>\n    mutate(\n      scale = recode(\n        head,\n        \"Умственная нагрузка\" = \"ME\",\n        \"Физическая нагрузка\" = \"PH\",\n        \"Давление времени\" = \"TI\",\n        \"Успешность выполнения\" = \"PE\",\n        \"Усилия\" = \"EF\",\n        \"Уровень фрустрации\" = \"FR\"\n      ),\n      task = recode(\n        task_type,\n        \"mental_rotation\" = \"MR\",\n        \"sternberg\" = \"ST\",\n        \"mental_span\" = \"MS\"\n      ),\n      level = recode(\n        task_level,\n        \"1\" = \"easy\",\n        \"2\" = \"medium\",\n        \"3\" = \"hard\"\n      )\n    ) |>\n    select(scale, score, task, level) -> NASATLX\n  \n  return(NASATLX)\n}\n\nsequence_preproc <- function(d) {\n\n  d |> select(\n    E_rotation,\n    M_rotation,\n    H_rotation,\n    E_Sternberg,\n    M_Sternberg,\n    H_Sternberg,\n    E_span,\n    M_span,\n    H_span\n  ) |>\n    drop_na() |>\n    sapply(function(x) which(x == 1)) -> v\n\n  tibble(name = names(v),\n         order = v) |>\n    arrange(order) |>\n    separate(name, c(\"level\", \"task\"), \"_\") |>\n    mutate(\n      task = recode(\n        task,\n        \"rotation\" = \"MR\",\n        \"Sternberg\" = \"ST\",\n        \"span\" = \"MS\"\n      ),\n      level = recode(\n        level,\n        \"E\" = \"easy\",\n        \"M\" = \"medium\",\n        \"H\" = \"hard\"\n      )\n    ) -> SEQUENCE\n\n  return(SEQUENCE)\n\n}\n\nweights_preproc <- function(d) {\n  \n  d %>% \n    select(matches(\"^pair\"), task_type) %>% \n    drop_na() %>% \n    pivot_longer(cols = matches(\"^pair\")) %>% \n    mutate(value = value %>% str_remove_all(\"\\\\\\\\n|\\\\[|\\\\]\")) %>% \n    separate(value, into = c(\"option1\", \"option2\"), sep = \",\") -> pairs\n  \n  d %>% \n    select(matches(\"^S_pc\"), task_type) %>% \n    drop_na() %>% \n    pivot_longer(cols = matches(\"^S_pc\")) %>% \n    mutate(name = name %>% str_remove(\"\\\\.response\") %>% \n             str_replace(\"S_pc_\", \"pair\")) %>% \n    full_join(pairs, by = join_by(task_type, name)) %>% \n    mutate(choice = ifelse(value == 1, option1, option2)) %>% \n    mutate(choice = recode(choice,\n                           '\"Умственнаянагрузка\"' = \"ME\",\n                           '\"Физическаянагрузка\"' = \"PH\",\n                           '\"Усилия\"' = \"EF\",\n                           '\"Давленивремени\"' = \"TI\",\n                           '\"Успешностьвыполнения\"' = \"PE\",\n                           '\"Уровеньфрустрации\"' = \"FR\")) %>% \n    group_by(task_type, choice) %>% \n    summarise(n = n()) %>% \n    mutate(w = n / 15) -> WEIGHTS\n  \n  return(WEIGHTS)\n  \n}\n\n\n\n\n\nfiles <- c(\n  paste0(\"../data-toloka/pool1/\", dir(\"../data-toloka/pool1\")),\n  paste0(\"../data-toloka/pool2/\", dir(\"../data-toloka/pool2\")),\n  paste0(\"../data-toloka/pool34/\", dir(\"../data-toloka/pool34\")),\n  paste0(\"../data-toloka/pool5/\", dir(\"../data-toloka/pool5\"))\n)\n\n\nMR_data <- tibble()\nST_data <- tibble()\nMS_data <- tibble()\nNASATLX_data <- tibble()\nSEQUENCE_data <- tibble()\nWEIGHTS_data <- tibble()\n\n\nfor (i in 1:length(files)) {\n  \n  print(files[i])\n  \n  d <- read_csv(files[i], show_col_types = FALSE)\n  \n  MR_data |> bind_rows(mr_preproc(d) |> mutate(file = files[i])) -> MR_data\n  ST_data |> bind_rows(st_preproc(d) |> mutate(file = files[i])) -> ST_data\n  MS_data |> bind_rows(ms_preproc(d) |> mutate(file = files[i])) -> MS_data\n  NASATLX_data |> bind_rows(nasatlx_preproc(d) |> mutate(file = files[i])) -> NASATLX_data\n  SEQUENCE_data |> bind_rows(sequence_preproc(d) |> mutate(file = files[i])) -> SEQUENCE_data\n  WEIGHTS_data |> bind_rows(weights_preproc(d) |> mutate(file = files[i])) -> WEIGHTS_data\n  \n}\n\n\n\n\nset.seed(116)\ntibble(file = MR_data$file |> unique(),\n       id = stringi::stri_rand_strings(MR_data$file |> unique() |> length(),\n                                       length = 10)) |> \n  mutate(pool = str_extract_all(file, \"pool\\\\d+\") |> unlist()) -> tolokaIDS\n\n\nunique(MR_data$file) |> length()\nunique(ST_data$file) |> length()\nunique(MS_data$file) |> length()\nunique(NASATLX_data$file) |> length()\nunique(SEQUENCE_data$file) |> length()\n\n\n\n\n\n\nMR_data %>% \n  full_join(tolokaIDS, by = \"file\") |> \n  filter(pool == \"pool5\")|> \n  ggplot(aes(level, rt)) +\n  geom_boxplot(data = MR_data |> select(-file), color = \"darkred\") +\n  geom_boxplot() +\n  facet_wrap(~ file, scales = \"free_y\") +\n  ylim(0, 100)\n\n\nMS_data %>% \n  full_join(tolokaIDS, by = \"file\") |> \n  filter(pool == \"pool5\")|>\n  ggplot(aes(level, rt)) +\n  geom_boxplot(data = MS_data |> select(-file), color = \"darkred\") +\n  geom_boxplot() +\n  facet_wrap(~ file, scales = \"free_y\") +\n  ylim(0, 250)\n\n\nST_data %>% \n  full_join(tolokaIDS, by = \"file\") |> \n  filter(pool == \"pool5\")|>\n  ggplot(aes(level, rt)) +\n  geom_boxplot(data = ST_data |> select(-file), color = \"darkred\") +\n  geom_boxplot() +\n  facet_wrap(~ file, scales = \"free_y\") +\n  ylim(0, 25)\n\n\nMR_data |> \n  full_join(tolokaIDS) |> \n  select(-file) -> MR_data\nMS_data |> \n  full_join(tolokaIDS) |> \n  select(-file) -> MS_data\nST_data |> \n  full_join(tolokaIDS) |> \n  select(-file) -> ST_data\nNASATLX_data |> \n  full_join(tolokaIDS) |> \n  select(-file) %>% \n  pivot_wider(names_from = scale, values_from = score) %>% \n  mutate(PE = 20 - PE) %>% # reverse PE scale\n  pivot_longer(cols = -c(\"task\", \"level\", \"id\"),\n               names_to = \"scale\", values_to = \"score\") %>% \n  mutate(score = (score * 5) %>% round()) -> NASATLX_data\nSEQUENCE_data |> \n  full_join(tolokaIDS) |> \n  select(-file) -> SEQUENCE_data\nWEIGHTS_data |> \n  full_join(tolokaIDS) |> \n  select(-file) -> WEIGHTS_data\n\n\n\n\n\nMR_data %>% \n  group_by(id, level, task) %>% \n  summarise(median = median(rt),\n            q1 = quantile(rt, 0.25),\n            q3 = quantile(rt, 0.75),\n            iqr = q3 - q1) %>% \n  full_join(MR_data, by = c(\"id\", \"level\", \"task\")) %>% \n  mutate(not_outlier = ifelse(rt > q1 - 1.5 * iqr & rt < q3 + 1.5 * iqr, TRUE, FALSE)) %>% \n  filter(not_outlier) %>% \n  group_by(task, level, id) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> MR_data_toloka_agg\n\n\nST_data |> \n  group_by(id, level, task) %>% \n  summarise(median = median(rt),\n            q1 = quantile(rt, 0.25),\n            q3 = quantile(rt, 0.75),\n            iqr = q3 - q1) %>% \n  full_join(ST_data, by = c(\"id\", \"level\", \"task\")) %>% \n  mutate(not_outlier = ifelse(rt > q1 - 1.5 * iqr & rt < q3 + 1.5 * iqr, TRUE, FALSE)) %>% \n  filter(not_outlier) %>% \n  group_by(task, level, id) |> \n  summarise(rt = mean(rt),\n            acc = mean(is_correct)) -> ST_data_toloka_agg\n\n\nMS_data |> \n  group_by(id, level, task) %>% \n  summarise(median = median(rt),\n            q1 = quantile(rt, 0.25),\n            q3 = quantile(rt, 0.75),\n            iqr = q3 - q1) %>% \n  full_join(MS_data, by = c(\"id\", \"level\", \"task\")) %>% \n  mutate(not_outlier = ifelse(rt > q1 - 1.5 * iqr & rt < q3 + 1.5 * iqr, \n                              TRUE, FALSE)) %>% \n  filter(not_outlier) %>% \n  group_by(task, level, id) |> \n  summarise(rt = mean(rt),\n            acc = mean(acc)) -> MS_data_toloka_agg\n\n\n\n\n\nMR_data_toloka_agg |> write_csv(\"../preproc-data/mental_rotation_data_toloka.csv\")\nST_data_toloka_agg |> write_csv(\"../preproc-data/sternberg_data_toloka.csv\")\nMS_data_toloka_agg |> write_csv(\"../preproc-data/mental_span_data_toloka.csv\")\nNASATLX_data |> write_csv(\"../preproc-data/nasa_tlx_data_toloka.csv\")\nSEQUENCE_data |> write_csv(\"../preproc-data/sequence_data_toloka.csv\")\nWEIGHTS_data |> write_csv(\"../preproc-data/weights_data_toloka.csv\")"
  }
]