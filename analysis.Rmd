---
title: "NASA-TLX Approbation"
author: "Anton Angelgardt"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

# Libraries

```{r}
library(tidyverse)
theme_set(theme_bw()) # set black and white theme
library(lavaan)
library(tidySEM)
```

# Preprocess

## Load custom function for preprocess.


### Mental rotation

```{r}
source("mr-preproc-fun.R")
```

```{bash}
cat mr-preproc-fun.R
```


### Sternberg task

```{r}
source("st-preproc-fun.R")
```

```{bash}
cat st-preproc-fun.R
```


### Mental span

This here is preprocess function.

```{r}
source("ms-preproc-fun.R")
```

```{bash}
cat ms-preproc-fun.R
```

### NASA-TLX

```{r}
source("nasatlx-preproc-fun.R")
```

```{bash}
cat nasatlx-preproc-fun.R
```


### Sequence.

```{r}
source("sequence-preproc-fun.R")
```

```{bash}
cat sequence-preproc-fun.R
```


## Reading and prepropcessing files

> Broken files
> 043SSMZ_entire_exp_2022-08-17_14h14.50.460.csv ## empty file
> 030SSPM_entire_exp_2022-08-17_21h31.18.058.csv 
> 069SSMV_entire_exp_2022-09-09_15h05.56.561.csv
> 028ARAA_entire_exp_2023-04-24_14h06.54.379.csv ## no correctAns column

```{r, warning=TRUE}
broken_files <- c("043SSMZ_entire_exp_2022-08-17_14h14.50.460.csv",
                  "030SSPM_entire_exp_2022-08-17_21h31.18.058.csv",
                  "069SSMV_entire_exp_2022-09-09_15h05.56.561.csv",
                  "028ARAA_entire_exp_2023-04-24_14h06.54.379.csv") 
# not really broken but results in two unique values in wide format
# broken_files |> map(function(x) file.remove(paste0("data2/", x)))
file.remove("data2/028ARAA_entire_exp_2023-04-24_14h06.54.379.csv") ## no correctAns column
file.remove("data2/028ARAA_entire_exp_2023-04-24_14h42.11.965.csv") ## no resp_MR_easy.keys column
file.remove("data2/029SSDL_entire_exp_2022-07-16_07h45.19.402.csv") ## no key_resp_SE.keys
file.remove("data2/043SSMZ_entire_exp_2022-08-17_14h14.50.460.csv") ## empty file
file.remove("data2/047SSAK_entire_exp_2022-08-20_23h05.43.884.csv") ## Caused by error: ! `trial` must be size 8 or 1, not 16.

```

```{r preprocess}

files <- paste0("data2/", dir("data2"))

MR_data <- tibble()
ST_data <- tibble()
MS_data <- tibble()
NASATLX_data <- tibble()
SEQUENCE_data <- tibble()

for (i in 1:length(files)) {
  
  print(files[i])
  
  d <- read_csv(files[i], show_col_types = FALSE)
  
  MR_data |> bind_rows(mr_preproc(d)) -> MR_data
  ST_data |> bind_rows(st_preproc(d)) -> ST_data
  MS_data |> bind_rows(ms_preproc(d)) -> MS_data
  NASATLX_data |> bind_rows(nasatlx_preproc(d)) -> NASATLX_data
  SEQUENCE_data |> bind_rows(sequence_preproc(d)) -> SEQUENCE_data

}

MR_data |> write_csv("mentral_rotation_data.csv")
ST_data |> write_csv("sternberg_data.csv")
MS_data |> write_csv("mental_span_data.csv")
NASATLX_data |> write_csv("nasa_tlx_data.csv")
SEQUENCE_data |> write_csv("sequence_data.csv")
```

# Analysis

## Reading data

```{r}
rm(list = ls()) # clear environment
```

```{r}
MR <- read_csv("mentral_rotation_data.csv")
ST <- read_csv("sternberg_data.csv")
MS <- read_csv("mental_span_data.csv")
NASA_TLX <- read_csv("nasa_tlx_data.csv")
SEQ <- read_csv("sequence_data.csv")
```

## Check the time in the exp
```{r}
MR$rt
ST$rt
MS$rt

MR |> 
  group_by(id) |> 
  summarise(rt_mr = sum(rt)) |> 
  full_join(
    ST |> 
      group_by(id) |> 
      summarise(rt_st = sum(rt)),
    by = join_by(id)
  ) |> 
  full_join(
    MS |> 
      group_by(id) |> 
      summarise(rt_ms = sum(rt))
  ) |> 
  mutate(time = rt_mr + rt_st + rt_ms) |> 
  summarize(max = max(time, na.rm = TRUE) / 60,
            min = min(time, na.rm = TRUE) / 60,
            sd = sd(time, na.rm = TRUE) / 60)
```

### Overall time in the exp

```{r}
files <- paste0("data2/", dir("data2"))

exp_time <- tibble()

for (j in 1:length(files)) {
  print(j)
  print(files[j])
  d <- read_csv(files[j], show_col_types = FALSE)
  tibble(
    n_row = d |> nrow(),
    time = d |> 
      select(contains(".rt") | contains(".time")) |> 
      ## select all vars contains rt-like info
      sapply(FUN = sum, na.rm = TRUE) |> unlist() |> 
      sum() / 60,
    id = files[j]
  ) |> 
    bind_rows(exp_time) -> exp_time
}
```

Fixing ids:

```{r}
exp_time |> 
  mutate(id = str_extract_all(id, "\\d{3}[:upper:]{4}") |> unlist()) -> exp_time
```

```{r}
exp_time |> 
  ggplot(aes(time)) +
  geom_histogram(binwidth = 1, fill = "gray60") +
  geom_vline(xintercept = 20) +
  xlab("Time, min")
```

Suspicious first peak around 10 min. Suppose 10 min is very little time to perform all tasks.
Let's take 20 min as a threshold for "ok" time vs "non-ok" time and study relationships with experimental vars.

```{r}
exp_time |> 
  mutate(group = ifelse(time > 20, "ok", "non-ok")) -> exp_time
```

Graph acc × time and rt × time scatterplots:

```{r}
MR |> 
  group_by(id, level) |> 
  summarise(acc = mean(is_correct)) |> 
  left_join(exp_time) |> 
  ggplot(aes(time, acc,
             color = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~ level, ncol = 1, scales = "free_y") +
  labs(x = "Time, min", y = "Accuracy",
       title = "Mental Rotation (accuracy)")
```

```{r}
MR |> 
  group_by(id, level) |> 
  summarise(rt = mean(rt)) |> 
  left_join(exp_time) |> 
  ggplot(aes(time, rt,
             color = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~ level, ncol = 1, scales = "free_y") +
  labs(x = "Time, min", y = "RT, sec",
       title = "Mental Rotation (reaction time)")
```

```{r}
MS |> 
  group_by(id, level) |> 
  summarise(acc = mean(acc)) |> 
  left_join(exp_time) |> 
  ggplot(aes(time, acc,
             color = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~ level, ncol = 1, scales = "free_y") +
  labs(x = "Time, min", y = "Accuracy",
       title = "Mental Span (accuracy)")
```

```{r}
MS |> 
  group_by(id, level) |> 
  summarise(rt = mean(rt)) |> 
  left_join(exp_time) |> 
  ggplot(aes(time, rt,
             color = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~ level, ncol = 1, scales = "free_y") +
  labs(x = "Time, min", y = "RT, sec",
       title = "Mental Span (reaction time)")
```

```{r}
ST |> 
  group_by(id, level) |> 
  summarise(acc = mean(is_correct)) |> 
  left_join(exp_time) |> 
  ggplot(aes(time, acc,
             color = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~ level, ncol = 1, scales = "free_y") +
  labs(x = "Time, min", y = "Accuracy",
       title = "Sternberg (accuracy)")
```

```{r}
ST |> 
  group_by(id, level) |> 
  summarise(rt = mean(rt)) |> 
  left_join(exp_time) |> 
  ggplot(aes(time, rt,
             color = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~ level, ncol = 1, scales = "free_y") +
  labs(x = "Time, min", y = "RT, sec",
       title = "Sternberg (reaction time)")
```


Plot NASA-TLX scales × time

```{r}
NASA_TLX |> 
  left_join(exp_time) |> 
  ggplot(aes(time, score, color = scale, shape = group, linetype = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_grid(task ~ level)
```


```{r}
NASA_TLX |> 
  left_join(exp_time) |> 
  ggplot(aes(scale, score, shape = group, group = group)) +
  stat_summary(fun.data = mean_cl_boot, geom = "pointrange",
               position = position_dodge(0.5)) +
  facet_grid(task ~ level)
```



## NASA-TLX

Firstly, we need preprocess data a bit to fix factor variable `level` and create a new variable `item` for future CFA.

```{r}
NASA_TLX |>
  # fix factor
  mutate(
    level = factor(
      level,
      levels = c("easy", "medium", "hard"),
      ordered = TRUE
    ),
    # modify vars to match with previously created encoding
    scl = str_to_lower(scale),
    tsk = str_to_lower(task),
    lvl = str_sub(level, start = 1, end = 1) |> str_to_upper(),
    score = score * 5
  ) |>
  # create a new var for CFA
  unite(item, scl, tsk, lvl) -> NASA_TLX
```

```{r, include=FALSE}
NASA_TLX |> 
  group_by(task, level, scale) |> 
  summarise(n = n())
unique(NASA_TLX$item)
```

Secondly, create an exploratory visualization.

```{r}
level_colors <- c("#4bd752", "#d7984b", "#d7524b")
task_colors <- c("red4", "green4", "blue4")
back_histogram_color <- "gray60"
```

```{r}
NASA_TLX |>
  ggplot(aes(scale, score, fill = level)) +
  geom_boxplot() +
  facet_grid(task ~ .) +
  theme(legend.position = "bottom") +
  labs(x = "NASA-TLX Scale",
       y = "NASA-TLX Score (raw)",
       fill = "Difficulty Level") +
  scale_fill_manual(values = level_colors)
```

```{r}
pd <- position_dodge(0.3)
NASA_TLX |>
  ggplot(aes(scale, score, color = level)) +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar",
               position = pd, width = .3) +
  stat_summary(fun = mean, geom = "point",
               position = pd) +
  facet_grid(task ~ .) +
  theme(legend.position = "bottom") +
  labs(x = "NASA-TLX Scale",
       y = "NASA-TLX Score (raw)",
       fill = "Difficulty Level") +
  scale_color_manual(values = level_colors)
```

```{r}
pd <- position_dodge(0.3)
NASA_TLX |>
  ggplot(aes(scale, score, color = level)) +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar",
               position = pd, width = .3) +
  stat_summary(fun = mean, geom = "point",
               position = pd) +
  facet_grid(task ~ .) +
  theme(legend.position = "bottom") +
  labs(x = "Шкалы NASA-TLX",
       y = "NASA-TLX (сырой балл)",
       color = "Уровень сложности") +
  scale_color_manual(values = level_colors, 
                     labels = c(easy = "легкий", 
                                medium = "средний", 
                                hard = "сложный"))
ggsave("anova_errorbars_color.png", dpi = 300)
```

```{r}
pd <- position_dodge(0.3)
NASA_TLX |>
  ggplot(aes(scale, score, color = level)) +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar",
               position = pd, width = .3) +
  stat_summary(fun = mean, geom = "point",
               position = pd) +
  facet_grid(task ~ .) +
  theme(legend.position = "bottom") +
  labs(x = "Шкалы NASA-TLX",
       y = "NASA-TLX (сырой балл)",
       color = "Уровень сложности") +
  scale_color_manual(values = c(easy = "black",
                                medium = "gray40",
                                hard = "gray60"))
ggsave("anova_errorbars.png", dpi = 300)
```

```{r}
NASA_TLX |> 
  select(-item) |> 
  # mutate(row_nubmer = row_number()) |> 
  pivot_wider(values_from = score, names_from = scale) |> 
  drop_na() -> nasa_tlx_wide
NASA_TLX |> group_by(task, level) |> summarise(n=n())
nasa_tlx_wide |> group_by(task, level) |> summarise(n=n())
# ez::ezANOVA(data=nasa_tlx_wide, dv = ME, within = .(task, level), wid = id)
```

```{r}
library(lme4)
library(lmerTest)
```

```{r}
mix_ME <- lmer(ME ~ task * level + (1|id), nasa_tlx_wide)
summary(mix_ME)
anova(mix_ME)
```
```{r}
mix_PH <- lmer(PH ~ task * level + (1|id), nasa_tlx_wide)
summary(mix_PH)
anova(mix_PH)
```

```{r}
mix_TI <- lmer(TI ~ task * level + (1|id), nasa_tlx_wide)
summary(mix_TI)
anova(mix_TI)
```

```{r}
mix_PE <- lmer(PE ~ task * level + (1|id), nasa_tlx_wide)
summary(mix_PE)
anova(mix_PE)
```

```{r}
mix_EF <- lmer(EF ~ task * level + (1|id), nasa_tlx_wide)
summary(mix_EF)
anova(mix_EF)
```

```{r}
mix_FR <- lmer(FR ~ task * level + (1|id), nasa_tlx_wide)
summary(mix_FR)
anova(mix_FR)
```


```{r}
NASA_TLX |> 
  filter(scale == "PE") |> 
  ggplot() +
  geom_histogram(data = NASA_TLX |> 
                   filter(scale == "PE") |> 
                   select(-task),
                 aes(score), fill = back_histogram_color,
                 binwidth = 1) +
  geom_histogram(aes(score, fill = task),
                 binwidth = 1) +
  facet_grid(task ~ level) +
  labs(title = "Performance (PE)") +
  scale_fill_manual(values = task_colors) +
  theme(legend.position = "bottom")
```


```{r}
NASA_TLX |> 
  filter(scale == "ME") |> 
  ggplot() +
  geom_histogram(data = NASA_TLX |> 
                   filter(scale == "ME") |> 
                   select(-task),
                 aes(score), fill = back_histogram_color,
                 binwidth = 1) +
  geom_histogram(aes(score, fill = task),
                 binwidth = 1) +
  facet_grid(task ~ level) +
  labs(title = "Mental Demand (ME)") +
  scale_fill_manual(values = task_colors) +
  theme(legend.position = "bottom")
```

```{r}
NASA_TLX |> 
  filter(scale == "PH") |> 
  ggplot() +
  geom_histogram(data = NASA_TLX |> 
                   filter(scale == "PH") |> 
                   select(-task),
                 aes(score), fill = back_histogram_color,
                 binwidth = 1) +
  geom_histogram(aes(score, fill = task),
                 binwidth = 1) +
  facet_grid(task ~ level) +
  labs(title = "Physical Demand (PH)") +
  scale_fill_manual(values = task_colors) +
  theme(legend.position = "bottom")
```

```{r}
NASA_TLX |> 
  filter(scale == "EF") |> 
  ggplot() +
  geom_histogram(data = NASA_TLX |> 
                   filter(scale == "EF") |> 
                   select(-task),
                 aes(score), fill = back_histogram_color,
                 binwidth = 1) +
  geom_histogram(aes(score, fill = task),
                 binwidth = 1) +
  facet_grid(task ~ level) +
  labs(title = "Effort (EF)") +
  scale_fill_manual(values = task_colors) +
  theme(legend.position = "bottom")
```


```{r}
NASA_TLX |> 
  filter(scale == "TI") |> 
  ggplot() +
  geom_histogram(data = NASA_TLX |> 
                   filter(scale == "TI") |> 
                   select(-task),
                 aes(score), fill = back_histogram_color,
                 binwidth = 1) +
  geom_histogram(aes(score, fill = task),
                 binwidth = 1) +
  facet_grid(task ~ level) +
  labs(title = "Time Pressure (TI)") +
  scale_fill_manual(values = task_colors) +
  theme(legend.position = "bottom")
```

```{r}
NASA_TLX |> 
  filter(scale == "FR") |> 
  ggplot() +
  geom_histogram(data = NASA_TLX |> 
                   filter(scale == "FR") |> 
                   select(-task),
                 aes(score), fill = back_histogram_color,
                 binwidth = 1) +
  geom_histogram(aes(score, fill = task),
                 binwidth = 1) +
  facet_grid(task ~ level) +
  labs(title = "Frustration (FR)") +
  scale_fill_manual(values = task_colors) +
  theme(legend.position = "bottom")
```



### CFA

```{r}
NASA_TLX |> 
  group_by(id, item) |> 
  summarise(n = n()) |> 
  filter(n>1)
```

```{r}
NASA_TLX |> 
  pivot_wider(id_cols = id, 
              names_from = item, 
              values_from = score,
              values_fn = unlist) -> NASA_TLX_w
names(NASA_TLX_w)
```

```{r}
model1 <- "PE =~ pe_st_E + pe_st_M + pe_st_H + pe_mr_E + pe_mr_M + pe_mr_H + pe_ms_E + pe_ms_M + pe_ms_H
ME =~ me_st_E + me_st_M + me_st_H + me_mr_E + me_mr_M + me_mr_H + me_ms_E + me_ms_M + me_ms_H
PH =~ ph_st_E + ph_st_M + ph_st_H + ph_mr_E + ph_mr_M + ph_mr_H + ph_ms_E + ph_ms_M + ph_ms_H
EF =~ ef_st_E + ef_st_M + ef_st_H + ef_mr_E + ef_mr_M + ef_mr_H + ef_ms_E + ef_ms_M + ef_ms_H
TI =~ ti_st_E + ti_st_M + ti_st_H + ti_mr_E + ti_mr_M + ti_mr_H + ti_ms_E + ti_ms_M + ti_ms_H
FR =~ fr_st_E + fr_st_M + fr_st_H + fr_mr_E + fr_mr_M + fr_mr_H + fr_ms_E + fr_ms_M + fr_ms_H
OW =~ PE + ME + PH + EF + TI + FR"
```

```{r}
model0 <- "PE =~ pe_st_E + pe_st_M + pe_st_H + pe_mr_E + pe_mr_M + pe_mr_H + pe_ms_E + pe_ms_M + pe_ms_H
ME =~ me_st_E + me_st_M + me_st_H + me_mr_E + me_mr_M + me_mr_H + me_ms_E + me_ms_M + me_ms_H
EF =~ ef_st_E + ef_st_M + ef_st_H + ef_mr_E + ef_mr_M + ef_mr_H + ef_ms_E + ef_ms_M + ef_ms_H
TI =~ ti_st_E + ti_st_M + ti_st_H + ti_mr_E + ti_mr_M + ti_mr_H + ti_ms_E + ti_ms_M + ti_ms_H
FR =~ fr_st_E + fr_st_M + fr_st_H + fr_mr_E + fr_mr_M + fr_mr_H + fr_ms_E + fr_ms_M + fr_ms_H
OW =~ PE + ME + EF + TI + FR"
```

```{r}
cfa0 <- cfa(model0, NASA_TLX_w)
summary(cfa0)
```
```{r}
fitmeasures(cfa0, fit.measures = c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr"))
```

```{r}
cfa0st <- standardizedsolution(cfa0)
```

```{r}
cfa0st %>% filter(op == "=~")
```


```{r}
cfa1 <- cfa(model1, NASA_TLX_w)
summary(cfa1)
```

```{r}
fitmeasures(cfa1, fit.measures = c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr"))
```

```{r}
cfa1st <- standardizedsolution(cfa1)
```

```{r}
cfa1st %>% filter(op == "=~")
```


Warning: lavaan WARNING: some estimated lv variances are negative

Oooookay... Let's try duplicate data to check is it a problem with a number of observations or not...

```{r}
NASA_TLX_w |> select(-id) |> drop_na() |> cor() |> corrplot::corrplot(order = 'hclust')
```

```{r}
NASA_TLX_w |> bind_rows(NASA_TLX_w) |> mutate(id = 1:(nrow(NASA_TLX_w)*2)) -> NASA_TLX_D
```

```{r}
cfa1d <- cfa(model1, NASA_TLX_D)
summary(cfa1)
```

```{r}
fitmeasures(cfa1d, fit.measures = c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr"))
```


## NEW CFA

```{r}
NASA_TLX |> 
  select(-item) |> 
  # mutate(row_nubmer = row_number()) |> 
  pivot_wider(values_from = score, names_from = scale) |> 
  drop_na() -> nasa_tlx_wide
```

```{r}
nasa_tlx_wide |> 
  group_by(id, level) |> 
  summarise(ME_mean = mean(ME),
            PH_mean = mean(PH),
            TI_mean = mean(TI),
            PE_mean = mean(PE),
            EF_mean = mean(EF),
            FR_mean = mean(FR)) |> 
  pivot_longer(cols = -c('id', 'level'), names_to = "scale", values_to = "score") |> 
  mutate(scale = str_remove(scale, "_mean"),
         lvl = substr(level, 1, 1) |> toupper()) |> 
  unite(item, c("scale", "lvl")) |> 
  pivot_wider(names_from = item, values_from = score) -> nasa_tlx_newcfa
```

```{r}
model_easy <- "OW =~ PE_E + ME_E + PH_E + EF_E + TI_E + FR_E"
model_medium <- "OW =~ PE_M + ME_M + PH_M + EF_M + TI_M + FR_M"
model_hard <- "OW =~ PE_H + ME_H + PH_H + EF_H + TI_H + FR_H"
```

```{r}
fit_easy <- cfa(model_easy, nasa_tlx_newcfa)
fit_medium <- cfa(model_medium, nasa_tlx_newcfa)
fit_hard <- cfa(model_hard, nasa_tlx_newcfa)
```

```{r}
graph_sem(model=fit_easy, fix_coord = TRUE)
```
```{r}
graph_sem(model=fit_medium, fix_coord=TRUE)
```
```{r}
graph_sem(model=fit_hard, fix_coord = TRUE)
```

```{r}
fitmeasures(fit_easy, fit.measures = c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr"))
```

```{r}
fitmeasures(fit_medium, fit.measures = c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr"))
```

```{r}
fitmeasures(fit_hard, fit.measures = c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr"))
```

```{r}
summary(fit_easy)
```

```{r}
summary(fit_medium)
```

```{r}
summary(fit_hard)
```

